{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import numpy as np\n",
    "import pandas as pd \n",
    "from sklearn.ensemble import IsolationForest\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "sys.path.append(\"/home/mindy/Documents/projects/creditCardFraud/scripts/\")\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from util import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Simple Isolation Forest Algorithm :\n",
    "\n",
    "* Forest: composed many trees \n",
    "\n",
    "* Isolation Tree:\n",
    "     * external node \n",
    "     * internal node \n",
    "     * randomly choose a feature and randomly choose a value in the feature between max and min and split the data\n",
    "     \n",
    "\n",
    "* Metrics: Path Length  \n",
    "\n",
    "  * abnormal cases tend to have shorter path length than normal cases "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Basic forest constructions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ExNode:\n",
    "    def __init__(self,size):\n",
    "        self.size = size \n",
    "        \n",
    "class InNode:\n",
    "    def __init__(self,left,right,splitAt,splitVal):\n",
    "        self.left = left\n",
    "        self.right = right\n",
    "        self.splitAt = splitAt \n",
    "        self.splitVal = splitVal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Tree(data,currLength,maxDepth):\n",
    "    # either max depth or only one sample left \n",
    "    if currLength >=maxDepth or data.shape[0] <=1:  \n",
    "        return ExNode(data.shape[0])  # the num of sample per external node \n",
    "    else:\n",
    "        allFeatures = data.columns\n",
    "        chosenF = np.random.choice(allFeatures,1)[0]  # randomly choose a feature \n",
    "        chosenV = np.random.choice(data[chosenF].unique(),1)[0] # randomly choose a split value with the chosen feature \n",
    "        left = data[data[chosenF]<chosenV]\n",
    "        right = data[data[chosenF]>=chosenV]\n",
    "        return InNode(Tree(left,currLength+1,maxDepth),Tree(right,currLength+1,maxDepth),chosenF,chosenV)        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pathLength(data,Tree,currLength):\n",
    "    if isinstance(Tree,ExNode): # if it is an external node\n",
    "        return currLength \n",
    "    # if an internal node \n",
    "    feature = Tree.splitAt \n",
    "    if data[feature] < Tree.splitVal: \n",
    "        return pathLength(data,Tree.left,currLength+1)  # traverse down the left branch \n",
    "    else:\n",
    "        return pathLength(data,Tree.right,currLength+1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Forest(data,numTrees, subsamplingSize):\n",
    "    # the maxDepth in the paper is log2(n), n is numer of samples \n",
    "    maxDepth = int(np.ceil(np.log2(subsamplingSize)))\n",
    "    forest = [Tree(data.sample(subsamplingSize),0,maxDepth) for i in range(numTrees)]\n",
    "    return forest"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv(\"../processedData/TrainingData_normal.csv\")\n",
    "dev = pd.read_csv(\"../processedData/DevData_normal.csv\")\n",
    "test = pd.read_csv(\"../processedData/hold_outset_moreFraud.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generate train, test, and normal data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "training, norm, test_data, y_test = train_test_dfs(train,dev,test,\"Class\",0.2,1989)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test one simple isolation Forest \n",
    "\n",
    "* in this case just simply wanting to see fraud cases actually have shorter pathlength "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "forest = Forest(test_data,30,1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "norm_classes = test_data[y_test==0]\n",
    "fraud_classes = test_data[y_test==1]\n",
    "n_sample = fraud_classes.shape[0]\n",
    "sub_norm_classes = norm_classes.sample(n_sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "norm_pL=[]\n",
    "for i in range(n_sample):\n",
    "    row = sub_norm_classes.iloc[i]\n",
    "    L = []\n",
    "    for tr in forest:\n",
    "        L.append(pathLength(row,tr,0))\n",
    "    norm_pL.append(np.mean(L))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "fraud_pL=[]\n",
    "for i in range(n_sample):\n",
    "    row = fraud_classes.iloc[i]\n",
    "    L = []\n",
    "    for tr in forest:\n",
    "        L.append(pathLength(row,tr,0))\n",
    "    fraud_pL.append(np.mean(L))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_relationship(norm_data=norm_pL,fraud_data=fraud_pL,feature_name=\"pathLength\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Appears that fraud cases do have shorter pathLength than non fraud cases even though pathLength is not normalized by tree depth "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Use more sophiscated Sklearn Isolation forest "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### the parameters are from trial and error "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "contam=training.Class.value_counts(normalize=True).loc[1] \n",
    "iFor_norm = IsolationForest(n_estimators=80, max_samples=0.8, contamination=contam*1.5,max_features=1.0, \n",
    "                        bootstrap=False,random_state=42, n_jobs=20)\n",
    "iFor_all = IsolationForest(n_estimators=80, max_samples=0.8, contamination=contam*1.5,max_features=1.0, \n",
    "                        bootstrap=False,random_state=42, n_jobs=20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Isolation Forest is supposed to be insensitive to outliers in the training dataset and we shall see if we get comparable outcome with normal vs data with fraud observations "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "IsolationForest(contamination=0.002607035484649652, max_samples=0.8,\n",
       "                n_estimators=80, n_jobs=20, random_state=42)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "iFor_norm.fit(norm)\n",
    "iFor_all.fit(training.drop(\"Class\",axis=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_score_norm = iFor_norm.decision_function(test_data)\n",
    "pred_score_all = iFor_all.decision_function(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>56962.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.160984</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.020926</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>-0.295073</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.157049</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.165796</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>0.171551</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>0.183105</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  0\n",
       "count  56962.000000\n",
       "mean       0.160984\n",
       "std        0.020926\n",
       "min       -0.295073\n",
       "25%        0.157049\n",
       "50%        0.165796\n",
       "75%        0.171551\n",
       "max        0.183105"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(pred_score_all).describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>56962.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.150670</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.023083</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>-0.318697</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.145813</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.155953</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>0.162389</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>0.173886</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  0\n",
       "count  56962.000000\n",
       "mean       0.150670\n",
       "std        0.023083\n",
       "min       -0.318697\n",
       "25%        0.145813\n",
       "50%        0.155953\n",
       "75%        0.162389\n",
       "max        0.173886"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(pred_score_norm).describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[56722   144]\n",
      " [   36    60]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00     56866\n",
      "           1       0.29      0.62      0.40        96\n",
      "\n",
      "    accuracy                           1.00     56962\n",
      "   macro avg       0.65      0.81      0.70     56962\n",
      "weighted avg       1.00      1.00      1.00     56962\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model_results(y_test,-pred_score_norm,0.0)  # negative score in sklearn version means abnormal "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[56776    90]\n",
      " [   53    43]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00     56866\n",
      "           1       0.32      0.45      0.38        96\n",
      "\n",
      "    accuracy                           1.00     56962\n",
      "   macro avg       0.66      0.72      0.69     56962\n",
      "weighted avg       1.00      1.00      1.00     56962\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model_results(y_test,-pred_score_all,0.0) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Didn't appear to have a huge difference if train on all normal or contaminated samples. \n",
    "\n",
    "* but proves that Isolation forest is not as sensitive to outlier the same way as OneClassSVM but normal class only is still better "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Use gridSearchCV to perform more systematic parameter optimization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Define Custom Score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "custom_score = make_custom_score()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define custom train and test splits "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "cvSplits,X_train,y_train = makeCustomSplits(training,\"Class\",5,208,contam)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### training parameter and CV grid "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "parameters = {\n",
    "              \"n_estimators\":[50,80,120],\n",
    "              \"max_samples\":[\"auto\",0.5,0.8],\n",
    "              \"contamination\":[contam, contam*1.5],\n",
    "}\n",
    "\n",
    "CV = GridSearchCV(IsolationForest(bootstrap=False,max_features=1),\n",
    "                  parameters,\n",
    "                  scoring=custom_score,\n",
    "                  refit=False,\n",
    "                  n_jobs=20,\n",
    "                  verbose=1,\n",
    "                  cv=cvSplits\n",
    "                 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 18 candidates, totalling 90 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=20)]: Using backend LokyBackend with 20 concurrent workers.\n",
      "[Parallel(n_jobs=20)]: Done  10 tasks      | elapsed:   17.2s\n",
      "[Parallel(n_jobs=20)]: Done  90 out of  90 | elapsed:  2.2min finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=<generator object makeCustomSplits.<locals>.<genexpr> at 0x7fe2ba202ca8>,\n",
       "             estimator=IsolationForest(max_features=1), n_jobs=20,\n",
       "             param_grid={'contamination': [0.0017380236564331015,\n",
       "                                           0.002607035484649652],\n",
       "                         'max_samples': ['auto', 0.5, 0.8],\n",
       "                         'n_estimators': [50, 80, 120]},\n",
       "             refit=False,\n",
       "             scoring={'f1_f': make_scorer(f1_f), 'fn': make_scorer(fn),\n",
       "                      'fp': make_scorer(fp), 'prec_f': make_scorer(prec_f),\n",
       "                      'recall_f': make_scorer(recall_f),\n",
       "                      'tp': make_scorer(tp)},\n",
       "             verbose=1)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "CV.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_output = CVResultsOutput(CV.cv_results_,custom_score.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>contamination</th>\n",
       "      <th>max_samples</th>\n",
       "      <th>n_estimators</th>\n",
       "      <th>tp</th>\n",
       "      <th>fp</th>\n",
       "      <th>fn</th>\n",
       "      <th>f1_f</th>\n",
       "      <th>prec_f</th>\n",
       "      <th>recall_f</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.001738</td>\n",
       "      <td>auto</td>\n",
       "      <td>50</td>\n",
       "      <td>28.4</td>\n",
       "      <td>81.4</td>\n",
       "      <td>50.6</td>\n",
       "      <td>0.299580</td>\n",
       "      <td>0.257657</td>\n",
       "      <td>0.359494</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.001738</td>\n",
       "      <td>auto</td>\n",
       "      <td>80</td>\n",
       "      <td>27.6</td>\n",
       "      <td>78.0</td>\n",
       "      <td>51.4</td>\n",
       "      <td>0.297709</td>\n",
       "      <td>0.260102</td>\n",
       "      <td>0.349367</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.001738</td>\n",
       "      <td>auto</td>\n",
       "      <td>120</td>\n",
       "      <td>26.6</td>\n",
       "      <td>80.8</td>\n",
       "      <td>52.4</td>\n",
       "      <td>0.284928</td>\n",
       "      <td>0.247730</td>\n",
       "      <td>0.336709</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.001738</td>\n",
       "      <td>0.5</td>\n",
       "      <td>50</td>\n",
       "      <td>32.6</td>\n",
       "      <td>82.8</td>\n",
       "      <td>46.4</td>\n",
       "      <td>0.335285</td>\n",
       "      <td>0.283019</td>\n",
       "      <td>0.412658</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.001738</td>\n",
       "      <td>0.5</td>\n",
       "      <td>80</td>\n",
       "      <td>30.0</td>\n",
       "      <td>85.0</td>\n",
       "      <td>49.0</td>\n",
       "      <td>0.308334</td>\n",
       "      <td>0.260132</td>\n",
       "      <td>0.379747</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.001738</td>\n",
       "      <td>0.5</td>\n",
       "      <td>120</td>\n",
       "      <td>33.6</td>\n",
       "      <td>85.4</td>\n",
       "      <td>45.4</td>\n",
       "      <td>0.338068</td>\n",
       "      <td>0.280952</td>\n",
       "      <td>0.425316</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.001738</td>\n",
       "      <td>0.8</td>\n",
       "      <td>50</td>\n",
       "      <td>31.6</td>\n",
       "      <td>90.6</td>\n",
       "      <td>47.4</td>\n",
       "      <td>0.315018</td>\n",
       "      <td>0.260685</td>\n",
       "      <td>0.400000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.001738</td>\n",
       "      <td>0.8</td>\n",
       "      <td>80</td>\n",
       "      <td>35.8</td>\n",
       "      <td>86.2</td>\n",
       "      <td>43.2</td>\n",
       "      <td>0.356197</td>\n",
       "      <td>0.294015</td>\n",
       "      <td>0.453165</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.001738</td>\n",
       "      <td>0.8</td>\n",
       "      <td>120</td>\n",
       "      <td>37.2</td>\n",
       "      <td>94.6</td>\n",
       "      <td>41.8</td>\n",
       "      <td>0.353030</td>\n",
       "      <td>0.283215</td>\n",
       "      <td>0.470886</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.002607</td>\n",
       "      <td>auto</td>\n",
       "      <td>50</td>\n",
       "      <td>30.6</td>\n",
       "      <td>120.6</td>\n",
       "      <td>48.4</td>\n",
       "      <td>0.263187</td>\n",
       "      <td>0.199706</td>\n",
       "      <td>0.387342</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.002607</td>\n",
       "      <td>auto</td>\n",
       "      <td>80</td>\n",
       "      <td>35.2</td>\n",
       "      <td>117.6</td>\n",
       "      <td>43.8</td>\n",
       "      <td>0.302862</td>\n",
       "      <td>0.230250</td>\n",
       "      <td>0.445570</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0.002607</td>\n",
       "      <td>auto</td>\n",
       "      <td>120</td>\n",
       "      <td>29.0</td>\n",
       "      <td>119.4</td>\n",
       "      <td>50.0</td>\n",
       "      <td>0.255013</td>\n",
       "      <td>0.195801</td>\n",
       "      <td>0.367089</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0.002607</td>\n",
       "      <td>0.5</td>\n",
       "      <td>50</td>\n",
       "      <td>38.0</td>\n",
       "      <td>132.2</td>\n",
       "      <td>41.0</td>\n",
       "      <td>0.306016</td>\n",
       "      <td>0.225218</td>\n",
       "      <td>0.481013</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0.002607</td>\n",
       "      <td>0.5</td>\n",
       "      <td>80</td>\n",
       "      <td>44.2</td>\n",
       "      <td>130.0</td>\n",
       "      <td>34.8</td>\n",
       "      <td>0.349023</td>\n",
       "      <td>0.254204</td>\n",
       "      <td>0.559494</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0.002607</td>\n",
       "      <td>0.5</td>\n",
       "      <td>120</td>\n",
       "      <td>41.6</td>\n",
       "      <td>128.4</td>\n",
       "      <td>37.4</td>\n",
       "      <td>0.334357</td>\n",
       "      <td>0.245340</td>\n",
       "      <td>0.526582</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>0.002607</td>\n",
       "      <td>0.8</td>\n",
       "      <td>50</td>\n",
       "      <td>34.6</td>\n",
       "      <td>135.0</td>\n",
       "      <td>44.4</td>\n",
       "      <td>0.275534</td>\n",
       "      <td>0.201737</td>\n",
       "      <td>0.437975</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>0.002607</td>\n",
       "      <td>0.8</td>\n",
       "      <td>80</td>\n",
       "      <td>39.8</td>\n",
       "      <td>135.0</td>\n",
       "      <td>39.2</td>\n",
       "      <td>0.311860</td>\n",
       "      <td>0.226398</td>\n",
       "      <td>0.503797</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>0.002607</td>\n",
       "      <td>0.8</td>\n",
       "      <td>120</td>\n",
       "      <td>40.2</td>\n",
       "      <td>135.0</td>\n",
       "      <td>38.8</td>\n",
       "      <td>0.316360</td>\n",
       "      <td>0.229795</td>\n",
       "      <td>0.508861</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    contamination max_samples  n_estimators    tp     fp    fn      f1_f  \\\n",
       "0        0.001738        auto            50  28.4   81.4  50.6  0.299580   \n",
       "1        0.001738        auto            80  27.6   78.0  51.4  0.297709   \n",
       "2        0.001738        auto           120  26.6   80.8  52.4  0.284928   \n",
       "3        0.001738         0.5            50  32.6   82.8  46.4  0.335285   \n",
       "4        0.001738         0.5            80  30.0   85.0  49.0  0.308334   \n",
       "5        0.001738         0.5           120  33.6   85.4  45.4  0.338068   \n",
       "6        0.001738         0.8            50  31.6   90.6  47.4  0.315018   \n",
       "7        0.001738         0.8            80  35.8   86.2  43.2  0.356197   \n",
       "8        0.001738         0.8           120  37.2   94.6  41.8  0.353030   \n",
       "9        0.002607        auto            50  30.6  120.6  48.4  0.263187   \n",
       "10       0.002607        auto            80  35.2  117.6  43.8  0.302862   \n",
       "11       0.002607        auto           120  29.0  119.4  50.0  0.255013   \n",
       "12       0.002607         0.5            50  38.0  132.2  41.0  0.306016   \n",
       "13       0.002607         0.5            80  44.2  130.0  34.8  0.349023   \n",
       "14       0.002607         0.5           120  41.6  128.4  37.4  0.334357   \n",
       "15       0.002607         0.8            50  34.6  135.0  44.4  0.275534   \n",
       "16       0.002607         0.8            80  39.8  135.0  39.2  0.311860   \n",
       "17       0.002607         0.8           120  40.2  135.0  38.8  0.316360   \n",
       "\n",
       "      prec_f  recall_f  \n",
       "0   0.257657  0.359494  \n",
       "1   0.260102  0.349367  \n",
       "2   0.247730  0.336709  \n",
       "3   0.283019  0.412658  \n",
       "4   0.260132  0.379747  \n",
       "5   0.280952  0.425316  \n",
       "6   0.260685  0.400000  \n",
       "7   0.294015  0.453165  \n",
       "8   0.283215  0.470886  \n",
       "9   0.199706  0.387342  \n",
       "10  0.230250  0.445570  \n",
       "11  0.195801  0.367089  \n",
       "12  0.225218  0.481013  \n",
       "13  0.254204  0.559494  \n",
       "14  0.245340  0.526582  \n",
       "15  0.201737  0.437975  \n",
       "16  0.226398  0.503797  \n",
       "17  0.229795  0.508861  "
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Instead of using best selected estimator, use the output with the best overall tp,fp,fn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_model = IsolationForest(n_estimators=80,max_samples=0.5,contamination=contam*1.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "IsolationForest(contamination=0.002607035484649652, max_samples=0.5,\n",
       "                n_estimators=80)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_model.fit(norm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_pred_score = best_model.decision_function(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[56729   137]\n",
      " [   29    67]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00     56866\n",
      "           1       0.33      0.70      0.45        96\n",
      "\n",
      "    accuracy                           1.00     56962\n",
      "   macro avg       0.66      0.85      0.72     56962\n",
      "weighted avg       1.00      1.00      1.00     56962\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model_results(y_test,-best_pred_score,-0.0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### It appears that gridSearch with this approach does better than orthogonal tuning"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
