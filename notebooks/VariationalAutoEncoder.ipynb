{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import numpy as np\n",
    "import pandas as pd \n",
    "import tensorflow_probability as tfp\n",
    "import tensorflow.compat.v2 as tf\n",
    "import matplotlib.pyplot as plt \n",
    "%matplotlib inline\n",
    "sys.path.append(\"/home/mindy/Documents/projects/creditCardFraud/scripts/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfk = tf.keras\n",
    "tfkl=tf.keras.layers\n",
    "tfpl= tfp.layers         # layers for tensor flow probability \n",
    "tfd = tfp.distributions # distribution layer "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "from util import *\n",
    "from NN_util import *\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make sure GPU is running \n",
    "tf.test.gpu_device_name()\n",
    "# set max limit to 7.5 G /8 total available \n",
    "set_gpu_limit(7.5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import training and dev data and convert to numpy array for NN "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv(\"../processedData/TrainingData_normal.csv\")\n",
    "dev = pd.read_csv(\"../processedData/DevData_normal.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### converting into tf data set to allow simple efficient data pipelines. \n",
    "* In autoencoder, you are predicting the original input x \n",
    "* shuffle and train data in batches with 1000 epochs "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "buffer_size = 10000\n",
    "batch_size = 256\n",
    "epochs = 500\n",
    "input_size = train.shape[1]\n",
    "encoded_size = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data, dev_data = make_tensor_dataset([train,dev],buffer_size,batch_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### set up checkpoint and other settings "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint = tfk.callbacks.ModelCheckpoint(\"../savedModels/VariationalEncoderModel_2.h5\",verbose=1,save_best_only=True)\n",
    "earlystop = tfk.callbacks.EarlyStopping(monitor=\"val_loss\", mode=\"min\", min_delta=0.005, patience=20, verbose=1, restore_best_weights=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### For variational autoencoder we need to maximize ELBO (evidence lower bound objective):\n",
    "\n",
    "$$ELBO(x)= \\int dzq(z|x)logp(x|z) + \\int dzq(z|x)log\\frac{q(z|x)}{p(z)} $$\n",
    "\n",
    "* p(z): the prior on the latent representation z (last layer of encoder) \n",
    "* q(z|x_input): the encoder (how likely is z given x_input)\n",
    "* p(x_hat|z): the decoder (how likely is x_hat given z) \n",
    "* $\\int dzq(z|x)logp(x|z)$: reconstructin term. (how likely for us to get output_x given input_x and encode to z then decode to x_output) \n",
    "* $\\int dzq(z|x)log\\frac{q(z|x)}{p(z)} $: KL divergence. How similar are the encoder distribution and the prior distribution. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prior distribution for z: \n",
    "\n",
    "* Since this is latent representation (noise has been removed), it is okay to assume it is isotropic gaussian "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "prior = tfd.Independent(tfd.Normal(loc=tf.zeros(encoded_size), scale=1),\n",
    "                        reinterpreted_batch_ndims=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## encoder model for autoencoder:\n",
    "* encoder: 3 layers:\n",
    "  * 3 dense layers \n",
    "  * 3 dimensional multivariable non zero covariance normal distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/mindy/.venv/tf/lib/python3.6/site-packages/tensorflow/python/ops/linalg/linear_operator_lower_triangular.py:158: calling LinearOperator.__init__ (from tensorflow.python.ops.linalg.linear_operator) with graph_parents is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Do not pass `graph_parents`.  They will  no longer be used.\n",
      "Model: \"encoder\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense (Dense)                (None, 20)                620       \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 10)                210       \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 20)                220       \n",
      "_________________________________________________________________\n",
      "multivariate_normal_tri_l (M ((None, 5), (None, 5))    0         \n",
      "=================================================================\n",
      "Total params: 1,050\n",
      "Trainable params: 1,050\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "encoder = tfk.Sequential([\n",
    "    tfkl.InputLayer(input_shape = input_size),  # 30 input features \n",
    "    tfkl.Dense(units=20, activation=tf.nn.leaky_relu, activity_regularizer=tfk.regularizers.l1(10e-5)),\n",
    "    tfkl.Dense(units=10, activation=tf.nn.leaky_relu, activity_regularizer=tfk.regularizers.l1(10e-5)),\n",
    "    tfkl.Dense(tfpl.MultivariateNormalTriL.params_size(encoded_size),activation=None),\n",
    "    tfpl.MultivariateNormalTriL(encoded_size,activity_regularizer=tfpl.KLDivergenceRegularizer(prior))\n",
    "    ], name=\"encoder\")\n",
    "encoder.summary()    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## decoder model for autoencoder:\n",
    "* decoder: 3 layers:\n",
    "   * 3 dense layers\n",
    "   * independent normal distributions as output "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"decoder\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_3 (Dense)              (None, 10)                60        \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 20)                220       \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 60)                1260      \n",
      "_________________________________________________________________\n",
      "independent_normal (Independ ((None, 30), (None, 30))  0         \n",
      "=================================================================\n",
      "Total params: 1,540\n",
      "Trainable params: 1,540\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "decoder = tfk.Sequential([\n",
    "    tfkl.InputLayer(input_shape=[encoded_size]),\n",
    "    tfkl.Dense(units=10, activation=tf.nn.leaky_relu, activity_regularizer=tfk.regularizers.l1(10e-5)),\n",
    "    tfkl.Dense(units=20, activation=tf.nn.leaky_relu, activity_regularizer=tfk.regularizers.l1(10e-5)),\n",
    "    tfkl.Dense(tfpl.IndependentNormal.params_size(input_size),activation=None),\n",
    "    tfpl.IndependentNormal(input_size)\n",
    "    ], name = \"decoder\")\n",
    "decoder.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Add encoders together \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "VAE = tfk.Model(inputs=encoder.inputs, outputs=decoder(encoder.outputs[0]),name=\"VAE\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"VAE\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         [(None, 30)]              0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 20)                620       \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 10)                210       \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 20)                220       \n",
      "_________________________________________________________________\n",
      "multivariate_normal_tri_l (M ((None, 5), (None, 5))    0         \n",
      "_________________________________________________________________\n",
      "decoder (Sequential)         (None, 30)                1540      \n",
      "=================================================================\n",
      "Total params: 2,590\n",
      "Trainable params: 2,590\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "VAE.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### define reconstruction loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "negloglik = lambda x_input, x_output: -x_output.log_prob(x_input)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### compile the model and train model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "VAE.compile(optimizer=tf.optimizers.Adam(learning_rate=1e-3), loss=negloglik)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/500\n",
      "706/711 [============================>.] - ETA: 0s - loss: 714.3268\n",
      "Epoch 00001: val_loss improved from inf to 127.02262, saving model to ../savedModels/VariationalEncoderModel_2.h5\n",
      "711/711 [==============================] - 3s 4ms/step - loss: 710.1678 - val_loss: 127.0226\n",
      "Epoch 2/500\n",
      "702/711 [============================>.] - ETA: 0s - loss: 618.9617\n",
      "Epoch 00002: val_loss improved from 127.02262 to 101.20383, saving model to ../savedModels/VariationalEncoderModel_2.h5\n",
      "711/711 [==============================] - 3s 4ms/step - loss: 612.4127 - val_loss: 101.2038\n",
      "Epoch 3/500\n",
      "700/711 [============================>.] - ETA: 0s - loss: 352046.9375\n",
      "Epoch 00003: val_loss improved from 101.20383 to 86.85255, saving model to ../savedModels/VariationalEncoderModel_2.h5\n",
      "711/711 [==============================] - 3s 4ms/step - loss: 346600.1562 - val_loss: 86.8525\n",
      "Epoch 4/500\n",
      "710/711 [============================>.] - ETA: 0s - loss: 143.5374\n",
      "Epoch 00004: val_loss improved from 86.85255 to 83.56260, saving model to ../savedModels/VariationalEncoderModel_2.h5\n",
      "711/711 [==============================] - 3s 4ms/step - loss: 143.4506 - val_loss: 83.5626\n",
      "Epoch 5/500\n",
      "711/711 [==============================] - ETA: 0s - loss: 82.4636\n",
      "Epoch 00005: val_loss improved from 83.56260 to 81.86973, saving model to ../savedModels/VariationalEncoderModel_2.h5\n",
      "711/711 [==============================] - 3s 4ms/step - loss: 82.4636 - val_loss: 81.8697\n",
      "Epoch 6/500\n",
      "706/711 [============================>.] - ETA: 0s - loss: 80.7035\n",
      "Epoch 00006: val_loss improved from 81.86973 to 79.81298, saving model to ../savedModels/VariationalEncoderModel_2.h5\n",
      "711/711 [==============================] - 3s 4ms/step - loss: 80.6791 - val_loss: 79.8130\n",
      "Epoch 7/500\n",
      "704/711 [============================>.] - ETA: 0s - loss: 84.5467\n",
      "Epoch 00007: val_loss improved from 79.81298 to 78.91199, saving model to ../savedModels/VariationalEncoderModel_2.h5\n",
      "711/711 [==============================] - 3s 4ms/step - loss: 84.4973 - val_loss: 78.9120\n",
      "Epoch 8/500\n",
      "711/711 [==============================] - ETA: 0s - loss: 268.2910\n",
      "Epoch 00008: val_loss improved from 78.91199 to 77.91272, saving model to ../savedModels/VariationalEncoderModel_2.h5\n",
      "711/711 [==============================] - 3s 4ms/step - loss: 268.2910 - val_loss: 77.9127\n",
      "Epoch 9/500\n",
      "710/711 [============================>.] - ETA: 0s - loss: 77.9236\n",
      "Epoch 00009: val_loss improved from 77.91272 to 77.49155, saving model to ../savedModels/VariationalEncoderModel_2.h5\n",
      "711/711 [==============================] - 3s 4ms/step - loss: 77.9226 - val_loss: 77.4916\n",
      "Epoch 10/500\n",
      "700/711 [============================>.] - ETA: 0s - loss: 491.6370\n",
      "Epoch 00010: val_loss improved from 77.49155 to 75.70221, saving model to ../savedModels/VariationalEncoderModel_2.h5\n",
      "711/711 [==============================] - 3s 4ms/step - loss: 485.1787 - val_loss: 75.7022\n",
      "Epoch 11/500\n",
      "706/711 [============================>.] - ETA: 0s - loss: 75.5756\n",
      "Epoch 00011: val_loss improved from 75.70221 to 74.97881, saving model to ../savedModels/VariationalEncoderModel_2.h5\n",
      "711/711 [==============================] - 3s 4ms/step - loss: 75.5668 - val_loss: 74.9788\n",
      "Epoch 12/500\n",
      "710/711 [============================>.] - ETA: 0s - loss: 75.0302\n",
      "Epoch 00012: val_loss improved from 74.97881 to 74.59526, saving model to ../savedModels/VariationalEncoderModel_2.h5\n",
      "711/711 [==============================] - 3s 4ms/step - loss: 75.0293 - val_loss: 74.5953\n",
      "Epoch 13/500\n",
      "704/711 [============================>.] - ETA: 0s - loss: 74.4200\n",
      "Epoch 00013: val_loss improved from 74.59526 to 73.83689, saving model to ../savedModels/VariationalEncoderModel_2.h5\n",
      "711/711 [==============================] - 3s 4ms/step - loss: 74.4317 - val_loss: 73.8369\n",
      "Epoch 14/500\n",
      "699/711 [============================>.] - ETA: 0s - loss: 73.6164\n",
      "Epoch 00014: val_loss improved from 73.83689 to 73.48008, saving model to ../savedModels/VariationalEncoderModel_2.h5\n",
      "711/711 [==============================] - 3s 4ms/step - loss: 73.6048 - val_loss: 73.4801\n",
      "Epoch 15/500\n",
      "700/711 [============================>.] - ETA: 0s - loss: 73.1602\n",
      "Epoch 00015: val_loss improved from 73.48008 to 72.25481, saving model to ../savedModels/VariationalEncoderModel_2.h5\n",
      "711/711 [==============================] - 3s 4ms/step - loss: 73.1320 - val_loss: 72.2548\n",
      "Epoch 16/500\n",
      "706/711 [============================>.] - ETA: 0s - loss: 71.5376\n",
      "Epoch 00016: val_loss improved from 72.25481 to 71.06036, saving model to ../savedModels/VariationalEncoderModel_2.h5\n",
      "711/711 [==============================] - 3s 4ms/step - loss: 71.5433 - val_loss: 71.0604\n",
      "Epoch 17/500\n",
      "700/711 [============================>.] - ETA: 0s - loss: 70.2111\n",
      "Epoch 00017: val_loss improved from 71.06036 to 69.29050, saving model to ../savedModels/VariationalEncoderModel_2.h5\n",
      "711/711 [==============================] - 3s 4ms/step - loss: 70.1787 - val_loss: 69.2905\n",
      "Epoch 18/500\n",
      "699/711 [============================>.] - ETA: 0s - loss: 68.2454\n",
      "Epoch 00018: val_loss improved from 69.29050 to 67.25780, saving model to ../savedModels/VariationalEncoderModel_2.h5\n",
      "711/711 [==============================] - 3s 4ms/step - loss: 68.2438 - val_loss: 67.2578\n",
      "Epoch 19/500\n",
      "709/711 [============================>.] - ETA: 0s - loss: 66.1341\n",
      "Epoch 00019: val_loss improved from 67.25780 to 64.74639, saving model to ../savedModels/VariationalEncoderModel_2.h5\n",
      "711/711 [==============================] - 3s 4ms/step - loss: 66.1203 - val_loss: 64.7464\n",
      "Epoch 20/500\n",
      "705/711 [============================>.] - ETA: 0s - loss: 63.6693\n",
      "Epoch 00020: val_loss improved from 64.74639 to 62.33298, saving model to ../savedModels/VariationalEncoderModel_2.h5\n",
      "711/711 [==============================] - 3s 4ms/step - loss: 63.6582 - val_loss: 62.3330\n",
      "Epoch 21/500\n",
      "704/711 [============================>.] - ETA: 0s - loss: 61.0681\n",
      "Epoch 00021: val_loss improved from 62.33298 to 59.74157, saving model to ../savedModels/VariationalEncoderModel_2.h5\n",
      "711/711 [==============================] - 3s 4ms/step - loss: 61.0529 - val_loss: 59.7416\n",
      "Epoch 22/500\n",
      "706/711 [============================>.] - ETA: 0s - loss: 58.2956\n",
      "Epoch 00022: val_loss improved from 59.74157 to 57.03807, saving model to ../savedModels/VariationalEncoderModel_2.h5\n",
      "711/711 [==============================] - 3s 4ms/step - loss: 58.2924 - val_loss: 57.0381\n",
      "Epoch 23/500\n",
      "705/711 [============================>.] - ETA: 0s - loss: 55.5442\n",
      "Epoch 00023: val_loss improved from 57.03807 to 54.19976, saving model to ../savedModels/VariationalEncoderModel_2.h5\n",
      "711/711 [==============================] - 3s 4ms/step - loss: 55.5370 - val_loss: 54.1998\n",
      "Epoch 24/500\n",
      "702/711 [============================>.] - ETA: 0s - loss: 52.7985\n",
      "Epoch 00024: val_loss improved from 54.19976 to 51.45391, saving model to ../savedModels/VariationalEncoderModel_2.h5\n",
      "711/711 [==============================] - 3s 4ms/step - loss: 52.7801 - val_loss: 51.4539\n",
      "Epoch 25/500\n",
      "699/711 [============================>.] - ETA: 0s - loss: 50.1541\n",
      "Epoch 00025: val_loss improved from 51.45391 to 48.94968, saving model to ../savedModels/VariationalEncoderModel_2.h5\n",
      "711/711 [==============================] - 3s 4ms/step - loss: 50.1370 - val_loss: 48.9497\n",
      "Epoch 26/500\n",
      "702/711 [============================>.] - ETA: 0s - loss: 47.9117\n",
      "Epoch 00026: val_loss improved from 48.94968 to 46.96243, saving model to ../savedModels/VariationalEncoderModel_2.h5\n",
      "711/711 [==============================] - 3s 4ms/step - loss: 47.8983 - val_loss: 46.9624\n",
      "Epoch 27/500\n",
      "702/711 [============================>.] - ETA: 0s - loss: 46.0389\n",
      "Epoch 00027: val_loss improved from 46.96243 to 45.60429, saving model to ../savedModels/VariationalEncoderModel_2.h5\n",
      "711/711 [==============================] - 3s 4ms/step - loss: 46.0301 - val_loss: 45.6043\n",
      "Epoch 28/500\n",
      "707/711 [============================>.] - ETA: 0s - loss: 44.6470\n",
      "Epoch 00028: val_loss improved from 45.60429 to 44.14147, saving model to ../savedModels/VariationalEncoderModel_2.h5\n",
      "711/711 [==============================] - 3s 4ms/step - loss: 44.6447 - val_loss: 44.1415\n",
      "Epoch 29/500\n",
      "698/711 [============================>.] - ETA: 0s - loss: 43.5923\n",
      "Epoch 00029: val_loss improved from 44.14147 to 43.02106, saving model to ../savedModels/VariationalEncoderModel_2.h5\n",
      "711/711 [==============================] - 3s 4ms/step - loss: 43.5741 - val_loss: 43.0211\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 30/500\n",
      "703/711 [============================>.] - ETA: 0s - loss: 42.6498\n",
      "Epoch 00030: val_loss improved from 43.02106 to 42.30232, saving model to ../savedModels/VariationalEncoderModel_2.h5\n",
      "711/711 [==============================] - 3s 4ms/step - loss: 42.6443 - val_loss: 42.3023\n",
      "Epoch 31/500\n",
      "696/711 [============================>.] - ETA: 0s - loss: 41.9472\n",
      "Epoch 00031: val_loss improved from 42.30232 to 41.64722, saving model to ../savedModels/VariationalEncoderModel_2.h5\n",
      "711/711 [==============================] - 3s 4ms/step - loss: 41.9415 - val_loss: 41.6472\n",
      "Epoch 32/500\n",
      "705/711 [============================>.] - ETA: 0s - loss: 41.3181\n",
      "Epoch 00032: val_loss improved from 41.64722 to 41.05382, saving model to ../savedModels/VariationalEncoderModel_2.h5\n",
      "711/711 [==============================] - 3s 4ms/step - loss: 41.3124 - val_loss: 41.0538\n",
      "Epoch 33/500\n",
      "701/711 [============================>.] - ETA: 0s - loss: 40.8512\n",
      "Epoch 00033: val_loss improved from 41.05382 to 40.67692, saving model to ../savedModels/VariationalEncoderModel_2.h5\n",
      "711/711 [==============================] - 3s 4ms/step - loss: 40.8551 - val_loss: 40.6769\n",
      "Epoch 34/500\n",
      "710/711 [============================>.] - ETA: 0s - loss: 40.4852\n",
      "Epoch 00034: val_loss improved from 40.67692 to 40.28920, saving model to ../savedModels/VariationalEncoderModel_2.h5\n",
      "711/711 [==============================] - 3s 4ms/step - loss: 40.4862 - val_loss: 40.2892\n",
      "Epoch 35/500\n",
      "708/711 [============================>.] - ETA: 0s - loss: 40.0942\n",
      "Epoch 00035: val_loss improved from 40.28920 to 39.99139, saving model to ../savedModels/VariationalEncoderModel_2.h5\n",
      "711/711 [==============================] - 3s 4ms/step - loss: 40.0912 - val_loss: 39.9914\n",
      "Epoch 36/500\n",
      "700/711 [============================>.] - ETA: 0s - loss: 39.7018\n",
      "Epoch 00036: val_loss improved from 39.99139 to 39.58932, saving model to ../savedModels/VariationalEncoderModel_2.h5\n",
      "711/711 [==============================] - 3s 4ms/step - loss: 39.6988 - val_loss: 39.5893\n",
      "Epoch 37/500\n",
      "701/711 [============================>.] - ETA: 0s - loss: 39.3177\n",
      "Epoch 00037: val_loss improved from 39.58932 to 39.14284, saving model to ../savedModels/VariationalEncoderModel_2.h5\n",
      "711/711 [==============================] - 3s 4ms/step - loss: 39.3091 - val_loss: 39.1428\n",
      "Epoch 38/500\n",
      "700/711 [============================>.] - ETA: 0s - loss: 38.8830\n",
      "Epoch 00038: val_loss improved from 39.14284 to 38.74326, saving model to ../savedModels/VariationalEncoderModel_2.h5\n",
      "711/711 [==============================] - 3s 4ms/step - loss: 38.8801 - val_loss: 38.7433\n",
      "Epoch 39/500\n",
      "703/711 [============================>.] - ETA: 0s - loss: 38.4590\n",
      "Epoch 00039: val_loss improved from 38.74326 to 38.32243, saving model to ../savedModels/VariationalEncoderModel_2.h5\n",
      "711/711 [==============================] - 3s 4ms/step - loss: 38.4533 - val_loss: 38.3224\n",
      "Epoch 40/500\n",
      "698/711 [============================>.] - ETA: 0s - loss: 37.9964\n",
      "Epoch 00040: val_loss improved from 38.32243 to 37.83699, saving model to ../savedModels/VariationalEncoderModel_2.h5\n",
      "711/711 [==============================] - 3s 4ms/step - loss: 37.9822 - val_loss: 37.8370\n",
      "Epoch 41/500\n",
      "708/711 [============================>.] - ETA: 0s - loss: 37.5347\n",
      "Epoch 00041: val_loss improved from 37.83699 to 37.34751, saving model to ../savedModels/VariationalEncoderModel_2.h5\n",
      "711/711 [==============================] - 3s 4ms/step - loss: 37.5316 - val_loss: 37.3475\n",
      "Epoch 42/500\n",
      "702/711 [============================>.] - ETA: 0s - loss: 37.0382\n",
      "Epoch 00042: val_loss improved from 37.34751 to 37.11637, saving model to ../savedModels/VariationalEncoderModel_2.h5\n",
      "711/711 [==============================] - 3s 4ms/step - loss: 37.0389 - val_loss: 37.1164\n",
      "Epoch 43/500\n",
      "701/711 [============================>.] - ETA: 0s - loss: 36.6207\n",
      "Epoch 00043: val_loss improved from 37.11637 to 36.46012, saving model to ../savedModels/VariationalEncoderModel_2.h5\n",
      "711/711 [==============================] - 3s 4ms/step - loss: 36.6181 - val_loss: 36.4601\n",
      "Epoch 44/500\n",
      "702/711 [============================>.] - ETA: 0s - loss: 36.1957\n",
      "Epoch 00044: val_loss improved from 36.46012 to 36.18133, saving model to ../savedModels/VariationalEncoderModel_2.h5\n",
      "711/711 [==============================] - 3s 4ms/step - loss: 36.1913 - val_loss: 36.1813\n",
      "Epoch 45/500\n",
      "709/711 [============================>.] - ETA: 0s - loss: 35.8846\n",
      "Epoch 00045: val_loss improved from 36.18133 to 35.83656, saving model to ../savedModels/VariationalEncoderModel_2.h5\n",
      "711/711 [==============================] - 3s 4ms/step - loss: 35.8813 - val_loss: 35.8366\n",
      "Epoch 46/500\n",
      "704/711 [============================>.] - ETA: 0s - loss: 35.6586\n",
      "Epoch 00046: val_loss improved from 35.83656 to 35.61667, saving model to ../savedModels/VariationalEncoderModel_2.h5\n",
      "711/711 [==============================] - 3s 4ms/step - loss: 35.6570 - val_loss: 35.6167\n",
      "Epoch 47/500\n",
      "707/711 [============================>.] - ETA: 0s - loss: 35.4723\n",
      "Epoch 00047: val_loss improved from 35.61667 to 35.45600, saving model to ../savedModels/VariationalEncoderModel_2.h5\n",
      "711/711 [==============================] - 3s 4ms/step - loss: 35.4665 - val_loss: 35.4560\n",
      "Epoch 48/500\n",
      "702/711 [============================>.] - ETA: 0s - loss: 35.3014\n",
      "Epoch 00048: val_loss improved from 35.45600 to 35.30256, saving model to ../savedModels/VariationalEncoderModel_2.h5\n",
      "711/711 [==============================] - 3s 4ms/step - loss: 35.3014 - val_loss: 35.3026\n",
      "Epoch 49/500\n",
      "708/711 [============================>.] - ETA: 0s - loss: 35.1351\n",
      "Epoch 00049: val_loss improved from 35.30256 to 35.09921, saving model to ../savedModels/VariationalEncoderModel_2.h5\n",
      "711/711 [==============================] - 3s 4ms/step - loss: 35.1357 - val_loss: 35.0992\n",
      "Epoch 50/500\n",
      "707/711 [============================>.] - ETA: 0s - loss: 34.9297\n",
      "Epoch 00050: val_loss improved from 35.09921 to 34.86952, saving model to ../savedModels/VariationalEncoderModel_2.h5\n",
      "711/711 [==============================] - 3s 4ms/step - loss: 34.9329 - val_loss: 34.8695\n",
      "Epoch 51/500\n",
      "710/711 [============================>.] - ETA: 0s - loss: 34.7133\n",
      "Epoch 00051: val_loss improved from 34.86952 to 34.62662, saving model to ../savedModels/VariationalEncoderModel_2.h5\n",
      "711/711 [==============================] - 3s 4ms/step - loss: 34.7115 - val_loss: 34.6266\n",
      "Epoch 52/500\n",
      "703/711 [============================>.] - ETA: 0s - loss: 34.4841\n",
      "Epoch 00052: val_loss improved from 34.62662 to 34.42563, saving model to ../savedModels/VariationalEncoderModel_2.h5\n",
      "711/711 [==============================] - 3s 4ms/step - loss: 34.4830 - val_loss: 34.4256\n",
      "Epoch 53/500\n",
      "701/711 [============================>.] - ETA: 0s - loss: 34.2799\n",
      "Epoch 00053: val_loss improved from 34.42563 to 34.28000, saving model to ../savedModels/VariationalEncoderModel_2.h5\n",
      "711/711 [==============================] - 3s 4ms/step - loss: 34.2778 - val_loss: 34.2800\n",
      "Epoch 54/500\n",
      "702/711 [============================>.] - ETA: 0s - loss: 34.1271\n",
      "Epoch 00054: val_loss improved from 34.28000 to 34.11866, saving model to ../savedModels/VariationalEncoderModel_2.h5\n",
      "711/711 [==============================] - 3s 4ms/step - loss: 34.1252 - val_loss: 34.1187\n",
      "Epoch 55/500\n",
      "702/711 [============================>.] - ETA: 0s - loss: 34.0048\n",
      "Epoch 00055: val_loss improved from 34.11866 to 34.01766, saving model to ../savedModels/VariationalEncoderModel_2.h5\n",
      "711/711 [==============================] - 3s 4ms/step - loss: 34.0037 - val_loss: 34.0177\n",
      "Epoch 56/500\n",
      "698/711 [============================>.] - ETA: 0s - loss: 33.8954\n",
      "Epoch 00056: val_loss improved from 34.01766 to 33.95015, saving model to ../savedModels/VariationalEncoderModel_2.h5\n",
      "711/711 [==============================] - 3s 4ms/step - loss: 33.8931 - val_loss: 33.9501\n",
      "Epoch 57/500\n",
      "699/711 [============================>.] - ETA: 0s - loss: 33.7942\n",
      "Epoch 00057: val_loss improved from 33.95015 to 33.80333, saving model to ../savedModels/VariationalEncoderModel_2.h5\n",
      "711/711 [==============================] - 3s 4ms/step - loss: 33.7936 - val_loss: 33.8033\n",
      "Epoch 58/500\n",
      "699/711 [============================>.] - ETA: 0s - loss: 33.7069\n",
      "Epoch 00058: val_loss improved from 33.80333 to 33.68774, saving model to ../savedModels/VariationalEncoderModel_2.h5\n",
      "711/711 [==============================] - 3s 4ms/step - loss: 33.7057 - val_loss: 33.6877\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 59/500\n",
      "709/711 [============================>.] - ETA: 0s - loss: 33.5873\n",
      "Epoch 00059: val_loss improved from 33.68774 to 33.61109, saving model to ../savedModels/VariationalEncoderModel_2.h5\n",
      "711/711 [==============================] - 3s 4ms/step - loss: 33.5866 - val_loss: 33.6111\n",
      "Epoch 60/500\n",
      "710/711 [============================>.] - ETA: 0s - loss: 33.5035\n",
      "Epoch 00060: val_loss did not improve from 33.61109\n",
      "711/711 [==============================] - 3s 4ms/step - loss: 33.5023 - val_loss: 33.7342\n",
      "Epoch 61/500\n",
      "708/711 [============================>.] - ETA: 0s - loss: 33.4175\n",
      "Epoch 00061: val_loss improved from 33.61109 to 33.45820, saving model to ../savedModels/VariationalEncoderModel_2.h5\n",
      "711/711 [==============================] - 3s 4ms/step - loss: 33.4166 - val_loss: 33.4582\n",
      "Epoch 62/500\n",
      "706/711 [============================>.] - ETA: 0s - loss: 33.3496\n",
      "Epoch 00062: val_loss improved from 33.45820 to 33.41706, saving model to ../savedModels/VariationalEncoderModel_2.h5\n",
      "711/711 [==============================] - 3s 4ms/step - loss: 33.3527 - val_loss: 33.4171\n",
      "Epoch 63/500\n",
      "710/711 [============================>.] - ETA: 0s - loss: 33.2742\n",
      "Epoch 00063: val_loss improved from 33.41706 to 33.29099, saving model to ../savedModels/VariationalEncoderModel_2.h5\n",
      "711/711 [==============================] - 3s 4ms/step - loss: 33.2741 - val_loss: 33.2910\n",
      "Epoch 64/500\n",
      "705/711 [============================>.] - ETA: 0s - loss: 33.2174\n",
      "Epoch 00064: val_loss improved from 33.29099 to 33.26331, saving model to ../savedModels/VariationalEncoderModel_2.h5\n",
      "711/711 [==============================] - 3s 4ms/step - loss: 33.2174 - val_loss: 33.2633\n",
      "Epoch 65/500\n",
      "698/711 [============================>.] - ETA: 0s - loss: 33.1706\n",
      "Epoch 00065: val_loss improved from 33.26331 to 33.19639, saving model to ../savedModels/VariationalEncoderModel_2.h5\n",
      "711/711 [==============================] - 3s 4ms/step - loss: 33.1643 - val_loss: 33.1964\n",
      "Epoch 66/500\n",
      "705/711 [============================>.] - ETA: 0s - loss: 33.1038\n",
      "Epoch 00066: val_loss improved from 33.19639 to 33.15207, saving model to ../savedModels/VariationalEncoderModel_2.h5\n",
      "711/711 [==============================] - 3s 4ms/step - loss: 33.1103 - val_loss: 33.1521\n",
      "Epoch 67/500\n",
      "708/711 [============================>.] - ETA: 0s - loss: 33.0636\n",
      "Epoch 00067: val_loss improved from 33.15207 to 33.11419, saving model to ../savedModels/VariationalEncoderModel_2.h5\n",
      "711/711 [==============================] - 3s 4ms/step - loss: 33.0619 - val_loss: 33.1142\n",
      "Epoch 68/500\n",
      "709/711 [============================>.] - ETA: 0s - loss: 33.0307\n",
      "Epoch 00068: val_loss improved from 33.11419 to 33.05779, saving model to ../savedModels/VariationalEncoderModel_2.h5\n",
      "711/711 [==============================] - 3s 4ms/step - loss: 33.0329 - val_loss: 33.0578\n",
      "Epoch 69/500\n",
      "710/711 [============================>.] - ETA: 0s - loss: 33.0001\n",
      "Epoch 00069: val_loss improved from 33.05779 to 33.05213, saving model to ../savedModels/VariationalEncoderModel_2.h5\n",
      "711/711 [==============================] - 3s 4ms/step - loss: 33.0003 - val_loss: 33.0521\n",
      "Epoch 70/500\n",
      "702/711 [============================>.] - ETA: 0s - loss: 32.9630\n",
      "Epoch 00070: val_loss improved from 33.05213 to 32.98158, saving model to ../savedModels/VariationalEncoderModel_2.h5\n",
      "711/711 [==============================] - 3s 4ms/step - loss: 32.9573 - val_loss: 32.9816\n",
      "Epoch 71/500\n",
      "711/711 [==============================] - ETA: 0s - loss: 32.9231\n",
      "Epoch 00071: val_loss improved from 32.98158 to 32.94060, saving model to ../savedModels/VariationalEncoderModel_2.h5\n",
      "711/711 [==============================] - 3s 4ms/step - loss: 32.9231 - val_loss: 32.9406\n",
      "Epoch 72/500\n",
      "708/711 [============================>.] - ETA: 0s - loss: 32.8652\n",
      "Epoch 00072: val_loss improved from 32.94060 to 32.86858, saving model to ../savedModels/VariationalEncoderModel_2.h5\n",
      "711/711 [==============================] - 3s 4ms/step - loss: 32.8626 - val_loss: 32.8686\n",
      "Epoch 73/500\n",
      "701/711 [============================>.] - ETA: 0s - loss: 32.8045\n",
      "Epoch 00073: val_loss improved from 32.86858 to 32.84478, saving model to ../savedModels/VariationalEncoderModel_2.h5\n",
      "711/711 [==============================] - 3s 4ms/step - loss: 32.8013 - val_loss: 32.8448\n",
      "Epoch 74/500\n",
      "706/711 [============================>.] - ETA: 0s - loss: 32.7482\n",
      "Epoch 00074: val_loss improved from 32.84478 to 32.76433, saving model to ../savedModels/VariationalEncoderModel_2.h5\n",
      "711/711 [==============================] - 3s 4ms/step - loss: 32.7569 - val_loss: 32.7643\n",
      "Epoch 75/500\n",
      "701/711 [============================>.] - ETA: 0s - loss: 32.6946\n",
      "Epoch 00075: val_loss improved from 32.76433 to 32.73304, saving model to ../savedModels/VariationalEncoderModel_2.h5\n",
      "711/711 [==============================] - 3s 4ms/step - loss: 32.6950 - val_loss: 32.7330\n",
      "Epoch 76/500\n",
      "701/711 [============================>.] - ETA: 0s - loss: 32.6543\n",
      "Epoch 00076: val_loss improved from 32.73304 to 32.71221, saving model to ../savedModels/VariationalEncoderModel_2.h5\n",
      "711/711 [==============================] - 3s 4ms/step - loss: 32.6493 - val_loss: 32.7122\n",
      "Epoch 77/500\n",
      "702/711 [============================>.] - ETA: 0s - loss: 32.6212\n",
      "Epoch 00077: val_loss did not improve from 32.71221\n",
      "711/711 [==============================] - 3s 4ms/step - loss: 32.6245 - val_loss: 32.7158\n",
      "Epoch 78/500\n",
      "711/711 [==============================] - ETA: 0s - loss: 32.5884\n",
      "Epoch 00078: val_loss improved from 32.71221 to 32.66611, saving model to ../savedModels/VariationalEncoderModel_2.h5\n",
      "711/711 [==============================] - 3s 4ms/step - loss: 32.5884 - val_loss: 32.6661\n",
      "Epoch 79/500\n",
      "702/711 [============================>.] - ETA: 0s - loss: 32.5793\n",
      "Epoch 00079: val_loss improved from 32.66611 to 32.62580, saving model to ../savedModels/VariationalEncoderModel_2.h5\n",
      "711/711 [==============================] - 3s 4ms/step - loss: 32.5719 - val_loss: 32.6258\n",
      "Epoch 80/500\n",
      "710/711 [============================>.] - ETA: 0s - loss: 32.5502\n",
      "Epoch 00080: val_loss improved from 32.62580 to 32.60682, saving model to ../savedModels/VariationalEncoderModel_2.h5\n",
      "711/711 [==============================] - 3s 4ms/step - loss: 32.5495 - val_loss: 32.6068\n",
      "Epoch 81/500\n",
      "705/711 [============================>.] - ETA: 0s - loss: 32.5238\n",
      "Epoch 00081: val_loss improved from 32.60682 to 32.60270, saving model to ../savedModels/VariationalEncoderModel_2.h5\n",
      "711/711 [==============================] - 3s 4ms/step - loss: 32.5248 - val_loss: 32.6027\n",
      "Epoch 82/500\n",
      "701/711 [============================>.] - ETA: 0s - loss: 32.5432\n",
      "Epoch 00082: val_loss improved from 32.60270 to 32.59308, saving model to ../savedModels/VariationalEncoderModel_2.h5\n",
      "711/711 [==============================] - 3s 4ms/step - loss: 32.5462 - val_loss: 32.5931\n",
      "Epoch 83/500\n",
      "699/711 [============================>.] - ETA: 0s - loss: 32.5087\n",
      "Epoch 00083: val_loss did not improve from 32.59308\n",
      "711/711 [==============================] - 3s 4ms/step - loss: 32.5080 - val_loss: 32.6404\n",
      "Epoch 84/500\n",
      "707/711 [============================>.] - ETA: 0s - loss: 32.4756\n",
      "Epoch 00084: val_loss improved from 32.59308 to 32.55689, saving model to ../savedModels/VariationalEncoderModel_2.h5\n",
      "711/711 [==============================] - 3s 4ms/step - loss: 32.4794 - val_loss: 32.5569\n",
      "Epoch 85/500\n",
      "711/711 [==============================] - ETA: 0s - loss: 32.4698\n",
      "Epoch 00085: val_loss did not improve from 32.55689\n",
      "711/711 [==============================] - 3s 4ms/step - loss: 32.4698 - val_loss: 32.5644\n",
      "Epoch 86/500\n",
      "698/711 [============================>.] - ETA: 0s - loss: 32.4544\n",
      "Epoch 00086: val_loss improved from 32.55689 to 32.48016, saving model to ../savedModels/VariationalEncoderModel_2.h5\n",
      "711/711 [==============================] - 3s 4ms/step - loss: 32.4639 - val_loss: 32.4802\n",
      "Epoch 87/500\n",
      "701/711 [============================>.] - ETA: 0s - loss: 32.4338\n",
      "Epoch 00087: val_loss did not improve from 32.48016\n",
      "711/711 [==============================] - 3s 4ms/step - loss: 32.4350 - val_loss: 32.6486\n",
      "Epoch 88/500\n",
      "699/711 [============================>.] - ETA: 0s - loss: 32.4291\n",
      "Epoch 00088: val_loss did not improve from 32.48016\n",
      "711/711 [==============================] - 3s 4ms/step - loss: 32.4243 - val_loss: 32.4844\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 89/500\n",
      "698/711 [============================>.] - ETA: 0s - loss: 32.4080\n",
      "Epoch 00089: val_loss did not improve from 32.48016\n",
      "711/711 [==============================] - 3s 4ms/step - loss: 32.4095 - val_loss: 32.5155\n",
      "Epoch 90/500\n",
      "711/711 [==============================] - ETA: 0s - loss: 32.3942\n",
      "Epoch 00090: val_loss did not improve from 32.48016\n",
      "711/711 [==============================] - 3s 4ms/step - loss: 32.3942 - val_loss: 32.5202\n",
      "Epoch 91/500\n",
      "703/711 [============================>.] - ETA: 0s - loss: 32.3912\n",
      "Epoch 00091: val_loss improved from 32.48016 to 32.46402, saving model to ../savedModels/VariationalEncoderModel_2.h5\n",
      "711/711 [==============================] - 3s 4ms/step - loss: 32.3888 - val_loss: 32.4640\n",
      "Epoch 92/500\n",
      "703/711 [============================>.] - ETA: 0s - loss: 32.3788\n",
      "Epoch 00092: val_loss improved from 32.46402 to 32.44158, saving model to ../savedModels/VariationalEncoderModel_2.h5\n",
      "711/711 [==============================] - 3s 4ms/step - loss: 32.3827 - val_loss: 32.4416\n",
      "Epoch 93/500\n",
      "711/711 [==============================] - ETA: 0s - loss: 32.3518\n",
      "Epoch 00093: val_loss improved from 32.44158 to 32.39180, saving model to ../savedModels/VariationalEncoderModel_2.h5\n",
      "711/711 [==============================] - 3s 4ms/step - loss: 32.3518 - val_loss: 32.3918\n",
      "Epoch 94/500\n",
      "706/711 [============================>.] - ETA: 0s - loss: 32.3397\n",
      "Epoch 00094: val_loss did not improve from 32.39180\n",
      "711/711 [==============================] - 3s 4ms/step - loss: 32.3350 - val_loss: 32.4583\n",
      "Epoch 95/500\n",
      "709/711 [============================>.] - ETA: 0s - loss: 32.3206\n",
      "Epoch 00095: val_loss did not improve from 32.39180\n",
      "711/711 [==============================] - 3s 4ms/step - loss: 32.3199 - val_loss: 32.3993\n",
      "Epoch 96/500\n",
      "709/711 [============================>.] - ETA: 0s - loss: 32.3086\n",
      "Epoch 00096: val_loss did not improve from 32.39180\n",
      "711/711 [==============================] - 3s 4ms/step - loss: 32.3088 - val_loss: 32.4020\n",
      "Epoch 97/500\n",
      "701/711 [============================>.] - ETA: 0s - loss: 32.2849\n",
      "Epoch 00097: val_loss improved from 32.39180 to 32.36382, saving model to ../savedModels/VariationalEncoderModel_2.h5\n",
      "711/711 [==============================] - 3s 4ms/step - loss: 32.2850 - val_loss: 32.3638\n",
      "Epoch 98/500\n",
      "707/711 [============================>.] - ETA: 0s - loss: 32.2819\n",
      "Epoch 00098: val_loss improved from 32.36382 to 32.34366, saving model to ../savedModels/VariationalEncoderModel_2.h5\n",
      "711/711 [==============================] - 3s 4ms/step - loss: 32.2826 - val_loss: 32.3437\n",
      "Epoch 99/500\n",
      "710/711 [============================>.] - ETA: 0s - loss: 32.2680\n",
      "Epoch 00099: val_loss improved from 32.34366 to 32.33495, saving model to ../savedModels/VariationalEncoderModel_2.h5\n",
      "711/711 [==============================] - 3s 4ms/step - loss: 32.2659 - val_loss: 32.3350\n",
      "Epoch 100/500\n",
      "702/711 [============================>.] - ETA: 0s - loss: 32.2683\n",
      "Epoch 00100: val_loss did not improve from 32.33495\n",
      "711/711 [==============================] - 3s 4ms/step - loss: 32.2641 - val_loss: 32.3516\n",
      "Epoch 101/500\n",
      "702/711 [============================>.] - ETA: 0s - loss: 32.2495\n",
      "Epoch 00101: val_loss did not improve from 32.33495\n",
      "711/711 [==============================] - 3s 4ms/step - loss: 32.2481 - val_loss: 32.3350\n",
      "Epoch 102/500\n",
      "700/711 [============================>.] - ETA: 0s - loss: 32.2378\n",
      "Epoch 00102: val_loss did not improve from 32.33495\n",
      "711/711 [==============================] - 3s 4ms/step - loss: 32.2385 - val_loss: 32.4046\n",
      "Epoch 103/500\n",
      "699/711 [============================>.] - ETA: 0s - loss: 32.2226\n",
      "Epoch 00103: val_loss improved from 32.33495 to 32.29400, saving model to ../savedModels/VariationalEncoderModel_2.h5\n",
      "711/711 [==============================] - 3s 4ms/step - loss: 32.2178 - val_loss: 32.2940\n",
      "Epoch 104/500\n",
      "698/711 [============================>.] - ETA: 0s - loss: 32.2067\n",
      "Epoch 00104: val_loss did not improve from 32.29400\n",
      "711/711 [==============================] - 3s 4ms/step - loss: 32.2083 - val_loss: 32.3508\n",
      "Epoch 105/500\n",
      "704/711 [============================>.] - ETA: 0s - loss: 32.2029\n",
      "Epoch 00105: val_loss improved from 32.29400 to 32.27949, saving model to ../savedModels/VariationalEncoderModel_2.h5\n",
      "711/711 [==============================] - 3s 4ms/step - loss: 32.2028 - val_loss: 32.2795\n",
      "Epoch 106/500\n",
      "708/711 [============================>.] - ETA: 0s - loss: 32.1850\n",
      "Epoch 00106: val_loss improved from 32.27949 to 32.25871, saving model to ../savedModels/VariationalEncoderModel_2.h5\n",
      "711/711 [==============================] - 3s 4ms/step - loss: 32.1805 - val_loss: 32.2587\n",
      "Epoch 107/500\n",
      "711/711 [==============================] - ETA: 0s - loss: 32.1685\n",
      "Epoch 00107: val_loss did not improve from 32.25871\n",
      "711/711 [==============================] - 3s 4ms/step - loss: 32.1685 - val_loss: 32.2814\n",
      "Epoch 108/500\n",
      "701/711 [============================>.] - ETA: 0s - loss: 32.1494\n",
      "Epoch 00108: val_loss improved from 32.25871 to 32.23775, saving model to ../savedModels/VariationalEncoderModel_2.h5\n",
      "711/711 [==============================] - 3s 4ms/step - loss: 32.1469 - val_loss: 32.2378\n",
      "Epoch 109/500\n",
      "701/711 [============================>.] - ETA: 0s - loss: 32.1595\n",
      "Epoch 00109: val_loss improved from 32.23775 to 32.19914, saving model to ../savedModels/VariationalEncoderModel_2.h5\n",
      "711/711 [==============================] - 3s 4ms/step - loss: 32.1521 - val_loss: 32.1991\n",
      "Epoch 110/500\n",
      "705/711 [============================>.] - ETA: 0s - loss: 32.1241\n",
      "Epoch 00110: val_loss did not improve from 32.19914\n",
      "711/711 [==============================] - 3s 4ms/step - loss: 32.1206 - val_loss: 32.2034\n",
      "Epoch 111/500\n",
      "705/711 [============================>.] - ETA: 0s - loss: 32.1205\n",
      "Epoch 00111: val_loss improved from 32.19914 to 32.17965, saving model to ../savedModels/VariationalEncoderModel_2.h5\n",
      "711/711 [==============================] - 3s 4ms/step - loss: 32.1199 - val_loss: 32.1796\n",
      "Epoch 112/500\n",
      "707/711 [============================>.] - ETA: 0s - loss: 32.1084\n",
      "Epoch 00112: val_loss improved from 32.17965 to 32.17413, saving model to ../savedModels/VariationalEncoderModel_2.h5\n",
      "711/711 [==============================] - 3s 4ms/step - loss: 32.1111 - val_loss: 32.1741\n",
      "Epoch 113/500\n",
      "705/711 [============================>.] - ETA: 0s - loss: 32.0841\n",
      "Epoch 00113: val_loss improved from 32.17413 to 32.15419, saving model to ../savedModels/VariationalEncoderModel_2.h5\n",
      "711/711 [==============================] - 3s 4ms/step - loss: 32.0880 - val_loss: 32.1542\n",
      "Epoch 114/500\n",
      "707/711 [============================>.] - ETA: 0s - loss: 32.0814\n",
      "Epoch 00114: val_loss did not improve from 32.15419\n",
      "711/711 [==============================] - 3s 4ms/step - loss: 32.0816 - val_loss: 32.3137\n",
      "Epoch 115/500\n",
      "705/711 [============================>.] - ETA: 0s - loss: 32.1108\n",
      "Epoch 00115: val_loss did not improve from 32.15419\n",
      "711/711 [==============================] - 3s 4ms/step - loss: 32.1108 - val_loss: 32.1783\n",
      "Epoch 116/500\n",
      "707/711 [============================>.] - ETA: 0s - loss: 32.0614\n",
      "Epoch 00116: val_loss improved from 32.15419 to 32.08329, saving model to ../savedModels/VariationalEncoderModel_2.h5\n",
      "711/711 [==============================] - 3s 4ms/step - loss: 32.0607 - val_loss: 32.0833\n",
      "Epoch 117/500\n",
      "707/711 [============================>.] - ETA: 0s - loss: 32.0466\n",
      "Epoch 00117: val_loss did not improve from 32.08329\n",
      "711/711 [==============================] - 3s 4ms/step - loss: 32.0461 - val_loss: 32.1584\n",
      "Epoch 118/500\n",
      "702/711 [============================>.] - ETA: 0s - loss: 32.0406\n",
      "Epoch 00118: val_loss did not improve from 32.08329\n",
      "711/711 [==============================] - 3s 4ms/step - loss: 32.0365 - val_loss: 32.1206\n",
      "Epoch 119/500\n",
      "702/711 [============================>.] - ETA: 0s - loss: 32.0307\n",
      "Epoch 00119: val_loss did not improve from 32.08329\n",
      "711/711 [==============================] - 3s 4ms/step - loss: 32.0232 - val_loss: 32.1523\n",
      "Epoch 120/500\n",
      "702/711 [============================>.] - ETA: 0s - loss: 32.0130\n",
      "Epoch 00120: val_loss improved from 32.08329 to 32.07141, saving model to ../savedModels/VariationalEncoderModel_2.h5\n",
      "711/711 [==============================] - 3s 4ms/step - loss: 32.0166 - val_loss: 32.0714\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 121/500\n",
      "703/711 [============================>.] - ETA: 0s - loss: 32.0114\n",
      "Epoch 00121: val_loss improved from 32.07141 to 32.06533, saving model to ../savedModels/VariationalEncoderModel_2.h5\n",
      "711/711 [==============================] - 3s 4ms/step - loss: 32.0144 - val_loss: 32.0653\n",
      "Epoch 122/500\n",
      "708/711 [============================>.] - ETA: 0s - loss: 32.0009\n",
      "Epoch 00122: val_loss improved from 32.06533 to 32.04026, saving model to ../savedModels/VariationalEncoderModel_2.h5\n",
      "711/711 [==============================] - 3s 4ms/step - loss: 32.0030 - val_loss: 32.0403\n",
      "Epoch 123/500\n",
      "701/711 [============================>.] - ETA: 0s - loss: 32.0012\n",
      "Epoch 00123: val_loss improved from 32.04026 to 32.03185, saving model to ../savedModels/VariationalEncoderModel_2.h5\n",
      "711/711 [==============================] - 3s 4ms/step - loss: 31.9965 - val_loss: 32.0319\n",
      "Epoch 124/500\n",
      "699/711 [============================>.] - ETA: 0s - loss: 32.0085\n",
      "Epoch 00124: val_loss did not improve from 32.03185\n",
      "711/711 [==============================] - 3s 4ms/step - loss: 32.0042 - val_loss: 32.1276\n",
      "Epoch 125/500\n",
      "704/711 [============================>.] - ETA: 0s - loss: 31.9842\n",
      "Epoch 00125: val_loss did not improve from 32.03185\n",
      "711/711 [==============================] - 3s 4ms/step - loss: 31.9875 - val_loss: 32.0520\n",
      "Epoch 126/500\n",
      "699/711 [============================>.] - ETA: 0s - loss: 31.9809\n",
      "Epoch 00126: val_loss did not improve from 32.03185\n",
      "711/711 [==============================] - 3s 4ms/step - loss: 31.9802 - val_loss: 32.0819\n",
      "Epoch 127/500\n",
      "697/711 [============================>.] - ETA: 0s - loss: 31.9743\n",
      "Epoch 00127: val_loss did not improve from 32.03185\n",
      "711/711 [==============================] - 3s 4ms/step - loss: 31.9661 - val_loss: 32.0879\n",
      "Epoch 128/500\n",
      "709/711 [============================>.] - ETA: 0s - loss: 31.9430\n",
      "Epoch 00128: val_loss did not improve from 32.03185\n",
      "711/711 [==============================] - 3s 4ms/step - loss: 31.9422 - val_loss: 32.0791\n",
      "Epoch 129/500\n",
      "710/711 [============================>.] - ETA: 0s - loss: 31.9495\n",
      "Epoch 00129: val_loss improved from 32.03185 to 32.02134, saving model to ../savedModels/VariationalEncoderModel_2.h5\n",
      "711/711 [==============================] - 3s 4ms/step - loss: 31.9480 - val_loss: 32.0213\n",
      "Epoch 130/500\n",
      "704/711 [============================>.] - ETA: 0s - loss: 31.9604\n",
      "Epoch 00130: val_loss improved from 32.02134 to 31.99878, saving model to ../savedModels/VariationalEncoderModel_2.h5\n",
      "711/711 [==============================] - 3s 4ms/step - loss: 31.9556 - val_loss: 31.9988\n",
      "Epoch 131/500\n",
      "706/711 [============================>.] - ETA: 0s - loss: 31.9320\n",
      "Epoch 00131: val_loss improved from 31.99878 to 31.95000, saving model to ../savedModels/VariationalEncoderModel_2.h5\n",
      "711/711 [==============================] - 3s 4ms/step - loss: 31.9296 - val_loss: 31.9500\n",
      "Epoch 132/500\n",
      "709/711 [============================>.] - ETA: 0s - loss: 31.9205\n",
      "Epoch 00132: val_loss did not improve from 31.95000\n",
      "711/711 [==============================] - 3s 4ms/step - loss: 31.9215 - val_loss: 32.0145\n",
      "Epoch 133/500\n",
      "700/711 [============================>.] - ETA: 0s - loss: 31.9146\n",
      "Epoch 00133: val_loss did not improve from 31.95000\n",
      "711/711 [==============================] - 3s 4ms/step - loss: 31.9105 - val_loss: 31.9766\n",
      "Epoch 134/500\n",
      "708/711 [============================>.] - ETA: 0s - loss: 31.9056\n",
      "Epoch 00134: val_loss did not improve from 31.95000\n",
      "711/711 [==============================] - 3s 4ms/step - loss: 31.9067 - val_loss: 32.0665\n",
      "Epoch 135/500\n",
      "700/711 [============================>.] - ETA: 0s - loss: 31.9033\n",
      "Epoch 00135: val_loss did not improve from 31.95000\n",
      "711/711 [==============================] - 3s 4ms/step - loss: 31.9080 - val_loss: 31.9803\n",
      "Epoch 136/500\n",
      "701/711 [============================>.] - ETA: 0s - loss: 31.8710\n",
      "Epoch 00136: val_loss did not improve from 31.95000\n",
      "711/711 [==============================] - 3s 4ms/step - loss: 31.8731 - val_loss: 31.9733\n",
      "Epoch 137/500\n",
      "698/711 [============================>.] - ETA: 0s - loss: 31.8747\n",
      "Epoch 00137: val_loss did not improve from 31.95000\n",
      "711/711 [==============================] - 3s 4ms/step - loss: 31.8744 - val_loss: 31.9899\n",
      "Epoch 138/500\n",
      "699/711 [============================>.] - ETA: 0s - loss: 31.8835\n",
      "Epoch 00138: val_loss improved from 31.95000 to 31.94543, saving model to ../savedModels/VariationalEncoderModel_2.h5\n",
      "711/711 [==============================] - 3s 4ms/step - loss: 31.8825 - val_loss: 31.9454\n",
      "Epoch 139/500\n",
      "707/711 [============================>.] - ETA: 0s - loss: 31.8803\n",
      "Epoch 00139: val_loss did not improve from 31.94543\n",
      "711/711 [==============================] - 3s 4ms/step - loss: 31.8816 - val_loss: 32.0969\n",
      "Epoch 140/500\n",
      "696/711 [============================>.] - ETA: 0s - loss: 31.8715\n",
      "Epoch 00140: val_loss did not improve from 31.94543\n",
      "711/711 [==============================] - 3s 4ms/step - loss: 31.8748 - val_loss: 32.0139\n",
      "Epoch 141/500\n",
      "707/711 [============================>.] - ETA: 0s - loss: 31.8566\n",
      "Epoch 00141: val_loss did not improve from 31.94543\n",
      "711/711 [==============================] - 3s 4ms/step - loss: 31.8603 - val_loss: 31.9513\n",
      "Epoch 142/500\n",
      "710/711 [============================>.] - ETA: 0s - loss: 31.8452\n",
      "Epoch 00142: val_loss improved from 31.94543 to 31.92328, saving model to ../savedModels/VariationalEncoderModel_2.h5\n",
      "711/711 [==============================] - 3s 4ms/step - loss: 31.8458 - val_loss: 31.9233\n",
      "Epoch 143/500\n",
      "705/711 [============================>.] - ETA: 0s - loss: 31.8394\n",
      "Epoch 00143: val_loss improved from 31.92328 to 31.91734, saving model to ../savedModels/VariationalEncoderModel_2.h5\n",
      "711/711 [==============================] - 3s 4ms/step - loss: 31.8450 - val_loss: 31.9173\n",
      "Epoch 144/500\n",
      "710/711 [============================>.] - ETA: 0s - loss: 31.8421\n",
      "Epoch 00144: val_loss did not improve from 31.91734\n",
      "711/711 [==============================] - 3s 4ms/step - loss: 31.8429 - val_loss: 31.9887\n",
      "Epoch 145/500\n",
      "703/711 [============================>.] - ETA: 0s - loss: 31.8309\n",
      "Epoch 00145: val_loss improved from 31.91734 to 31.90421, saving model to ../savedModels/VariationalEncoderModel_2.h5\n",
      "711/711 [==============================] - 3s 4ms/step - loss: 31.8322 - val_loss: 31.9042\n",
      "Epoch 146/500\n",
      "705/711 [============================>.] - ETA: 0s - loss: 31.8322\n",
      "Epoch 00146: val_loss did not improve from 31.90421\n",
      "711/711 [==============================] - 3s 4ms/step - loss: 31.8316 - val_loss: 31.9334\n",
      "Epoch 147/500\n",
      "706/711 [============================>.] - ETA: 0s - loss: 31.8246\n",
      "Epoch 00147: val_loss did not improve from 31.90421\n",
      "711/711 [==============================] - 3s 4ms/step - loss: 31.8216 - val_loss: 31.9046\n",
      "Epoch 148/500\n",
      "706/711 [============================>.] - ETA: 0s - loss: 43.2750\n",
      "Epoch 00148: val_loss did not improve from 31.90421\n",
      "711/711 [==============================] - 3s 4ms/step - loss: 43.2891 - val_loss: 43.9190\n",
      "Epoch 149/500\n",
      "700/711 [============================>.] - ETA: 0s - loss: 41.5063\n",
      "Epoch 00149: val_loss did not improve from 31.90421\n",
      "711/711 [==============================] - 3s 4ms/step - loss: 41.4710 - val_loss: 39.2519\n",
      "Epoch 150/500\n",
      "711/711 [==============================] - ETA: 0s - loss: 38.0577\n",
      "Epoch 00150: val_loss did not improve from 31.90421\n",
      "711/711 [==============================] - 3s 4ms/step - loss: 38.0577 - val_loss: 37.6928\n",
      "Epoch 151/500\n",
      "702/711 [============================>.] - ETA: 0s - loss: 36.6383\n",
      "Epoch 00151: val_loss did not improve from 31.90421\n",
      "711/711 [==============================] - 3s 4ms/step - loss: 36.6315 - val_loss: 36.1967\n",
      "Epoch 152/500\n",
      "704/711 [============================>.] - ETA: 0s - loss: 35.5308\n",
      "Epoch 00152: val_loss did not improve from 31.90421\n",
      "711/711 [==============================] - 3s 4ms/step - loss: 35.5396 - val_loss: 36.3917\n",
      "Epoch 153/500\n",
      "704/711 [============================>.] - ETA: 0s - loss: 34.6764\n",
      "Epoch 00153: val_loss did not improve from 31.90421\n",
      "711/711 [==============================] - 3s 4ms/step - loss: 34.6766 - val_loss: 34.4642\n",
      "Epoch 154/500\n",
      "702/711 [============================>.] - ETA: 0s - loss: 34.0364\n",
      "Epoch 00154: val_loss did not improve from 31.90421\n",
      "711/711 [==============================] - 3s 4ms/step - loss: 34.0267 - val_loss: 33.8733\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 155/500\n",
      "703/711 [============================>.] - ETA: 0s - loss: 33.5255\n",
      "Epoch 00155: val_loss did not improve from 31.90421\n",
      "711/711 [==============================] - 3s 4ms/step - loss: 33.5200 - val_loss: 33.4154\n",
      "Epoch 156/500\n",
      "704/711 [============================>.] - ETA: 0s - loss: 33.1434\n",
      "Epoch 00156: val_loss did not improve from 31.90421\n",
      "711/711 [==============================] - 3s 4ms/step - loss: 33.1366 - val_loss: 33.0443\n",
      "Epoch 157/500\n",
      "708/711 [============================>.] - ETA: 0s - loss: 32.8024\n",
      "Epoch 00157: val_loss did not improve from 31.90421\n",
      "711/711 [==============================] - 3s 4ms/step - loss: 32.8000 - val_loss: 32.7997\n",
      "Epoch 158/500\n",
      "703/711 [============================>.] - ETA: 0s - loss: 32.5179\n",
      "Epoch 00158: val_loss did not improve from 31.90421\n",
      "711/711 [==============================] - 3s 4ms/step - loss: 32.5122 - val_loss: 32.4923\n",
      "Epoch 159/500\n",
      "710/711 [============================>.] - ETA: 0s - loss: 32.3007\n",
      "Epoch 00159: val_loss did not improve from 31.90421\n",
      "711/711 [==============================] - 3s 4ms/step - loss: 32.3032 - val_loss: 32.6178\n",
      "Epoch 160/500\n",
      "699/711 [============================>.] - ETA: 0s - loss: 32.1567\n",
      "Epoch 00160: val_loss did not improve from 31.90421\n",
      "711/711 [==============================] - 3s 4ms/step - loss: 32.1509 - val_loss: 32.2027\n",
      "Epoch 161/500\n",
      "702/711 [============================>.] - ETA: 0s - loss: 32.0447\n",
      "Epoch 00161: val_loss did not improve from 31.90421\n",
      "711/711 [==============================] - 3s 4ms/step - loss: 32.0437 - val_loss: 32.0802\n",
      "Epoch 162/500\n",
      "699/711 [============================>.] - ETA: 0s - loss: 31.9742\n",
      "Epoch 00162: val_loss did not improve from 31.90421\n",
      "711/711 [==============================] - 3s 4ms/step - loss: 31.9796 - val_loss: 32.0268\n",
      "Epoch 163/500\n",
      "698/711 [============================>.] - ETA: 0s - loss: 31.9242\n",
      "Epoch 00163: val_loss did not improve from 31.90421\n",
      "711/711 [==============================] - 3s 4ms/step - loss: 31.9224 - val_loss: 31.9786\n",
      "Epoch 164/500\n",
      "706/711 [============================>.] - ETA: 0s - loss: 31.8808\n",
      "Epoch 00164: val_loss did not improve from 31.90421\n",
      "711/711 [==============================] - 3s 4ms/step - loss: 31.8788 - val_loss: 31.9271\n",
      "Epoch 165/500\n",
      "711/711 [==============================] - ETA: 0s - loss: 31.8499\n",
      "Epoch 00165: val_loss did not improve from 31.90421\n",
      "Restoring model weights from the end of the best epoch.\n",
      "711/711 [==============================] - 3s 4ms/step - loss: 31.8499 - val_loss: 31.9410\n",
      "Epoch 00165: early stopping\n"
     ]
    }
   ],
   "source": [
    "history = VAE.fit(train,epochs=epochs,shuffle=True,\n",
    "                          verbose=1,validation_data=dev,\n",
    "                          callbacks=[checkpoint,earlystop])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_loss(history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/mindy/.venv/tf/lib/python3.6/site-packages/tensorflow/python/ops/linalg/linear_operator_lower_triangular.py:158: calling LinearOperator.__init__ (from tensorflow.python.ops.linalg.linear_operator) with graph_parents is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Do not pass `graph_parents`.  They will  no longer be used.\n"
     ]
    }
   ],
   "source": [
    "encoder, decoder, VAE = create_model(input_size, encoded_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "VAE.load_weights(\"../savedModels/VariationalEncoderModel.h5\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### create monte carlo to generate output log prob score for anomaly prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = pd.read_csv(\"../processedData/hold_outset_moreFraud.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_tf_data, label = test.drop(\"Class\",axis=1).values, test[\"Class\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Model was constructed with shape (None, 5) for input Tensor(\"input_2:0\", shape=(None, 5), dtype=float32), but it was called on an input with incompatible shape (100, 57350, 5).\n"
     ]
    }
   ],
   "source": [
    "x_log_prob = reconstruction_log_prob(test_tf_data,encoder,decoder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYgAAAEXCAYAAAC3c9OwAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjEsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+j8jraAAAdOUlEQVR4nO3debhdVZnn8e+PBAJEZUxZZPIGgmAcQL2FiLSdVkoTJGAjCilEGYo0PkUX+mgjYFV1LIsS5wIF6RRCKKACiEAlGJpJY0plCjRzGMKYMBimhDATePuPvS5sDvvcu++wzz7n3t/nec6Tu4ez9nv2zd3vWWvtvZYiAjMzs0Yb1B2AmZm1JycIMzMr5ARhZmaFnCDMzKyQE4SZmRVygjAzs0JOEGZDTNKBki6voNzpklYNdblDTdJcSWfXHYcNnhOEDXuSQtLUisruSuWP7lkXEedExKeqOJ5ZKzlB2JDKXyg7RSfGXCefr5HDCcIGTdIDkr4p6RbgOUmjJe0q6Y+S1ki6WdL03P5bSjpD0iOSnpZ0cW7b4ZJWSHpK0kJJ43PbQtIRku5J5Z4sSWnbVEm/k7RW0hOSzkvrl6a33yzpWUn79zTVpJgfA86QdLCk3zd8rtdrHpI2kfQjSQ+mY/xe0iZAT/lrUvkfbSxL0m6Srk/vu17SbrltSyR9R9IfJK2TdLmkrUue9/ek96+RdLukvXPbtpK0SNIz6Zj/1Pj5cvv21ILmpN/Jo5K+kds+V9IFks6W9AxwsKTx6ffzVPp9Hd5Q7MaSzkuf6UZJO5X5TNZmIsIvvwb1Ah4AbgImAZsAE4AngT3JvoT8ZVoel/b/NXAesAWwIfBf0/pPAE8AHwLGAD8FluaOE8AlwObAZOBxYEbatgD4VjrexsDuDe+bmlueDqwHvpeOswlwMPD7hs/1+vuAk4El6bONAnZL7+1K+43Ove/1soAtgaeBg4DRwOy0vFXavgS4F3h3imMJcEKT8zwdWJV+3hBYARwHbJTO3Tpgh7T93PTaFJgGrGz8fLlyez7DAmAs8P50bvdI2+cCrwCfTee3JzGeks71zmn/TzTsv1+K8xvA/cCGdf9f9at/L9cgbKicFBErI+IF4IvA4ohYHBGvRcQVwDJgT0nbADOBIyLi6Yh4JSJ+l8o4EDg9Im6MiJeAY4GPSurKHeeEiFgTEQ8BvyW7OEF2QXoXMD4iXoyIwm/LOa8B/zsiXkoxNyVpA+BQ4KiIeDgiXo2IP6YY+/IZ4J6IOCsi1kfEAuBOYFZunzMi4u4Ux/m5z9SbXYG3kZ2PlyPiN2TJc7akUcDn0ud7PiLuAM4sUea3I+K5iLgVOIMsmfW4OiIujojXgK2BjwHfTOf6JuA04Eu5/W+IiAsi4hXgx2SJZNcSMVgbcYKwobIy9/O7gM+npo81ktYAuwPbkNUynoqIpwvKGA882LMQEc+S1Twm5PZ5LPfz82QXSYCjAQHXpeaWQ/uI9/GIeLHE54Lsgrgx2Tf9/nrTZ0oepNxn6qvclemC3VjuOLLaSv53kv+5mfw+D6ZjFG0bT/Y7XFdw7Lfsn2Jc1VCedQAnCBsq+WGBVwJnRcTmudfYiDghbdtS0uYFZTxCllwAkDQW2Ap4uM+DRzwWEYdHxHjgfwCn9HHnUuMwxs+RNcf0HPvPc9ueAF4EtitRTqM3faZkMiU+U4lyJ6XaTWO5j5M1oU3MbZtUosz8PpPTMXrkP+cjZL/Dtxcc+y1lpRgnNpRnHcAJwqpwNjBL0qcljZK0ceoYnhgRjwKXkl3At5C0oaSPp/ctAA6RtLOkMcA/A9dGxAN9HVDS5yX1XBCfJrug9Xy7/hOwbR9F3Ay8Nx17Y7J2dOD1b8CnAz9OnbOjUmf0GLKL8Wu9lL8YeLekv0qd9/uT9Qlc0tdn6sO1ZLWNo9M5nE7WbHVuRLwKXAjMlbSppB15c/NPM3+f9n8vcAhZP9FbRMRK4I/Ad9Pv9gPAYWS/9x4flrSvsjuevgq8BFwzoE9qtXGCsCGXLiD7kHWgPk5Wa/hfvPH/7SCyPoM7gdVkFxAi4krg74FfAY+SfWM/oORh/wK4VtKzwEKy/oL70ra5wJmpuesLTWK+G/hH4ErgHqCxD+MbwK3A9cBTZB3cG0TE88DxwB9S+W9qZ4+IJ4G9gK+TNZcdDewVEU+U/FyFIuJlsoQwk6yGcwrwpYi4M+1yJLAZWfPVWWTJt68+k9+RdXxfBfwwInp72G82Wef2I8BFZP0dV+a2/wewP2900O+b+iOsgyjCEwaZDXeSvgf8eUR8uWBbF2/cZbS+xaFZG3MNwmwYkrSjpA8oswtZE9BFdcdlncVPRJoNT28na1YaT9YH8yOyZh+z0tzEZGZmhdzEZGZmhTq6iWnrrbeOrq6uusMwM+soN9xwwxMRMa6v/To6QXR1dbFs2bK6wzAz6yiSGp/uL+QmJjMzK+QEYWZmhZwgzMysUEcmCEmzJM1bu3Zt3aGYmQ1bHZkgImJRRMzZbLPN6g7FzGzY6sgEYWZm1XOCMDOzQk4QZmZWqKMflLP2MXfu8DyW2UjmGoSZmRVygjAzs0IdmSD8HISZWfU6MkH4OQgzs+p1ZIIwM7PqOUGYmVkhJwgzMyvkBGFmZoWcIMzMrJAThJmZFfJQG8OUh6Mws8FyDcLMzAq1VYKQNFbSMkl71R2LmdlIV2kTk6TTgb2A1RHxvtz6GcCJwCjgtIg4IW36JnB+lTFZ52t185mb62ykqroGMR+YkV8haRRwMjATmAbMljRN0l8CdwCrK47JzMxKqLQGERFLJXU1rN4FWBER9wFIOhfYB3gbMJYsabwgaXFEvFZlfGZm1lwddzFNAFbmllcBH4mIIwEkHQw80Sw5SJoDzAGYPHlytZGamY1gbdVJDRAR8yPikl62z4uI7ojoHjduXCtDMzMbUepIEA8Dk3LLE9O60jwfhJlZ9epIENcD20uaImkj4ABgYX8K8HwQZmbVqzRBSFoAXA3sIGmVpMMiYj1wJHAZsBw4PyJu72e5rkGYmVWs6ruYZjdZvxhYPIhyFwGLuru7Dx9oGWZm1ru266Q2M7P20JEJwk1MZmbV68gE4U5qM7PqdWSCMDOz6nVkgnATk5lZ9ToyQbiJycyseh2ZIMzMrHodOeWopFnArKlTp9YdSmmeU8DMOk1H1iDcxGRmVr2OTBBmZlY9JwgzMyvkBGFmZoU6MkH4OQgzs+p1ZIJwJ7WZWfU6MkGYmVn1nCDMzKyQE4SZmRXqyAThTmozs+p15FAbnnLUWqnVw6R4WBZrFx1ZgzAzs+o5QZiZWSEnCDMzK+QEYWZmhZwgzMyskBOEmZkV6sgE4ecgzMyq15EJwoP1mZlVryMThJmZVc8JwszMCjlBmJlZIScIMzMr5ARhZmaFnCDMzKyQE4SZmRVygjAzs0JOEGZmVqhtEoSk90g6VdIFkr5SdzxmZiNdpQlC0umSVku6rWH9DEl3SVoh6RiAiFgeEUcAXwA+VmVcZmbWt6prEPOBGfkVkkYBJwMzgWnAbEnT0ra9gV8DiyuOy8zM+lBpgoiIpcBTDat3AVZExH0R8TJwLrBP2n9hRMwEDmxWpqQ5kpZJWvb4449XFbqZ2Yg3uoZjTgBW5pZXAR+RNB3YFxhDLzWIiJgHzAPo7u6OgQYxd+5A32lmNjLUkSAKRcQSYEmZfSXNAmZNnTq1ypDMzEa0Ou5iehiYlFuemNaV5vkgzMyqV0eCuB7YXtIUSRsBBwAL+1OAZ5QzM6tenwlC0jpJzzS8Vkq6SNK2fbx3AXA1sIOkVZIOi4j1wJHAZcBy4PyIuL0/QbsGYWZWvTJ9EP9C1pH874DIvvFvB9wInA5Mb/bGiJjdZP1ifCurmVlbK9PEtHdE/J+IWBcRz6S7iD4dEecBW1QcXyE3MZmZVa9Mgnhe0hckbZBeXwBeTNsGfJvpYLiJycysemUSxIHAQcDq9DoI+KKkTcj6EszMbBjqsw8iIu4DZjXZ/PuhDaccPwdhZla9MncxTUx3LK1Or19JmtiK4JpxE5OZWfXKNDGdQfacwvj0WpTWmZnZMFYmQYyLiDMiYn16zQfGVRyXmZnVrMxzEE9K+iKwIC3PBp6sLqS+uQ/ChrNWDyTpgSutmTI1iEPJJvF5DHgU2A84pMqg+uI+CDOz6pW5i+lBYO8WxGJmZm2kaYKQ9FN6eRAuIv62kojMzKwt9FaDWNayKPrJfRBmZtVrmiAi4sxWBtIfEbEIWNTd3X143bGYmQ1XdcwHYWZmHcAJwszMCjlBmJlZoTJjMb1b0lWSbkvLH5D0d9WHZmZmdSpTg/hX4FjgFYCIuIVsVrnaeMIgM7PqlUkQm0bEdQ3r1lcRTFl+ktrMrHplEsQTkrYjPTQnaT+yITfMzGwYKzNY398A84AdJT0M3A98sdKozMysdmVnlNtD0lhgg4hYV31YZmZWtzJ3Mf2zpM0j4rmIWCdpC0n/1IrgzMysPmX6IGZGxJqehYh4GtizupDMzKwdlEkQoySN6VmQtAkwppf9zcxsGCjTSX0OcJWknnmoDwFqHcjPo7mamVWvzxpERHwPOB54T3p9JyK+X3VgfcTk5yDMzCpWpgZBRFwKXFpxLGZm1kbK3MW0r6R7JK2V9IykdZKeaUVwZmZWnzI1iO8DsyJiedXBmJlZ+yhzF9OfnBzMzEaeMjWIZZLOAy4GXupZGREXVhaVmZnVrkyCeAfwPPCp3LoAnCDMzIaxMmMxHdKKQMzMrL14RjkzMyvUVjPKSfqspH+VdJ6kT/X9DjMzq0qZPohNI+I6Sfl1pWeUk3Q6sBewOiLel1s/AzgRGAWcFhEnRMTFwMWStgB+CFxe9jhmNkTmzh1ex7EBa8WMcvOBGfkVkkYBJwMzgWnAbEnTcrv8XdpuZmY1qXxGuYhYKqmrYfUuwIo0GRGSzgX2kbQcOAG4NCJuLCpP0hxgDsDkyZPLhmFmZv1U14xyE4CVueVVwEeA/wnsAWwmaWpEnFoQzzyyhEV3d3cMQSxmnWHJkmrKnVtRudbx+kwQkv6hYRmAiPjHoQ4mIk4CTioRk4f7NjOrWJk+iOdyr1fJ+g26Bnnch4FJueWJaV0pHu7bzKx6ZZqYfpRflvRD4LJBHvd6YHtJU8gSwwHAXw2yTDOzYr4za0DK1CAabUr2jb8USQuAq4EdJK2SdFhErAeOJEs0y4HzI+L2fpQ5S9K8tWvX9jN0MzMrq0wfxK2kW1zJnlkYB5Tuf4iI2U3WLwYWly2n4b2LgEXd3d2HD+T9ZtYGhtm37eGozG2ue+V+Xk82/HfpB+Wq4E5qs6Ezd8n01h1r+pKWHcsGr0wT07rc6wXgHZK27HlVGl0T7qQ2M6temRrEjWR3HD0NCNgceChtC2DbakIzM7M6lalBXEE25ejWEbEVWZPT5RExJSJqSQ7upDYzq16ZBLFr6lAGICIuBXarLqS+uYnJzKx6ZZqYHknzP5ydlg8EHqkuJDMzawdlahCzyW5tvYhsmtFxaZ2ZmQ1jZZ6kfgo4StLYiHiuBTH1ybe5mplVr8yUo7tJuoPsiWck7STplMoj64X7IMzMqlemieknwKeBJwEi4mbg41UGZWZm9SvTSU1ErGyYcvTVasIxM+tgrRw+pAXHKlODWClpNyAkbSjpG6Tmprr4OQgzs+qVSRBHkE07OoFsaO6d03Jt3AdhZla9XpuYJI0CToyIA1sUj5mZtYleaxAR8SrwLkkbtSgeMzNrE2U6qe8D/iBpIdm0owBExI8ri8rMzGpXJkHcm14bAG+vNhwzM2sXTROEpLMi4iBgTUSc2MKY+uQnqc3MqtdbDeLDksYDh0r6N7K5IF6XhuCohacctT4tWdKa40yf3prjmNWgtwRxKnAV2YRAN/DmBOGJgszMhrmmdzFFxEkR8R7g9IjYNk0QNKXOiYLMzKx1+nxQLiK+0opAzMysvZR5ktrMzEYgJwgzMyvkBGFmZoVKDffdbvwcRAdr1e2nrTLcPo9ZTkfWIDyaq5lZ9ToyQZiZWfWcIMzMrJAThJmZFXKCMDOzQh15F5OZdaa5S6a39njTl7T0eMONE4T5Vk0zK+QmJjMzK+QEYWZmhdomQUjaVtIvJF1QdyxmZlZxgpB0uqTVkm5rWD9D0l2SVkg6BiAi7ouIw6qMx8zMyqu6BjEfmJFfIWkUcDIwE5gGzJY0reI4zMysnypNEBGxFGicu3oXYEWqMbwMnAvsU2UcZmbWf3Xc5joBWJlbXgV8RNJWwPHAByUdGxHfLXqzpDnAHIDJkydXHauZdTA/dzE4bfMcREQ8CRxRYr95wDyA7u7uqDouM7ORqo67mB4GJuWWJ6Z1pUmaJWne2rVrhzQwMzN7Qx0J4npge0lTJG0EHAAs7E8Bng/CzKx6Vd/mugC4GthB0ipJh0XEeuBI4DJgOXB+RNzez3JdgzAzq1ilfRARMbvJ+sXA4kGUuwhY1N3dffhAyzAzs961zZPUZmbWXjoyQbiJycyseh2ZINxJbWZWvY5MEGZmVr2OTBBuYjIzq15HJgg3MZmZVa8jE4SZmVWvIxOEm5jMzKrXkQnCTUxmZtXryARhZmbVc4IwM7NCThBmZlaoIxOEO6nNzKrXkQnCndRmZtXryARhZmbVc4IwM7NCThBmZlaoIxOEO6nNzKrXkQnCndRmZtXryARhZmbVc4IwM7NCThBmZlbICcLMzAo5QZiZWSEnCDMzK9SRCcLPQZiZVa8jE4SfgzAzq15HJggzM6ueE4SZmRVygjAzs0JOEGZmVsgJwszMCjlBmJlZIScIMzMr5ARhZmaFnCDMzKzQ6LoD6CFpLHAK8DKwJCLOqTkkM7MRrdIahKTTJa2WdFvD+hmS7pK0QtIxafW+wAURcTiwd5VxmZlZ36puYpoPzMivkDQKOBmYCUwDZkuaBkwEVqbdXq04LjMz60OlTUwRsVRSV8PqXYAVEXEfgKRzgX2AVWRJ4iZ6SVyS5gBzACZPnjz0QbeTJUvqjsDMRrA6Oqkn8EZNAbLEMAG4EPicpJ8Di5q9OSLmRUR3RHSPGzeu2kjNzEawtumkjojngEPK7CtpFjBr6tSp1QZlZjaC1VGDeBiYlFuemNaV5vkgzMyqV0eCuB7YXtIUSRsBBwAL+1OAZ5QzM6te1be5LgCuBnaQtErSYRGxHjgSuAxYDpwfEbf3p1zXIMzMqlf1XUyzm6xfDCyu8thmZjY4HTnUhpuYzMyq15EJwk1MZmbV68gEYWZm1VNE1B3DgEl6HHhwiIrbGnhiiMoaSu0aFzi2gXJsA+PY+q9ZXO+KiD6fNO7oBDGUJC2LiO6642jUrnGBYxsoxzYwjq3/BhuXm5jMzKyQE4SZmRVygnjDvLoDaKJd4wLHNlCObWAcW/8NKi73QZiZWSHXIMzMrJAThJmZFRrRCULSDyTdKekWSRdJ2jy37dg0Z/Zdkj5dU3xFc3fXQtIkSb+VdIek2yUdldZvKekKSfekf7eoKb5Rkv6fpEvS8hRJ16Zzd14aObiOuDaXdEH6f7Zc0kfb6Jx9Lf0ub5O0QNLGdZ23ovnrm50nZU5KMd4i6UM1xNYW146i2HLbvi4pJG2dlvt93kZ0ggCuAN4XER8A7gaOBUhzZB8AvJdsTu1T0lzaLdPL3N11WQ98PSKmAbsCf5PiOQa4KiK2B65Ky3U4imx04B7fA34SEVOBp4HDaokKTgT+b0TsCOxEFmPt50zSBOBvge6IeB8wiuz/fF3nbT4N89fT/DzNBLZPrznAz2uIrV2uHUWxIWkS8Cngodzqfp+3EZ0gIuLyNPw4wDVkkxdBNkf2uRHxUkTcD6wgm0u7lV6fuzsiXgZ65u6uRUQ8GhE3pp/XkV3oJqSYzky7nQl8ttWxSZoIfAY4LS0L+ARwQc1xbQZ8HPgFQES8HBFraINzlowGNpE0GtgUeJSazltELAWealjd7DztA/xbZK4BNpe0TStja5drR5PzBvAT4GggfxdSv8/biE4QDQ4FLk0/N5s3u5XaIYZCkrqADwLXAu+MiEfTpseAd9YQ0r+Q/TG8lpa3Atbk/oDrOndTgMeBM1Lz12mSxtIG5ywiHgZ+SPYN81FgLXAD7XHeejQ7T+32t9FW1w5J+wAPR8TNDZv6HduwTxCSrkxtrI2vfXL7fIusCeWc+iLtDJLeBvwK+GpEPJPfFtk90y29b1rSXsDqiLihlcctaTTwIeDnEfFB4DkampPqOGcAqT1/H7IkNh4YS0FTRbuo6zz1pd2uHZI2BY4D/mEoyqt0wqB2EBF79LZd0sHAXsAn442HQgY9b/YQaIcY3kTShmTJ4ZyIuDCt/pOkbSLi0VRdXd3isD4G7C1pT2Bj4B1k7f6bSxqdvg3Xde5WAasi4tq0fAFZgqj7nAHsAdwfEY8DSLqQ7Fy2w3nr0ew8tcXfRpteO7YjS/o3Zy2tTARulLTLQGIb9jWI3kiaQdY0sXdEPJ/btBA4QNIYSVPIOnWua3F4g567eyildv1fAMsj4se5TQuBL6efvwz8RyvjiohjI2JiRHSRnaPfRMSBwG+B/eqKK8X2GLBS0g5p1SeBO6j5nCUPAbtK2jT9bntiq/285TQ7TwuBL6W7cnYF1uaaolqiXa8dEXFrRPxZRHSlv4lVwIfS/8X+n7eIGLEvsg6klcBN6XVqbtu3gHuBu4CZNcW3J9kdEvcC36r5XO1OVsW/JXe+9iRr778KuAe4EtiyxhinA5ekn7cl+8NcAfwSGFNTTDsDy9J5uxjYol3OGfBt4E7gNuAsYExd5w1YQNYX8kq6qB3W7DwBIrvD717gVrI7sVodW1tcO4pia9j+ALD1QM+bh9owM7NCI7qJyczMmnOCMDOzQk4QZmZWyAnCzMwKOUGYmVkhJwgzMyvkBGG1kfRsReV+VdKXBvC+06oYMVfScQ3LS9J4VpWSNF3SboMs47jczxtJWpoG97MRwAnChpV08ToU+Pf+vjci/joi7hj6qDiu710qMR0YVIIgF3tkowpfBew/yDKtQzhBWO3So/8/SIMo3ipp/7R+A0mnpIlZrpC0WNJ+adsDkr6f9r9O0tRU3CeAGyNivaTRkq6XND2957uSju8ljiWSutPPz0o6XtLNkq6R9M60fr6kUyUtk3R3GiwQSQdL+lmurEvSN/gTyIbUvknSOQ3H6298n0yjwt6qbKKYMblz0TMpTHeuhnIE8LV07P8yRLFfDBzYLEYbXpwgrB3sSzYkxU5kg8j9IA3Oti/QRTZh0kHARxvetzYi3g/8jGzIb8gGnLsBILIB5w4Gfi5pD7LRSr9dMqaxwDURsROwFDg8t62LbIz/zwCnStq4WSERcQzwQkTsHNkYUfltpeNLx5gP7J8+82jgK70c9wHgVLLJf3aOiP8cothvA/6i2XtseHGCsHawO7AgIl6NiD8BvyO7CO0O/DIiXotssLHfNrxvQe7fnuSxDdkcDABExO1k4wxdAhyamknKeDm9B7KE05Xbdn6K6R7gPmDHkmW+RT/i24Fs9NW70/KZZJMR9degYo+IV4GXJb19AMe2DuMEYZ0sCn5+gWzY77z3A2uAP+tH2a/EGwOVvcqbh8ZvHMAsyOYEyP89Nf1mXmAg8eXlj93XcYci9jHAi6Wjs47lBGHt4D+B/SWNkjSO7JvxdcAfgM+lvoh3knW65u2f+/fq9PNyoKc/Akn7AlumMn+q3OTyg/D5FNN2ZKOf3kU2aubOaf0k3jzN5CvK5tJ4i37EdxfQletrOYispkU69ofTz5/LvWcd0PhNf1CxS9oKeCIiXmkSpw0jThDWDi4iGw77ZuA3wNGpSelXZEMY3wGcDdxINjVmjy0k3QIcBXwtrbuU1PSSOm5PAP46Nc38jGwyocF6iCyBXQocEREvkiWz+1OsJ6VYe8wDbinopC4dXzrGIcAvJd1KNr3qqWnzt4ETJS0jq+30WAT8955O6iGK/b8Bv+799Nhw4eG+ra1JeltEPJu+uV4HfCwiHpP0ANl49k8UvOcisiRzTwXxzCebc+KCQZSxBDg4dSS3zBDFfiFwTK4vxIYxP/Bi7e6S1OyyEfCdVLPoyzFkndVDniBGMmUzG17s5DByuAZhI06qYUxpWP3NiLisRcc/mOxCu6bJ9lrjM+vhBGFmZoXcSW1mZoWcIMzMrJAThJmZFXKCMDOzQv8fd6ZtbrgfjcUAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "neg_log_prob(-x_log_prob,label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_roc(label,-x_log_prob)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Choose a threshold that gives a good overall class1 recall "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[56717   141]\n",
      " [  131   361]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00     56858\n",
      "           1       0.72      0.73      0.73       492\n",
      "\n",
      "    accuracy                           1.00     57350\n",
      "   macro avg       0.86      0.87      0.86     57350\n",
      "weighted avg       1.00      1.00      1.00     57350\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model_results(label,-x_log_prob,75)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
