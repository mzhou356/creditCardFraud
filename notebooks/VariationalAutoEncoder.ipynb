{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import numpy as np\n",
    "import pandas as pd \n",
    "import tensorflow_probability as tfp\n",
    "import tensorflow.compat.v2 as tf\n",
    "import matplotlib.pyplot as plt \n",
    "%matplotlib inline\n",
    "from sklearn.metrics import confusion_matrix, classification_report, roc_curve, roc_auc_score\n",
    "sys.path.append(\"/home/mindy/Documents/projects/creditCardFraud/scripts/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfk = tf.keras\n",
    "tfkl=tf.keras.layers\n",
    "tfpl= tfp.layers         # layers for tensor flow probability \n",
    "tfd = tfp.distributions # distribution layer "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from util import *\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/device:GPU:0'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# make sure GPU is running \n",
    "tf.test.gpu_device_name()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import training and dev data and convert to numpy array for NN "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv(\"../processedData/TrainingData_normal.csv\").values\n",
    "dev = pd.read_csv(\"../processedData/DevData_normal.csv\").values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### converting into tf data set to allow simple efficient data pipelines. \n",
    "* In autoencoder, you are predicting the original input x \n",
    "* shuffle and train data in batches with 1000 epochs "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "buffer_size = 10000\n",
    "batch_size = 256\n",
    "epochs = 200\n",
    "input_size = train.shape[1]\n",
    "encoded_size = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = tf.data.Dataset.from_tensor_slices((train,train)).batch(batch_size).prefetch(tf.data.experimental.AUTOTUNE).shuffle(buffer_size)\n",
    "dev = tf.data.Dataset.from_tensor_slices((dev,dev)).batch(batch_size).prefetch(tf.data.experimental.AUTOTUNE).shuffle(buffer_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### set up checkpoint and other settings "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint = tfk.callbacks.ModelCheckpoint(\"../savedModels/VariationalEncoderModel.h5\",verbose=1,save_best_only=True)\n",
    "earlystop = tfk.callbacks.EarlyStopping(monitor=\"val_loss\", mode=\"min\", min_delta=0.001, patience=20, verbose=1, restore_best_weights=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### For variational autoencoder we need to maximize ELBO (evidence lower bound objective):\n",
    "\n",
    "$$ELBO(x)= \\int dzq(z|x)logp(x|z) + \\int dzq(z|x)log\\frac{q(z|x)}{p(z)} $$\n",
    "\n",
    "* p(z): the prior on the latent representation z (last layer of encoder) \n",
    "* q(z|x_input): the encoder (how likely is z given x_input)\n",
    "* p(x_hat|z): the decoder (how likely is x_hat given z) \n",
    "* $\\int dzq(z|x)logp(x|z)$: reconstructin term. (how likely for us to get output_x given input_x and encode to z then decode to x_output) \n",
    "* $\\int dzq(z|x)log\\frac{q(z|x)}{p(z)} $: KL divergence. How similar are the encoder distribution and the prior distribution. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prior distribution for z: \n",
    "\n",
    "* Since this is latent representation (noise has been removed), it is okay to assume multivariate normal distribution with non zero covariance (features are not independent) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "prior = tfd.MultivariateNormalDiag(loc=tf.zeros([encoded_size]),\n",
    "                                  scale_identity_multiplier=1.0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## encoder model for autoencoder:\n",
    "* encoder: 3 layers:\n",
    "  * 3 dense layers \n",
    "  * 3 dimensional multivariable non zero covariance normal distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/mindy/.venv/tf/lib/python3.6/site-packages/tensorflow/python/ops/linalg/linear_operator_lower_triangular.py:158: calling LinearOperator.__init__ (from tensorflow.python.ops.linalg.linear_operator) with graph_parents is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Do not pass `graph_parents`.  They will  no longer be used.\n",
      "Model: \"encoder\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense (Dense)                (None, 20)                620       \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 10)                210       \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 7)                 77        \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 9)                 72        \n",
      "_________________________________________________________________\n",
      "multivariate_normal_tri_l (M ((None, 3), (None, 3))    0         \n",
      "=================================================================\n",
      "Total params: 979\n",
      "Trainable params: 979\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "encoder = tfk.Sequential([\n",
    "    tfkl.InputLayer(input_shape = 30),  # 30 input features \n",
    "    tfkl.Dense(units=20, activation=tf.nn.leaky_relu, activity_regularizer=tfk.regularizers.l1(10e-5)),\n",
    "    tfkl.Dense(units=10, activation=tf.nn.leaky_relu, activity_regularizer=tfk.regularizers.l1(10e-5)),\n",
    "    tfkl.Dense(units=7, activation =tf.nn.leaky_relu, activity_regularizer=tfk.regularizers.l1(10e-5)),\n",
    "    tfkl.Dense(tfpl.MultivariateNormalTriL.params_size(encoded_size),activation=None),\n",
    "    tfpl.MultivariateNormalTriL(encoded_size,activity_regularizer=tfpl.KLDivergenceRegularizer(prior))\n",
    "    ], name=\"encoder\")\n",
    "encoder.summary()    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## decoder model for autoencoder:\n",
    "* decoder: 3 layers:\n",
    "   * 3 dense layers\n",
    "   * independent normal distributions as output "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"decoder\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_4 (Dense)              (None, 7)                 28        \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 10)                80        \n",
      "_________________________________________________________________\n",
      "dense_6 (Dense)              (None, 20)                220       \n",
      "_________________________________________________________________\n",
      "dense_7 (Dense)              (None, 60)                1260      \n",
      "_________________________________________________________________\n",
      "independent_normal (Independ ((None, 30), (None, 30))  0         \n",
      "=================================================================\n",
      "Total params: 1,588\n",
      "Trainable params: 1,588\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "decoder = tfk.Sequential([\n",
    "    tfkl.InputLayer(input_shape=[encoded_size]),\n",
    "    tfkl.Dense(units=7, activation=tf.nn.leaky_relu, activity_regularizer=tfk.regularizers.l1(10e-5)),\n",
    "    tfkl.Dense(units=10, activation=tf.nn.leaky_relu, activity_regularizer=tfk.regularizers.l1(10e-5)),\n",
    "    tfkl.Dense(units=20, activation=tf.nn.leaky_relu, activity_regularizer=tfk.regularizers.l1(10e-5)),\n",
    "    tfkl.Dense(tfpl.IndependentNormal.params_size(input_size),activation=None),\n",
    "    tfpl.IndependentNormal(input_size)\n",
    "    ], name = \"decoder\")\n",
    "decoder.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Add encoders together \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "VAE = tfk.Model(inputs=encoder.inputs, outputs=decoder(encoder.outputs[0]),name=\"VAE\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"VAE\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         [(None, 30)]              0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 20)                620       \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 10)                210       \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 7)                 77        \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 9)                 72        \n",
      "_________________________________________________________________\n",
      "multivariate_normal_tri_l (M ((None, 3), (None, 3))    0         \n",
      "_________________________________________________________________\n",
      "decoder (Sequential)         (None, 30)                1588      \n",
      "=================================================================\n",
      "Total params: 2,567\n",
      "Trainable params: 2,567\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "VAE.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### define reconstruction loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "negloglik = lambda x_input, x_output: -x_output.log_prob(x_input)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### compile the model and train model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "VAE.compile(optimizer=tf.optimizers.Adam(learning_rate=1e-3), loss=negloglik)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "707/711 [============================>.] - ETA: 0s - loss: 57.5664\n",
      "Epoch 00001: val_loss improved from inf to 42.50559, saving model to ../savedModels/VariationalEncoderModel.h5\n",
      "711/711 [==============================] - 4s 5ms/step - loss: 57.4811 - val_loss: 42.5056\n",
      "Epoch 2/200\n",
      "709/711 [============================>.] - ETA: 0s - loss: 39.1914\n",
      "Epoch 00002: val_loss improved from 42.50559 to 36.62857, saving model to ../savedModels/VariationalEncoderModel.h5\n",
      "711/711 [==============================] - 3s 5ms/step - loss: 39.1852 - val_loss: 36.6286\n",
      "Epoch 3/200\n",
      "703/711 [============================>.] - ETA: 0s - loss: 36.0949\n",
      "Epoch 00003: val_loss improved from 36.62857 to 35.79831, saving model to ../savedModels/VariationalEncoderModel.h5\n",
      "711/711 [==============================] - 4s 5ms/step - loss: 36.0838 - val_loss: 35.7983\n",
      "Epoch 4/200\n",
      "707/711 [============================>.] - ETA: 0s - loss: 35.5486\n",
      "Epoch 00004: val_loss improved from 35.79831 to 35.41450, saving model to ../savedModels/VariationalEncoderModel.h5\n",
      "711/711 [==============================] - 3s 5ms/step - loss: 35.5497 - val_loss: 35.4145\n",
      "Epoch 5/200\n",
      "707/711 [============================>.] - ETA: 0s - loss: 35.2329\n",
      "Epoch 00005: val_loss improved from 35.41450 to 35.18483, saving model to ../savedModels/VariationalEncoderModel.h5\n",
      "711/711 [==============================] - 3s 5ms/step - loss: 35.2337 - val_loss: 35.1848\n",
      "Epoch 6/200\n",
      "709/711 [============================>.] - ETA: 0s - loss: 35.0614\n",
      "Epoch 00006: val_loss improved from 35.18483 to 35.03589, saving model to ../savedModels/VariationalEncoderModel.h5\n",
      "711/711 [==============================] - 4s 5ms/step - loss: 35.0626 - val_loss: 35.0359\n",
      "Epoch 7/200\n",
      "709/711 [============================>.] - ETA: 0s - loss: 34.9369\n",
      "Epoch 00007: val_loss improved from 35.03589 to 34.94521, saving model to ../savedModels/VariationalEncoderModel.h5\n",
      "711/711 [==============================] - 3s 5ms/step - loss: 34.9368 - val_loss: 34.9452\n",
      "Epoch 8/200\n",
      "702/711 [============================>.] - ETA: 0s - loss: 34.8179\n",
      "Epoch 00008: val_loss improved from 34.94521 to 34.82312, saving model to ../savedModels/VariationalEncoderModel.h5\n",
      "711/711 [==============================] - 3s 5ms/step - loss: 34.8181 - val_loss: 34.8231\n",
      "Epoch 9/200\n",
      "700/711 [============================>.] - ETA: 0s - loss: 34.7298\n",
      "Epoch 00009: val_loss improved from 34.82312 to 34.73678, saving model to ../savedModels/VariationalEncoderModel.h5\n",
      "711/711 [==============================] - 3s 5ms/step - loss: 34.7294 - val_loss: 34.7368\n",
      "Epoch 10/200\n",
      "711/711 [==============================] - ETA: 0s - loss: 34.6573\n",
      "Epoch 00010: val_loss improved from 34.73678 to 34.67310, saving model to ../savedModels/VariationalEncoderModel.h5\n",
      "711/711 [==============================] - 4s 5ms/step - loss: 34.6573 - val_loss: 34.6731\n",
      "Epoch 11/200\n",
      "710/711 [============================>.] - ETA: 0s - loss: 34.5837\n",
      "Epoch 00011: val_loss improved from 34.67310 to 34.62886, saving model to ../savedModels/VariationalEncoderModel.h5\n",
      "711/711 [==============================] - 3s 5ms/step - loss: 34.5834 - val_loss: 34.6289\n",
      "Epoch 12/200\n",
      "705/711 [============================>.] - ETA: 0s - loss: 34.5146\n",
      "Epoch 00012: val_loss improved from 34.62886 to 34.54119, saving model to ../savedModels/VariationalEncoderModel.h5\n",
      "711/711 [==============================] - 3s 5ms/step - loss: 34.5174 - val_loss: 34.5412\n",
      "Epoch 13/200\n",
      "701/711 [============================>.] - ETA: 0s - loss: 34.4386\n",
      "Epoch 00013: val_loss improved from 34.54119 to 34.48795, saving model to ../savedModels/VariationalEncoderModel.h5\n",
      "711/711 [==============================] - 3s 5ms/step - loss: 34.4416 - val_loss: 34.4880\n",
      "Epoch 14/200\n",
      "702/711 [============================>.] - ETA: 0s - loss: 34.3853\n",
      "Epoch 00014: val_loss improved from 34.48795 to 34.42044, saving model to ../savedModels/VariationalEncoderModel.h5\n",
      "711/711 [==============================] - 3s 5ms/step - loss: 34.3809 - val_loss: 34.4204\n",
      "Epoch 15/200\n",
      "711/711 [==============================] - ETA: 0s - loss: 34.3208\n",
      "Epoch 00015: val_loss improved from 34.42044 to 34.38705, saving model to ../savedModels/VariationalEncoderModel.h5\n",
      "711/711 [==============================] - 3s 5ms/step - loss: 34.3208 - val_loss: 34.3871\n",
      "Epoch 16/200\n",
      "701/711 [============================>.] - ETA: 0s - loss: 34.2866\n",
      "Epoch 00016: val_loss improved from 34.38705 to 34.32732, saving model to ../savedModels/VariationalEncoderModel.h5\n",
      "711/711 [==============================] - 3s 5ms/step - loss: 34.2845 - val_loss: 34.3273\n",
      "Epoch 17/200\n",
      "703/711 [============================>.] - ETA: 0s - loss: 34.2517\n",
      "Epoch 00017: val_loss improved from 34.32732 to 34.30377, saving model to ../savedModels/VariationalEncoderModel.h5\n",
      "711/711 [==============================] - 3s 5ms/step - loss: 34.2501 - val_loss: 34.3038\n",
      "Epoch 18/200\n",
      "709/711 [============================>.] - ETA: 0s - loss: 34.2204\n",
      "Epoch 00018: val_loss improved from 34.30377 to 34.28403, saving model to ../savedModels/VariationalEncoderModel.h5\n",
      "711/711 [==============================] - 4s 5ms/step - loss: 34.2206 - val_loss: 34.2840\n",
      "Epoch 19/200\n",
      "710/711 [============================>.] - ETA: 0s - loss: 34.1984\n",
      "Epoch 00019: val_loss improved from 34.28403 to 34.23456, saving model to ../savedModels/VariationalEncoderModel.h5\n",
      "711/711 [==============================] - 3s 5ms/step - loss: 34.1973 - val_loss: 34.2346\n",
      "Epoch 20/200\n",
      "709/711 [============================>.] - ETA: 0s - loss: 34.1658\n",
      "Epoch 00020: val_loss improved from 34.23456 to 34.20092, saving model to ../savedModels/VariationalEncoderModel.h5\n",
      "711/711 [==============================] - 3s 5ms/step - loss: 34.1668 - val_loss: 34.2009\n",
      "Epoch 21/200\n",
      "703/711 [============================>.] - ETA: 0s - loss: 34.1375\n",
      "Epoch 00021: val_loss improved from 34.20092 to 34.20091, saving model to ../savedModels/VariationalEncoderModel.h5\n",
      "711/711 [==============================] - 3s 5ms/step - loss: 34.1347 - val_loss: 34.2009\n",
      "Epoch 22/200\n",
      "704/711 [============================>.] - ETA: 0s - loss: 34.0961\n",
      "Epoch 00022: val_loss improved from 34.20091 to 34.17271, saving model to ../savedModels/VariationalEncoderModel.h5\n",
      "711/711 [==============================] - 3s 5ms/step - loss: 34.1003 - val_loss: 34.1727\n",
      "Epoch 23/200\n",
      "700/711 [============================>.] - ETA: 0s - loss: 34.0796\n",
      "Epoch 00023: val_loss improved from 34.17271 to 34.13461, saving model to ../savedModels/VariationalEncoderModel.h5\n",
      "711/711 [==============================] - 3s 5ms/step - loss: 34.0774 - val_loss: 34.1346\n",
      "Epoch 24/200\n",
      "707/711 [============================>.] - ETA: 0s - loss: 34.0407\n",
      "Epoch 00024: val_loss improved from 34.13461 to 34.11654, saving model to ../savedModels/VariationalEncoderModel.h5\n",
      "711/711 [==============================] - 3s 5ms/step - loss: 34.0409 - val_loss: 34.1165\n",
      "Epoch 25/200\n",
      "700/711 [============================>.] - ETA: 0s - loss: 34.0126\n",
      "Epoch 00025: val_loss did not improve from 34.11654\n",
      "711/711 [==============================] - 3s 5ms/step - loss: 34.0103 - val_loss: 34.1386\n",
      "Epoch 26/200\n",
      "702/711 [============================>.] - ETA: 0s - loss: 33.9641\n",
      "Epoch 00026: val_loss improved from 34.11654 to 33.99452, saving model to ../savedModels/VariationalEncoderModel.h5\n",
      "711/711 [==============================] - 3s 5ms/step - loss: 33.9667 - val_loss: 33.9945\n",
      "Epoch 27/200\n",
      "711/711 [==============================] - ETA: 0s - loss: 33.9051\n",
      "Epoch 00027: val_loss improved from 33.99452 to 33.94576, saving model to ../savedModels/VariationalEncoderModel.h5\n",
      "711/711 [==============================] - 3s 5ms/step - loss: 33.9051 - val_loss: 33.9458\n",
      "Epoch 28/200\n",
      "709/711 [============================>.] - ETA: 0s - loss: 33.8434\n",
      "Epoch 00028: val_loss improved from 33.94576 to 33.86961, saving model to ../savedModels/VariationalEncoderModel.h5\n",
      "711/711 [==============================] - 3s 5ms/step - loss: 33.8437 - val_loss: 33.8696\n",
      "Epoch 29/200\n",
      "699/711 [============================>.] - ETA: 0s - loss: 33.7905\n",
      "Epoch 00029: val_loss improved from 33.86961 to 33.81993, saving model to ../savedModels/VariationalEncoderModel.h5\n",
      "711/711 [==============================] - 3s 5ms/step - loss: 33.7899 - val_loss: 33.8199\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 30/200\n",
      "700/711 [============================>.] - ETA: 0s - loss: 33.7280\n",
      "Epoch 00030: val_loss improved from 33.81993 to 33.78839, saving model to ../savedModels/VariationalEncoderModel.h5\n",
      "711/711 [==============================] - 4s 5ms/step - loss: 33.7303 - val_loss: 33.7884\n",
      "Epoch 31/200\n",
      "711/711 [==============================] - ETA: 0s - loss: 33.6876\n",
      "Epoch 00031: val_loss improved from 33.78839 to 33.77042, saving model to ../savedModels/VariationalEncoderModel.h5\n",
      "711/711 [==============================] - 3s 5ms/step - loss: 33.6876 - val_loss: 33.7704\n",
      "Epoch 32/200\n",
      "704/711 [============================>.] - ETA: 0s - loss: 33.6655\n",
      "Epoch 00032: val_loss improved from 33.77042 to 33.68986, saving model to ../savedModels/VariationalEncoderModel.h5\n",
      "711/711 [==============================] - 3s 5ms/step - loss: 33.6645 - val_loss: 33.6899\n",
      "Epoch 33/200\n",
      "700/711 [============================>.] - ETA: 0s - loss: 33.6249\n",
      "Epoch 00033: val_loss did not improve from 33.68986\n",
      "711/711 [==============================] - 3s 5ms/step - loss: 33.6260 - val_loss: 33.7079\n",
      "Epoch 34/200\n",
      "701/711 [============================>.] - ETA: 0s - loss: 33.6025\n",
      "Epoch 00034: val_loss improved from 33.68986 to 33.64998, saving model to ../savedModels/VariationalEncoderModel.h5\n",
      "711/711 [==============================] - 3s 5ms/step - loss: 33.6042 - val_loss: 33.6500\n",
      "Epoch 35/200\n",
      "701/711 [============================>.] - ETA: 0s - loss: 33.5695\n",
      "Epoch 00035: val_loss did not improve from 33.64998\n",
      "711/711 [==============================] - 3s 5ms/step - loss: 33.5700 - val_loss: 33.6699\n",
      "Epoch 36/200\n",
      "711/711 [==============================] - ETA: 0s - loss: 33.5443\n",
      "Epoch 00036: val_loss improved from 33.64998 to 33.58471, saving model to ../savedModels/VariationalEncoderModel.h5\n",
      "711/711 [==============================] - 3s 5ms/step - loss: 33.5443 - val_loss: 33.5847\n",
      "Epoch 37/200\n",
      "708/711 [============================>.] - ETA: 0s - loss: 33.5018\n",
      "Epoch 00037: val_loss improved from 33.58471 to 33.51792, saving model to ../savedModels/VariationalEncoderModel.h5\n",
      "711/711 [==============================] - 3s 5ms/step - loss: 33.5009 - val_loss: 33.5179\n",
      "Epoch 38/200\n",
      "705/711 [============================>.] - ETA: 0s - loss: 33.4707\n",
      "Epoch 00038: val_loss improved from 33.51792 to 33.49826, saving model to ../savedModels/VariationalEncoderModel.h5\n",
      "711/711 [==============================] - 3s 5ms/step - loss: 33.4712 - val_loss: 33.4983\n",
      "Epoch 39/200\n",
      "709/711 [============================>.] - ETA: 0s - loss: 33.4103\n",
      "Epoch 00039: val_loss improved from 33.49826 to 33.41341, saving model to ../savedModels/VariationalEncoderModel.h5\n",
      "711/711 [==============================] - 3s 5ms/step - loss: 33.4132 - val_loss: 33.4134\n",
      "Epoch 40/200\n",
      "710/711 [============================>.] - ETA: 0s - loss: 33.3652\n",
      "Epoch 00040: val_loss improved from 33.41341 to 33.39077, saving model to ../savedModels/VariationalEncoderModel.h5\n",
      "711/711 [==============================] - 3s 5ms/step - loss: 33.3658 - val_loss: 33.3908\n",
      "Epoch 41/200\n",
      "705/711 [============================>.] - ETA: 0s - loss: 33.3243\n",
      "Epoch 00041: val_loss improved from 33.39077 to 33.35743, saving model to ../savedModels/VariationalEncoderModel.h5\n",
      "711/711 [==============================] - 3s 5ms/step - loss: 33.3278 - val_loss: 33.3574\n",
      "Epoch 42/200\n",
      "706/711 [============================>.] - ETA: 0s - loss: 33.2660\n",
      "Epoch 00042: val_loss improved from 33.35743 to 33.28979, saving model to ../savedModels/VariationalEncoderModel.h5\n",
      "711/711 [==============================] - 3s 5ms/step - loss: 33.2593 - val_loss: 33.2898\n",
      "Epoch 43/200\n",
      "704/711 [============================>.] - ETA: 0s - loss: 33.2266\n",
      "Epoch 00043: val_loss did not improve from 33.28979\n",
      "711/711 [==============================] - 3s 5ms/step - loss: 33.2247 - val_loss: 33.3148\n",
      "Epoch 44/200\n",
      "711/711 [==============================] - ETA: 0s - loss: 33.1868\n",
      "Epoch 00044: val_loss improved from 33.28979 to 33.20524, saving model to ../savedModels/VariationalEncoderModel.h5\n",
      "711/711 [==============================] - 3s 5ms/step - loss: 33.1868 - val_loss: 33.2052\n",
      "Epoch 45/200\n",
      "707/711 [============================>.] - ETA: 0s - loss: 33.1275\n",
      "Epoch 00045: val_loss did not improve from 33.20524\n",
      "711/711 [==============================] - 3s 5ms/step - loss: 33.1292 - val_loss: 33.2436\n",
      "Epoch 46/200\n",
      "701/711 [============================>.] - ETA: 0s - loss: 33.1398\n",
      "Epoch 00046: val_loss improved from 33.20524 to 33.15718, saving model to ../savedModels/VariationalEncoderModel.h5\n",
      "711/711 [==============================] - 3s 5ms/step - loss: 33.1400 - val_loss: 33.1572\n",
      "Epoch 47/200\n",
      "702/711 [============================>.] - ETA: 0s - loss: 33.1085\n",
      "Epoch 00047: val_loss did not improve from 33.15718\n",
      "711/711 [==============================] - 3s 5ms/step - loss: 33.1027 - val_loss: 33.1936\n",
      "Epoch 48/200\n",
      "699/711 [============================>.] - ETA: 0s - loss: 33.0799\n",
      "Epoch 00048: val_loss improved from 33.15718 to 33.12922, saving model to ../savedModels/VariationalEncoderModel.h5\n",
      "711/711 [==============================] - 3s 5ms/step - loss: 33.0882 - val_loss: 33.1292\n",
      "Epoch 49/200\n",
      "705/711 [============================>.] - ETA: 0s - loss: 33.0867\n",
      "Epoch 00049: val_loss did not improve from 33.12922\n",
      "711/711 [==============================] - 3s 5ms/step - loss: 33.0887 - val_loss: 33.1927\n",
      "Epoch 50/200\n",
      "711/711 [==============================] - ETA: 0s - loss: 33.0728\n",
      "Epoch 00050: val_loss did not improve from 33.12922\n",
      "711/711 [==============================] - 3s 5ms/step - loss: 33.0728 - val_loss: 33.1351\n",
      "Epoch 51/200\n",
      "700/711 [============================>.] - ETA: 0s - loss: 33.0691\n",
      "Epoch 00051: val_loss improved from 33.12922 to 33.09744, saving model to ../savedModels/VariationalEncoderModel.h5\n",
      "711/711 [==============================] - 3s 5ms/step - loss: 33.0634 - val_loss: 33.0974\n",
      "Epoch 52/200\n",
      "703/711 [============================>.] - ETA: 0s - loss: 33.0632\n",
      "Epoch 00052: val_loss did not improve from 33.09744\n",
      "711/711 [==============================] - 3s 5ms/step - loss: 33.0599 - val_loss: 33.2305\n",
      "Epoch 53/200\n",
      "705/711 [============================>.] - ETA: 0s - loss: 33.0499\n",
      "Epoch 00053: val_loss did not improve from 33.09744\n",
      "711/711 [==============================] - 3s 5ms/step - loss: 33.0520 - val_loss: 33.1884\n",
      "Epoch 54/200\n",
      "709/711 [============================>.] - ETA: 0s - loss: 33.0501\n",
      "Epoch 00054: val_loss improved from 33.09744 to 33.08545, saving model to ../savedModels/VariationalEncoderModel.h5\n",
      "711/711 [==============================] - 4s 5ms/step - loss: 33.0503 - val_loss: 33.0855\n",
      "Epoch 55/200\n",
      "709/711 [============================>.] - ETA: 0s - loss: 33.0234\n",
      "Epoch 00055: val_loss improved from 33.08545 to 33.06851, saving model to ../savedModels/VariationalEncoderModel.h5\n",
      "711/711 [==============================] - 4s 5ms/step - loss: 33.0260 - val_loss: 33.0685\n",
      "Epoch 56/200\n",
      "701/711 [============================>.] - ETA: 0s - loss: 33.0006\n",
      "Epoch 00056: val_loss improved from 33.06851 to 33.03666, saving model to ../savedModels/VariationalEncoderModel.h5\n",
      "711/711 [==============================] - 3s 5ms/step - loss: 32.9998 - val_loss: 33.0367\n",
      "Epoch 57/200\n",
      "711/711 [==============================] - ETA: 0s - loss: 32.9879\n",
      "Epoch 00057: val_loss improved from 33.03666 to 33.03172, saving model to ../savedModels/VariationalEncoderModel.h5\n",
      "711/711 [==============================] - 3s 5ms/step - loss: 32.9879 - val_loss: 33.0317\n",
      "Epoch 58/200\n",
      "709/711 [============================>.] - ETA: 0s - loss: 32.9844\n",
      "Epoch 00058: val_loss did not improve from 33.03172\n",
      "711/711 [==============================] - 3s 5ms/step - loss: 32.9833 - val_loss: 33.0695\n",
      "Epoch 59/200\n",
      "701/711 [============================>.] - ETA: 0s - loss: 32.9704\n",
      "Epoch 00059: val_loss did not improve from 33.03172\n",
      "711/711 [==============================] - 3s 5ms/step - loss: 32.9745 - val_loss: 33.0761\n",
      "Epoch 60/200\n",
      "699/711 [============================>.] - ETA: 0s - loss: 32.9817\n",
      "Epoch 00060: val_loss did not improve from 33.03172\n",
      "711/711 [==============================] - 3s 5ms/step - loss: 32.9751 - val_loss: 33.0552\n",
      "Epoch 61/200\n",
      "709/711 [============================>.] - ETA: 0s - loss: 32.9717\n",
      "Epoch 00061: val_loss did not improve from 33.03172\n",
      "711/711 [==============================] - 3s 5ms/step - loss: 32.9718 - val_loss: 33.0433\n",
      "Epoch 62/200\n",
      "704/711 [============================>.] - ETA: 0s - loss: 32.9516\n",
      "Epoch 00062: val_loss improved from 33.03172 to 32.95384, saving model to ../savedModels/VariationalEncoderModel.h5\n",
      "711/711 [==============================] - 3s 5ms/step - loss: 32.9490 - val_loss: 32.9538\n",
      "Epoch 63/200\n",
      "704/711 [============================>.] - ETA: 0s - loss: 32.9680\n",
      "Epoch 00063: val_loss did not improve from 32.95384\n",
      "711/711 [==============================] - 3s 5ms/step - loss: 32.9614 - val_loss: 33.0208\n",
      "Epoch 64/200\n",
      "711/711 [==============================] - ETA: 0s - loss: 32.9337\n",
      "Epoch 00064: val_loss did not improve from 32.95384\n",
      "711/711 [==============================] - 3s 5ms/step - loss: 32.9337 - val_loss: 33.0375\n",
      "Epoch 65/200\n",
      "701/711 [============================>.] - ETA: 0s - loss: 32.9553\n",
      "Epoch 00065: val_loss did not improve from 32.95384\n",
      "711/711 [==============================] - 3s 5ms/step - loss: 32.9513 - val_loss: 33.0410\n",
      "Epoch 66/200\n",
      "707/711 [============================>.] - ETA: 0s - loss: 32.9384\n",
      "Epoch 00066: val_loss did not improve from 32.95384\n",
      "711/711 [==============================] - 3s 5ms/step - loss: 32.9387 - val_loss: 33.0506\n",
      "Epoch 67/200\n",
      "707/711 [============================>.] - ETA: 0s - loss: 32.9565\n",
      "Epoch 00067: val_loss did not improve from 32.95384\n",
      "711/711 [==============================] - 3s 5ms/step - loss: 32.9573 - val_loss: 33.0283\n",
      "Epoch 68/200\n",
      "707/711 [============================>.] - ETA: 0s - loss: 32.9310\n",
      "Epoch 00068: val_loss did not improve from 32.95384\n",
      "711/711 [==============================] - 3s 5ms/step - loss: 32.9343 - val_loss: 33.0288\n",
      "Epoch 69/200\n",
      "704/711 [============================>.] - ETA: 0s - loss: 32.8916\n",
      "Epoch 00069: val_loss did not improve from 32.95384\n",
      "711/711 [==============================] - 3s 5ms/step - loss: 32.8981 - val_loss: 33.0063\n",
      "Epoch 70/200\n",
      "710/711 [============================>.] - ETA: 0s - loss: 32.9178\n",
      "Epoch 00070: val_loss did not improve from 32.95384\n",
      "711/711 [==============================] - 3s 5ms/step - loss: 32.9174 - val_loss: 33.0661\n",
      "Epoch 71/200\n",
      "700/711 [============================>.] - ETA: 0s - loss: 32.9189\n",
      "Epoch 00071: val_loss did not improve from 32.95384\n",
      "711/711 [==============================] - 3s 5ms/step - loss: 32.9182 - val_loss: 33.0235\n",
      "Epoch 72/200\n",
      "705/711 [============================>.] - ETA: 0s - loss: 32.9247\n",
      "Epoch 00072: val_loss improved from 32.95384 to 32.93361, saving model to ../savedModels/VariationalEncoderModel.h5\n",
      "711/711 [==============================] - 4s 5ms/step - loss: 32.9196 - val_loss: 32.9336\n",
      "Epoch 73/200\n",
      "700/711 [============================>.] - ETA: 0s - loss: 32.9314\n",
      "Epoch 00073: val_loss did not improve from 32.93361\n",
      "711/711 [==============================] - 3s 5ms/step - loss: 32.9315 - val_loss: 33.0168\n",
      "Epoch 74/200\n",
      "711/711 [==============================] - ETA: 0s - loss: 32.9661\n",
      "Epoch 00074: val_loss did not improve from 32.93361\n",
      "711/711 [==============================] - 3s 5ms/step - loss: 32.9661 - val_loss: 33.1275\n",
      "Epoch 75/200\n",
      "707/711 [============================>.] - ETA: 0s - loss: 32.9048\n",
      "Epoch 00075: val_loss did not improve from 32.93361\n",
      "711/711 [==============================] - 3s 5ms/step - loss: 32.9024 - val_loss: 32.9756\n",
      "Epoch 76/200\n",
      "708/711 [============================>.] - ETA: 0s - loss: 33.0018\n",
      "Epoch 00076: val_loss did not improve from 32.93361\n",
      "711/711 [==============================] - 3s 5ms/step - loss: 33.0024 - val_loss: 33.0237\n",
      "Epoch 77/200\n",
      "711/711 [==============================] - ETA: 0s - loss: 32.9718\n",
      "Epoch 00077: val_loss did not improve from 32.93361\n",
      "711/711 [==============================] - 3s 5ms/step - loss: 32.9718 - val_loss: 33.0391\n",
      "Epoch 78/200\n",
      "701/711 [============================>.] - ETA: 0s - loss: 32.9409\n",
      "Epoch 00078: val_loss improved from 32.93361 to 32.91880, saving model to ../savedModels/VariationalEncoderModel.h5\n",
      "711/711 [==============================] - 3s 5ms/step - loss: 32.9366 - val_loss: 32.9188\n",
      "Epoch 79/200\n",
      "710/711 [============================>.] - ETA: 0s - loss: 32.8715\n",
      "Epoch 00079: val_loss did not improve from 32.91880\n",
      "711/711 [==============================] - 3s 5ms/step - loss: 32.8752 - val_loss: 33.0475\n",
      "Epoch 80/200\n",
      "700/711 [============================>.] - ETA: 0s - loss: 32.8694\n",
      "Epoch 00080: val_loss did not improve from 32.91880\n",
      "711/711 [==============================] - 3s 5ms/step - loss: 32.8672 - val_loss: 32.9592\n",
      "Epoch 81/200\n",
      "705/711 [============================>.] - ETA: 0s - loss: 32.8698\n",
      "Epoch 00081: val_loss improved from 32.91880 to 32.90754, saving model to ../savedModels/VariationalEncoderModel.h5\n",
      "711/711 [==============================] - 4s 5ms/step - loss: 32.8715 - val_loss: 32.9075\n",
      "Epoch 82/200\n",
      "700/711 [============================>.] - ETA: 0s - loss: 32.8466\n",
      "Epoch 00082: val_loss did not improve from 32.90754\n",
      "711/711 [==============================] - 3s 5ms/step - loss: 32.8507 - val_loss: 33.0232\n",
      "Epoch 83/200\n",
      "700/711 [============================>.] - ETA: 0s - loss: 32.9045\n",
      "Epoch 00083: val_loss did not improve from 32.90754\n",
      "711/711 [==============================] - 3s 5ms/step - loss: 32.9119 - val_loss: 32.9635\n",
      "Epoch 84/200\n",
      "704/711 [============================>.] - ETA: 0s - loss: 32.8850\n",
      "Epoch 00084: val_loss did not improve from 32.90754\n",
      "711/711 [==============================] - 3s 5ms/step - loss: 32.8865 - val_loss: 32.9103\n",
      "Epoch 85/200\n",
      "708/711 [============================>.] - ETA: 0s - loss: 32.8973\n",
      "Epoch 00085: val_loss improved from 32.90754 to 32.87312, saving model to ../savedModels/VariationalEncoderModel.h5\n",
      "711/711 [==============================] - 3s 5ms/step - loss: 32.8986 - val_loss: 32.8731\n",
      "Epoch 86/200\n",
      "320/711 [============>.................] - ETA: 1s - loss: 32.8722"
     ]
    }
   ],
   "source": [
    "history = VAE.fit(train,epochs=epochs,shuffle=True,\n",
    "                          verbose=1,validation_data=dev,\n",
    "                          callbacks=[checkpoint,earlystop])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# plot_loss(history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "VAE.load_weights(\"../savedModels/VariationalEncoderModel.h5\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### create monte carlo to generate output prob score for anomaly prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "sampling_size = 100\n",
    "\n",
    "def reconstruction_log_prob(x_input,sampling_size):\n",
    "    Z = encoder(x_input)\n",
    "    encoder_samples = Z.sample(sampling_size)  # generate 30 outputs from encoder per input \n",
    "    return np.mean(decoder(encoder_samples).log_prob(x_input), axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = pd.read_csv(\"../processedData/hold_outset_moreFraud.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_tf_data, label = test.drop(\"Class\",axis=1).values, test[\"Class\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Model was constructed with shape (None, 3) for input Tensor(\"input_2:0\", shape=(None, 3), dtype=float32), but it was called on an input with incompatible shape (100, 57350, 3).\n"
     ]
    }
   ],
   "source": [
    "x_log_prob = reconstruction_log_prob(test_tf_data, sampling_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.hist(-x_log_prob[label==1],label=\"fraud\",color=\"red\",alpha = 0.5, log=True)\n",
    "plt.hist(-x_log_prob[label==0],label=\"normal\",color=\"blue\",alpha=0.5, log=True)\n",
    "plt.title(\"reconstruction log prob\")\n",
    "plt.ylabel(\"frequence log\")\n",
    "plt.xlabel(\"logp(x_input|x_output)\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "fpr, tpr, threshold = roc_curve(label,-x_log_prob)\n",
    "auc = roc_auc_score(label,-x_log_prob)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(fpr,tpr,label=f\"linear in-sample, auc={auc}\")\n",
    "plt.legend(loc=\"best\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Choose a threshold that gives a good overall class1 recall "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = pd.DataFrame({\"label\":label,\"neg_log_prob\":-x_log_prob})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "results[\"pred_class\"]=results.neg_log_prob.apply(lambda x: 1 if x>76 else 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[56679,   179],\n",
       "       [  118,   374]])"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "confusion_matrix(results.label,results.pred_class)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00     56858\n",
      "           1       0.68      0.76      0.72       492\n",
      "\n",
      "    accuracy                           0.99     57350\n",
      "   macro avg       0.84      0.88      0.86     57350\n",
      "weighted avg       1.00      0.99      0.99     57350\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(results.label, results.pred_class))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
