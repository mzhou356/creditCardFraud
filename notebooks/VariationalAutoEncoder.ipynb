{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import numpy as np\n",
    "import pandas as pd \n",
    "import tensorflow_probability as tfp\n",
    "import tensorflow.compat.v2 as tf\n",
    "import matplotlib.pyplot as plt \n",
    "%matplotlib inline\n",
    "from sklearn.metrics import confusion_matrix, classification_report, roc_curve, roc_auc_score\n",
    "sys.path.append(\"/home/mindy/Documents/projects/creditCardFraud/scripts/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfk = tf.keras\n",
    "tfkl=tf.keras.layers\n",
    "tfpl= tfp.layers         # layers for tensor flow probability \n",
    "tfd = tfp.distributions # distribution layer "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from util import *\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/device:GPU:0'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# make sure GPU is running \n",
    "tf.test.gpu_device_name()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "gpus = tf.config.experimental.list_physical_devices(\"GPU\")\n",
    "tf.config.experimental.set_virtual_device_configuration(gpus[0],\n",
    "[tf.config.experimental.VirtualDeviceConfiguration(memory_limit=1024*7)])  # limit to 7 G"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import training and dev data and convert to numpy array for NN "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv(\"../processedData/TrainingData_normal.csv\").values\n",
    "dev = pd.read_csv(\"../processedData/DevData_normal.csv\").values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### converting into tf data set to allow simple efficient data pipelines. \n",
    "* In autoencoder, you are predicting the original input x \n",
    "* shuffle and train data in batches with 1000 epochs "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "buffer_size = 10000\n",
    "batch_size = 256\n",
    "epochs = 500\n",
    "input_size = train.shape[1]\n",
    "encoded_size = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = tf.data.Dataset.from_tensor_slices((train,train)).batch(batch_size).prefetch(tf.data.experimental.AUTOTUNE).shuffle(buffer_size)\n",
    "dev = tf.data.Dataset.from_tensor_slices((dev,dev)).batch(batch_size).prefetch(tf.data.experimental.AUTOTUNE).shuffle(buffer_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### set up checkpoint and other settings "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint = tfk.callbacks.ModelCheckpoint(\"../savedModels/VariationalEncoderModel_2.h5\",verbose=1,save_best_only=True)\n",
    "earlystop = tfk.callbacks.EarlyStopping(monitor=\"val_loss\", mode=\"min\", min_delta=0.005, patience=20, verbose=1, restore_best_weights=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### For variational autoencoder we need to maximize ELBO (evidence lower bound objective):\n",
    "\n",
    "$$ELBO(x)= \\int dzq(z|x)logp(x|z) + \\int dzq(z|x)log\\frac{q(z|x)}{p(z)} $$\n",
    "\n",
    "* p(z): the prior on the latent representation z (last layer of encoder) \n",
    "* q(z|x_input): the encoder (how likely is z given x_input)\n",
    "* p(x_hat|z): the decoder (how likely is x_hat given z) \n",
    "* $\\int dzq(z|x)logp(x|z)$: reconstructin term. (how likely for us to get output_x given input_x and encode to z then decode to x_output) \n",
    "* $\\int dzq(z|x)log\\frac{q(z|x)}{p(z)} $: KL divergence. How similar are the encoder distribution and the prior distribution. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prior distribution for z: \n",
    "\n",
    "* Since this is latent representation (noise has been removed), it is okay to assume it is isotropic gaussian "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "prior = tfd.Independent(tfd.Normal(loc=tf.zeros(encoded_size), scale=1),\n",
    "                        reinterpreted_batch_ndims=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## encoder model for autoencoder:\n",
    "* encoder: 3 layers:\n",
    "  * 3 dense layers \n",
    "  * 3 dimensional multivariable non zero covariance normal distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/mindy/.venv/tf/lib/python3.6/site-packages/tensorflow/python/ops/linalg/linear_operator_lower_triangular.py:158: calling LinearOperator.__init__ (from tensorflow.python.ops.linalg.linear_operator) with graph_parents is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Do not pass `graph_parents`.  They will  no longer be used.\n",
      "Model: \"encoder\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense (Dense)                (None, 20)                620       \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 10)                210       \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 20)                220       \n",
      "_________________________________________________________________\n",
      "multivariate_normal_tri_l (M ((None, 5), (None, 5))    0         \n",
      "=================================================================\n",
      "Total params: 1,050\n",
      "Trainable params: 1,050\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "encoder = tfk.Sequential([\n",
    "    tfkl.InputLayer(input_shape = input_size),  # 30 input features \n",
    "    tfkl.Dense(units=20, activation=tf.nn.leaky_relu, activity_regularizer=tfk.regularizers.l1(10e-5)),\n",
    "    tfkl.Dense(units=10, activation=tf.nn.leaky_relu, activity_regularizer=tfk.regularizers.l1(10e-5)),\n",
    "    tfkl.Dense(tfpl.MultivariateNormalTriL.params_size(encoded_size),activation=None),\n",
    "    tfpl.MultivariateNormalTriL(encoded_size,activity_regularizer=tfpl.KLDivergenceRegularizer(prior))\n",
    "    ], name=\"encoder\")\n",
    "encoder.summary()    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## decoder model for autoencoder:\n",
    "* decoder: 3 layers:\n",
    "   * 3 dense layers\n",
    "   * independent normal distributions as output "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"decoder\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_3 (Dense)              (None, 10)                60        \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 20)                220       \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 60)                1260      \n",
      "_________________________________________________________________\n",
      "independent_normal (Independ ((None, 30), (None, 30))  0         \n",
      "=================================================================\n",
      "Total params: 1,540\n",
      "Trainable params: 1,540\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "decoder = tfk.Sequential([\n",
    "    tfkl.InputLayer(input_shape=[encoded_size]),\n",
    "    tfkl.Dense(units=10, activation=tf.nn.leaky_relu, activity_regularizer=tfk.regularizers.l1(10e-5)),\n",
    "    tfkl.Dense(units=20, activation=tf.nn.leaky_relu, activity_regularizer=tfk.regularizers.l1(10e-5)),\n",
    "    tfkl.Dense(tfpl.IndependentNormal.params_size(input_size),activation=None),\n",
    "    tfpl.IndependentNormal(input_size)\n",
    "    ], name = \"decoder\")\n",
    "decoder.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Add encoders together \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "VAE = tfk.Model(inputs=encoder.inputs, outputs=decoder(encoder.outputs[0]),name=\"VAE\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"VAE\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         [(None, 30)]              0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 20)                620       \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 10)                210       \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 20)                220       \n",
      "_________________________________________________________________\n",
      "multivariate_normal_tri_l (M ((None, 5), (None, 5))    0         \n",
      "_________________________________________________________________\n",
      "decoder (Sequential)         (None, 30)                1540      \n",
      "=================================================================\n",
      "Total params: 2,590\n",
      "Trainable params: 2,590\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "VAE.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### define reconstruction loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "negloglik = lambda x_input, x_output: -x_output.log_prob(x_input)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### compile the model and train model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "VAE.compile(optimizer=tf.optimizers.Adam(learning_rate=1e-3), loss=negloglik)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/500\n",
      "704/711 [============================>.] - ETA: 0s - loss: 185184464.0000\n",
      "Epoch 00001: val_loss improved from inf to 70.62479, saving model to ../savedModels/VariationalEncoderModel_2.h5\n",
      "711/711 [==============================] - 3s 5ms/step - loss: 183360768.0000 - val_loss: 70.6248\n",
      "Epoch 2/500\n",
      "699/711 [============================>.] - ETA: 0s - loss: 80.1723\n",
      "Epoch 00002: val_loss improved from 70.62479 to 66.08174, saving model to ../savedModels/VariationalEncoderModel_2.h5\n",
      "711/711 [==============================] - 3s 4ms/step - loss: 79.9530 - val_loss: 66.0817\n",
      "Epoch 3/500\n",
      "704/711 [============================>.] - ETA: 0s - loss: 104.8916\n",
      "Epoch 00003: val_loss improved from 66.08174 to 63.31161, saving model to ../savedModels/VariationalEncoderModel_2.h5\n",
      "711/711 [==============================] - 3s 4ms/step - loss: 104.5431 - val_loss: 63.3116\n",
      "Epoch 4/500\n",
      "708/711 [============================>.] - ETA: 0s - loss: 65.9836\n",
      "Epoch 00004: val_loss improved from 63.31161 to 61.45732, saving model to ../savedModels/VariationalEncoderModel_2.h5\n",
      "711/711 [==============================] - 3s 4ms/step - loss: 65.9656 - val_loss: 61.4573\n",
      "Epoch 5/500\n",
      "709/711 [============================>.] - ETA: 0s - loss: 61.1171\n",
      "Epoch 00005: val_loss improved from 61.45732 to 60.07925, saving model to ../savedModels/VariationalEncoderModel_2.h5\n",
      "711/711 [==============================] - 3s 4ms/step - loss: 61.1238 - val_loss: 60.0793\n",
      "Epoch 6/500\n",
      "704/711 [============================>.] - ETA: 0s - loss: 60.2598\n",
      "Epoch 00006: val_loss improved from 60.07925 to 59.11095, saving model to ../savedModels/VariationalEncoderModel_2.h5\n",
      "711/711 [==============================] - 3s 4ms/step - loss: 60.2544 - val_loss: 59.1109\n",
      "Epoch 7/500\n",
      "705/711 [============================>.] - ETA: 0s - loss: 58.9170\n",
      "Epoch 00007: val_loss improved from 59.11095 to 58.56646, saving model to ../savedModels/VariationalEncoderModel_2.h5\n",
      "711/711 [==============================] - 3s 4ms/step - loss: 58.9185 - val_loss: 58.5665\n",
      "Epoch 8/500\n",
      "701/711 [============================>.] - ETA: 0s - loss: 64.3414\n",
      "Epoch 00008: val_loss improved from 58.56646 to 58.29590, saving model to ../savedModels/VariationalEncoderModel_2.h5\n",
      "711/711 [==============================] - 3s 4ms/step - loss: 64.2506 - val_loss: 58.2959\n",
      "Epoch 9/500\n",
      "708/711 [============================>.] - ETA: 0s - loss: 58.6277\n",
      "Epoch 00009: val_loss improved from 58.29590 to 57.75991, saving model to ../savedModels/VariationalEncoderModel_2.h5\n",
      "711/711 [==============================] - 3s 4ms/step - loss: 58.6169 - val_loss: 57.7599\n",
      "Epoch 10/500\n",
      "709/711 [============================>.] - ETA: 0s - loss: 58.7288\n",
      "Epoch 00010: val_loss improved from 57.75991 to 57.43933, saving model to ../savedModels/VariationalEncoderModel_2.h5\n",
      "711/711 [==============================] - 3s 4ms/step - loss: 58.7528 - val_loss: 57.4393\n",
      "Epoch 11/500\n",
      "709/711 [============================>.] - ETA: 0s - loss: 57.7925\n",
      "Epoch 00011: val_loss improved from 57.43933 to 57.26423, saving model to ../savedModels/VariationalEncoderModel_2.h5\n",
      "711/711 [==============================] - 3s 4ms/step - loss: 57.7961 - val_loss: 57.2642\n",
      "Epoch 12/500\n",
      "711/711 [==============================] - ETA: 0s - loss: 66.0079\n",
      "Epoch 00012: val_loss improved from 57.26423 to 57.06544, saving model to ../savedModels/VariationalEncoderModel_2.h5\n",
      "711/711 [==============================] - 3s 4ms/step - loss: 66.0079 - val_loss: 57.0654\n",
      "Epoch 13/500\n",
      "700/711 [============================>.] - ETA: 0s - loss: 59.0202\n",
      "Epoch 00013: val_loss did not improve from 57.06544\n",
      "711/711 [==============================] - 3s 4ms/step - loss: 58.9842 - val_loss: 57.4291\n",
      "Epoch 14/500\n",
      "700/711 [============================>.] - ETA: 0s - loss: 57.1232\n",
      "Epoch 00014: val_loss improved from 57.06544 to 56.81363, saving model to ../savedModels/VariationalEncoderModel_2.h5\n",
      "711/711 [==============================] - 3s 4ms/step - loss: 57.1341 - val_loss: 56.8136\n",
      "Epoch 15/500\n",
      "705/711 [============================>.] - ETA: 0s - loss: 56.9548\n",
      "Epoch 00015: val_loss did not improve from 56.81363\n",
      "711/711 [==============================] - 3s 4ms/step - loss: 56.9535 - val_loss: 57.1203\n",
      "Epoch 16/500\n",
      "707/711 [============================>.] - ETA: 0s - loss: 56.9415\n",
      "Epoch 00016: val_loss improved from 56.81363 to 56.52950, saving model to ../savedModels/VariationalEncoderModel_2.h5\n",
      "711/711 [==============================] - 3s 4ms/step - loss: 56.9282 - val_loss: 56.5295\n",
      "Epoch 17/500\n",
      "700/711 [============================>.] - ETA: 0s - loss: 59.7393\n",
      "Epoch 00017: val_loss improved from 56.52950 to 56.50827, saving model to ../savedModels/VariationalEncoderModel_2.h5\n",
      "711/711 [==============================] - 3s 4ms/step - loss: 59.6724 - val_loss: 56.5083\n",
      "Epoch 18/500\n",
      "701/711 [============================>.] - ETA: 0s - loss: 56.2345\n",
      "Epoch 00018: val_loss improved from 56.50827 to 56.26588, saving model to ../savedModels/VariationalEncoderModel_2.h5\n",
      "711/711 [==============================] - 3s 4ms/step - loss: 56.2342 - val_loss: 56.2659\n",
      "Epoch 19/500\n",
      "708/711 [============================>.] - ETA: 0s - loss: 59.2996\n",
      "Epoch 00019: val_loss did not improve from 56.26588\n",
      "711/711 [==============================] - 3s 4ms/step - loss: 59.2778 - val_loss: 56.8777\n",
      "Epoch 20/500\n",
      "705/711 [============================>.] - ETA: 0s - loss: 60.7712\n",
      "Epoch 00020: val_loss improved from 56.26588 to 55.95367, saving model to ../savedModels/VariationalEncoderModel_2.h5\n",
      "711/711 [==============================] - 3s 4ms/step - loss: 60.7246 - val_loss: 55.9537\n",
      "Epoch 21/500\n",
      "707/711 [============================>.] - ETA: 0s - loss: 55.8456\n",
      "Epoch 00021: val_loss improved from 55.95367 to 55.57871, saving model to ../savedModels/VariationalEncoderModel_2.h5\n",
      "711/711 [==============================] - 3s 4ms/step - loss: 55.8392 - val_loss: 55.5787\n",
      "Epoch 22/500\n",
      "711/711 [==============================] - ETA: 0s - loss: 55.9203\n",
      "Epoch 00022: val_loss improved from 55.57871 to 55.42505, saving model to ../savedModels/VariationalEncoderModel_2.h5\n",
      "711/711 [==============================] - 3s 4ms/step - loss: 55.9203 - val_loss: 55.4250\n",
      "Epoch 23/500\n",
      "706/711 [============================>.] - ETA: 0s - loss: 55.6689\n",
      "Epoch 00023: val_loss improved from 55.42505 to 55.13284, saving model to ../savedModels/VariationalEncoderModel_2.h5\n",
      "711/711 [==============================] - 3s 4ms/step - loss: 55.6619 - val_loss: 55.1328\n",
      "Epoch 24/500\n",
      "700/711 [============================>.] - ETA: 0s - loss: 58.4533\n",
      "Epoch 00024: val_loss improved from 55.13284 to 55.00183, saving model to ../savedModels/VariationalEncoderModel_2.h5\n",
      "711/711 [==============================] - 3s 4ms/step - loss: 58.3979 - val_loss: 55.0018\n",
      "Epoch 25/500\n",
      "703/711 [============================>.] - ETA: 0s - loss: 54.9746\n",
      "Epoch 00025: val_loss improved from 55.00183 to 54.65799, saving model to ../savedModels/VariationalEncoderModel_2.h5\n",
      "711/711 [==============================] - 3s 4ms/step - loss: 54.9621 - val_loss: 54.6580\n",
      "Epoch 26/500\n",
      "711/711 [==============================] - ETA: 0s - loss: 54.6870\n",
      "Epoch 00026: val_loss did not improve from 54.65799\n",
      "711/711 [==============================] - 3s 4ms/step - loss: 54.6870 - val_loss: 54.9084\n",
      "Epoch 27/500\n",
      "699/711 [============================>.] - ETA: 0s - loss: 487.8724\n",
      "Epoch 00027: val_loss improved from 54.65799 to 52.81097, saving model to ../savedModels/VariationalEncoderModel_2.h5\n",
      "711/711 [==============================] - 3s 4ms/step - loss: 480.5223 - val_loss: 52.8110\n",
      "Epoch 28/500\n",
      "707/711 [============================>.] - ETA: 0s - loss: 53.0326\n",
      "Epoch 00028: val_loss improved from 52.81097 to 52.43645, saving model to ../savedModels/VariationalEncoderModel_2.h5\n",
      "711/711 [==============================] - 3s 4ms/step - loss: 53.0296 - val_loss: 52.4365\n",
      "Epoch 29/500\n",
      "710/711 [============================>.] - ETA: 0s - loss: 52.9481\n",
      "Epoch 00029: val_loss improved from 52.43645 to 52.36936, saving model to ../savedModels/VariationalEncoderModel_2.h5\n",
      "711/711 [==============================] - 3s 4ms/step - loss: 52.9489 - val_loss: 52.3694\n",
      "Epoch 30/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "706/711 [============================>.] - ETA: 0s - loss: 53.2080\n",
      "Epoch 00030: val_loss improved from 52.36936 to 52.29855, saving model to ../savedModels/VariationalEncoderModel_2.h5\n",
      "711/711 [==============================] - 3s 4ms/step - loss: 53.2048 - val_loss: 52.2985\n",
      "Epoch 31/500\n",
      "704/711 [============================>.] - ETA: 0s - loss: 52.3073\n",
      "Epoch 00031: val_loss improved from 52.29855 to 51.85083, saving model to ../savedModels/VariationalEncoderModel_2.h5\n",
      "711/711 [==============================] - 3s 4ms/step - loss: 52.2959 - val_loss: 51.8508\n",
      "Epoch 32/500\n",
      "700/711 [============================>.] - ETA: 0s - loss: 40403.6055\n",
      "Epoch 00032: val_loss did not improve from 51.85083\n",
      "711/711 [==============================] - 3s 4ms/step - loss: 39779.1875 - val_loss: 55.9010\n",
      "Epoch 33/500\n",
      "699/711 [============================>.] - ETA: 0s - loss: 54.0064\n",
      "Epoch 00033: val_loss did not improve from 51.85083\n",
      "711/711 [==============================] - 3s 4ms/step - loss: 54.0056 - val_loss: 53.9521\n",
      "Epoch 34/500\n",
      "705/711 [============================>.] - ETA: 0s - loss: 54.6937\n",
      "Epoch 00034: val_loss did not improve from 51.85083\n",
      "711/711 [==============================] - 3s 4ms/step - loss: 54.6849 - val_loss: 53.7996\n",
      "Epoch 35/500\n",
      "706/711 [============================>.] - ETA: 0s - loss: 53.9595\n",
      "Epoch 00035: val_loss did not improve from 51.85083\n",
      "711/711 [==============================] - 3s 4ms/step - loss: 53.9529 - val_loss: 53.6021\n",
      "Epoch 36/500\n",
      "700/711 [============================>.] - ETA: 0s - loss: 53.9389\n",
      "Epoch 00036: val_loss did not improve from 51.85083\n",
      "711/711 [==============================] - 3s 4ms/step - loss: 53.9281 - val_loss: 53.6372\n",
      "Epoch 37/500\n",
      "710/711 [============================>.] - ETA: 0s - loss: 53.6212\n",
      "Epoch 00037: val_loss did not improve from 51.85083\n",
      "711/711 [==============================] - 3s 4ms/step - loss: 53.6351 - val_loss: 53.4228\n",
      "Epoch 38/500\n",
      "709/711 [============================>.] - ETA: 0s - loss: 56.7721\n",
      "Epoch 00038: val_loss did not improve from 51.85083\n",
      "711/711 [==============================] - 3s 4ms/step - loss: 56.7589 - val_loss: 53.2986\n",
      "Epoch 39/500\n",
      "704/711 [============================>.] - ETA: 0s - loss: 53.3403\n",
      "Epoch 00039: val_loss did not improve from 51.85083\n",
      "711/711 [==============================] - 3s 4ms/step - loss: 53.3318 - val_loss: 53.0353\n",
      "Epoch 40/500\n",
      "706/711 [============================>.] - ETA: 0s - loss: 59.3256\n",
      "Epoch 00040: val_loss did not improve from 51.85083\n",
      "711/711 [==============================] - 3s 4ms/step - loss: 59.2679 - val_loss: 52.4824\n",
      "Epoch 41/500\n",
      "705/711 [============================>.] - ETA: 0s - loss: 52.3326\n",
      "Epoch 00041: val_loss did not improve from 51.85083\n",
      "711/711 [==============================] - 3s 4ms/step - loss: 52.3392 - val_loss: 51.9809\n",
      "Epoch 42/500\n",
      "710/711 [============================>.] - ETA: 0s - loss: 53.6203\n",
      "Epoch 00042: val_loss improved from 51.85083 to 51.53186, saving model to ../savedModels/VariationalEncoderModel_2.h5\n",
      "711/711 [==============================] - 3s 4ms/step - loss: 53.6158 - val_loss: 51.5319\n",
      "Epoch 43/500\n",
      "698/711 [============================>.] - ETA: 0s - loss: 51.2408\n",
      "Epoch 00043: val_loss improved from 51.53186 to 50.76217, saving model to ../savedModels/VariationalEncoderModel_2.h5\n",
      "711/711 [==============================] - 3s 4ms/step - loss: 51.2388 - val_loss: 50.7622\n",
      "Epoch 44/500\n",
      "698/711 [============================>.] - ETA: 0s - loss: 50.3907\n",
      "Epoch 00044: val_loss improved from 50.76217 to 50.21507, saving model to ../savedModels/VariationalEncoderModel_2.h5\n",
      "711/711 [==============================] - 3s 4ms/step - loss: 50.3918 - val_loss: 50.2151\n",
      "Epoch 45/500\n",
      "698/711 [============================>.] - ETA: 0s - loss: 50.6632\n",
      "Epoch 00045: val_loss improved from 50.21507 to 48.75764, saving model to ../savedModels/VariationalEncoderModel_2.h5\n",
      "711/711 [==============================] - 3s 4ms/step - loss: 50.6241 - val_loss: 48.7576\n",
      "Epoch 46/500\n",
      "706/711 [============================>.] - ETA: 0s - loss: 48.3288\n",
      "Epoch 00046: val_loss improved from 48.75764 to 47.72754, saving model to ../savedModels/VariationalEncoderModel_2.h5\n",
      "711/711 [==============================] - 3s 4ms/step - loss: 48.3269 - val_loss: 47.7275\n",
      "Epoch 47/500\n",
      "707/711 [============================>.] - ETA: 0s - loss: 47.3110\n",
      "Epoch 00047: val_loss improved from 47.72754 to 46.71053, saving model to ../savedModels/VariationalEncoderModel_2.h5\n",
      "711/711 [==============================] - 3s 4ms/step - loss: 47.3207 - val_loss: 46.7105\n",
      "Epoch 48/500\n",
      "707/711 [============================>.] - ETA: 0s - loss: 46.3375\n",
      "Epoch 00048: val_loss improved from 46.71053 to 46.02123, saving model to ../savedModels/VariationalEncoderModel_2.h5\n",
      "711/711 [==============================] - 3s 4ms/step - loss: 46.3291 - val_loss: 46.0212\n",
      "Epoch 49/500\n",
      "701/711 [============================>.] - ETA: 0s - loss: 45.5151\n",
      "Epoch 00049: val_loss improved from 46.02123 to 45.08171, saving model to ../savedModels/VariationalEncoderModel_2.h5\n",
      "711/711 [==============================] - 3s 4ms/step - loss: 45.5152 - val_loss: 45.0817\n",
      "Epoch 50/500\n",
      "700/711 [============================>.] - ETA: 0s - loss: 44.9299\n",
      "Epoch 00050: val_loss improved from 45.08171 to 44.50560, saving model to ../savedModels/VariationalEncoderModel_2.h5\n",
      "711/711 [==============================] - 3s 4ms/step - loss: 44.9239 - val_loss: 44.5056\n",
      "Epoch 51/500\n",
      "700/711 [============================>.] - ETA: 0s - loss: 44.1264\n",
      "Epoch 00051: val_loss improved from 44.50560 to 43.99241, saving model to ../savedModels/VariationalEncoderModel_2.h5\n",
      "711/711 [==============================] - 3s 4ms/step - loss: 44.1565 - val_loss: 43.9924\n",
      "Epoch 52/500\n",
      "699/711 [============================>.] - ETA: 0s - loss: 43.6444\n",
      "Epoch 00052: val_loss improved from 43.99241 to 43.40158, saving model to ../savedModels/VariationalEncoderModel_2.h5\n",
      "711/711 [==============================] - 3s 4ms/step - loss: 43.6372 - val_loss: 43.4016\n",
      "Epoch 53/500\n",
      "699/711 [============================>.] - ETA: 0s - loss: 43.0778\n",
      "Epoch 00053: val_loss improved from 43.40158 to 42.87316, saving model to ../savedModels/VariationalEncoderModel_2.h5\n",
      "711/711 [==============================] - 3s 4ms/step - loss: 43.0793 - val_loss: 42.8732\n",
      "Epoch 54/500\n",
      "700/711 [============================>.] - ETA: 0s - loss: 42.6831\n",
      "Epoch 00054: val_loss improved from 42.87316 to 42.54750, saving model to ../savedModels/VariationalEncoderModel_2.h5\n",
      "711/711 [==============================] - 3s 4ms/step - loss: 42.6718 - val_loss: 42.5475\n",
      "Epoch 55/500\n",
      "709/711 [============================>.] - ETA: 0s - loss: 42.3387\n",
      "Epoch 00055: val_loss improved from 42.54750 to 42.07689, saving model to ../savedModels/VariationalEncoderModel_2.h5\n",
      "711/711 [==============================] - 3s 4ms/step - loss: 42.3367 - val_loss: 42.0769\n",
      "Epoch 56/500\n",
      "704/711 [============================>.] - ETA: 0s - loss: 41.9214\n",
      "Epoch 00056: val_loss improved from 42.07689 to 41.83769, saving model to ../savedModels/VariationalEncoderModel_2.h5\n",
      "711/711 [==============================] - 3s 4ms/step - loss: 41.9154 - val_loss: 41.8377\n",
      "Epoch 57/500\n",
      "704/711 [============================>.] - ETA: 0s - loss: 41.5169\n",
      "Epoch 00057: val_loss improved from 41.83769 to 41.41858, saving model to ../savedModels/VariationalEncoderModel_2.h5\n",
      "711/711 [==============================] - 3s 4ms/step - loss: 41.5131 - val_loss: 41.4186\n",
      "Epoch 58/500\n",
      "704/711 [============================>.] - ETA: 0s - loss: 41.1474\n",
      "Epoch 00058: val_loss improved from 41.41858 to 40.89691, saving model to ../savedModels/VariationalEncoderModel_2.h5\n",
      "711/711 [==============================] - 3s 4ms/step - loss: 41.1550 - val_loss: 40.8969\n",
      "Epoch 59/500\n",
      "710/711 [============================>.] - ETA: 0s - loss: 40.7358\n",
      "Epoch 00059: val_loss improved from 40.89691 to 40.42675, saving model to ../savedModels/VariationalEncoderModel_2.h5\n",
      "711/711 [==============================] - 3s 4ms/step - loss: 40.7360 - val_loss: 40.4267\n",
      "Epoch 60/500\n",
      "702/711 [============================>.] - ETA: 0s - loss: 40.2667\n",
      "Epoch 00060: val_loss improved from 40.42675 to 40.02195, saving model to ../savedModels/VariationalEncoderModel_2.h5\n",
      "711/711 [==============================] - 3s 4ms/step - loss: 40.2636 - val_loss: 40.0219\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 61/500\n",
      "706/711 [============================>.] - ETA: 0s - loss: 39.7682\n",
      "Epoch 00061: val_loss improved from 40.02195 to 39.53992, saving model to ../savedModels/VariationalEncoderModel_2.h5\n",
      "711/711 [==============================] - 3s 4ms/step - loss: 39.7646 - val_loss: 39.5399\n",
      "Epoch 62/500\n",
      "700/711 [============================>.] - ETA: 0s - loss: 39.2781\n",
      "Epoch 00062: val_loss improved from 39.53992 to 39.10884, saving model to ../savedModels/VariationalEncoderModel_2.h5\n",
      "711/711 [==============================] - 3s 4ms/step - loss: 39.2719 - val_loss: 39.1088\n",
      "Epoch 63/500\n",
      "699/711 [============================>.] - ETA: 0s - loss: 38.6987\n",
      "Epoch 00063: val_loss improved from 39.10884 to 38.49768, saving model to ../savedModels/VariationalEncoderModel_2.h5\n",
      "711/711 [==============================] - 3s 4ms/step - loss: 38.7001 - val_loss: 38.4977\n",
      "Epoch 64/500\n",
      "701/711 [============================>.] - ETA: 0s - loss: 38.2001\n",
      "Epoch 00064: val_loss improved from 38.49768 to 37.90058, saving model to ../savedModels/VariationalEncoderModel_2.h5\n",
      "711/711 [==============================] - 3s 4ms/step - loss: 38.1896 - val_loss: 37.9006\n",
      "Epoch 65/500\n",
      "702/711 [============================>.] - ETA: 0s - loss: 37.6190\n",
      "Epoch 00065: val_loss improved from 37.90058 to 37.37535, saving model to ../savedModels/VariationalEncoderModel_2.h5\n",
      "711/711 [==============================] - 3s 4ms/step - loss: 37.6078 - val_loss: 37.3753\n",
      "Epoch 66/500\n",
      "703/711 [============================>.] - ETA: 0s - loss: 37.0585\n",
      "Epoch 00066: val_loss improved from 37.37535 to 36.90719, saving model to ../savedModels/VariationalEncoderModel_2.h5\n",
      "711/711 [==============================] - 3s 4ms/step - loss: 37.0537 - val_loss: 36.9072\n",
      "Epoch 67/500\n",
      "710/711 [============================>.] - ETA: 0s - loss: 36.6476\n",
      "Epoch 00067: val_loss improved from 36.90719 to 36.54841, saving model to ../savedModels/VariationalEncoderModel_2.h5\n",
      "711/711 [==============================] - 3s 4ms/step - loss: 36.6455 - val_loss: 36.5484\n",
      "Epoch 68/500\n",
      "702/711 [============================>.] - ETA: 0s - loss: 36.3721\n",
      "Epoch 00068: val_loss improved from 36.54841 to 36.29058, saving model to ../savedModels/VariationalEncoderModel_2.h5\n",
      "711/711 [==============================] - 3s 4ms/step - loss: 36.3676 - val_loss: 36.2906\n",
      "Epoch 69/500\n",
      "706/711 [============================>.] - ETA: 0s - loss: 36.1377\n",
      "Epoch 00069: val_loss improved from 36.29058 to 36.08610, saving model to ../savedModels/VariationalEncoderModel_2.h5\n",
      "711/711 [==============================] - 3s 4ms/step - loss: 36.1359 - val_loss: 36.0861\n",
      "Epoch 70/500\n",
      "705/711 [============================>.] - ETA: 0s - loss: 35.9419\n",
      "Epoch 00070: val_loss improved from 36.08610 to 35.94277, saving model to ../savedModels/VariationalEncoderModel_2.h5\n",
      "711/711 [==============================] - 3s 4ms/step - loss: 35.9453 - val_loss: 35.9428\n",
      "Epoch 71/500\n",
      "703/711 [============================>.] - ETA: 0s - loss: 35.7643\n",
      "Epoch 00071: val_loss improved from 35.94277 to 35.75309, saving model to ../savedModels/VariationalEncoderModel_2.h5\n",
      "711/711 [==============================] - 3s 4ms/step - loss: 35.7636 - val_loss: 35.7531\n",
      "Epoch 72/500\n",
      "705/711 [============================>.] - ETA: 0s - loss: 35.6028\n",
      "Epoch 00072: val_loss improved from 35.75309 to 35.54964, saving model to ../savedModels/VariationalEncoderModel_2.h5\n",
      "711/711 [==============================] - 3s 4ms/step - loss: 35.5978 - val_loss: 35.5496\n",
      "Epoch 73/500\n",
      "696/711 [============================>.] - ETA: 0s - loss: 35.3486\n",
      "Epoch 00073: val_loss improved from 35.54964 to 35.25353, saving model to ../savedModels/VariationalEncoderModel_2.h5\n",
      "711/711 [==============================] - 3s 4ms/step - loss: 35.3538 - val_loss: 35.2535\n",
      "Epoch 74/500\n",
      "709/711 [============================>.] - ETA: 0s - loss: 35.0065\n",
      "Epoch 00074: val_loss improved from 35.25353 to 34.88315, saving model to ../savedModels/VariationalEncoderModel_2.h5\n",
      "711/711 [==============================] - 3s 4ms/step - loss: 35.0079 - val_loss: 34.8832\n",
      "Epoch 75/500\n",
      "698/711 [============================>.] - ETA: 0s - loss: 34.6786\n",
      "Epoch 00075: val_loss improved from 34.88315 to 34.55357, saving model to ../savedModels/VariationalEncoderModel_2.h5\n",
      "711/711 [==============================] - 3s 4ms/step - loss: 34.6724 - val_loss: 34.5536\n",
      "Epoch 76/500\n",
      "704/711 [============================>.] - ETA: 0s - loss: 34.3857\n",
      "Epoch 00076: val_loss improved from 34.55357 to 34.26170, saving model to ../savedModels/VariationalEncoderModel_2.h5\n",
      "711/711 [==============================] - 3s 4ms/step - loss: 34.3823 - val_loss: 34.2617\n",
      "Epoch 77/500\n",
      "704/711 [============================>.] - ETA: 0s - loss: 34.1774\n",
      "Epoch 00077: val_loss improved from 34.26170 to 34.11023, saving model to ../savedModels/VariationalEncoderModel_2.h5\n",
      "711/711 [==============================] - 3s 4ms/step - loss: 34.1731 - val_loss: 34.1102\n",
      "Epoch 78/500\n",
      "709/711 [============================>.] - ETA: 0s - loss: 34.0270\n",
      "Epoch 00078: val_loss improved from 34.11023 to 34.05519, saving model to ../savedModels/VariationalEncoderModel_2.h5\n",
      "711/711 [==============================] - 3s 4ms/step - loss: 34.0245 - val_loss: 34.0552\n",
      "Epoch 79/500\n",
      "706/711 [============================>.] - ETA: 0s - loss: 33.8857\n",
      "Epoch 00079: val_loss improved from 34.05519 to 33.91557, saving model to ../savedModels/VariationalEncoderModel_2.h5\n",
      "711/711 [==============================] - 3s 4ms/step - loss: 33.8865 - val_loss: 33.9156\n",
      "Epoch 80/500\n",
      "705/711 [============================>.] - ETA: 0s - loss: 33.7541\n",
      "Epoch 00080: val_loss improved from 33.91557 to 33.71533, saving model to ../savedModels/VariationalEncoderModel_2.h5\n",
      "711/711 [==============================] - 3s 4ms/step - loss: 33.7504 - val_loss: 33.7153\n",
      "Epoch 81/500\n",
      "702/711 [============================>.] - ETA: 0s - loss: 33.6182\n",
      "Epoch 00081: val_loss improved from 33.71533 to 33.58369, saving model to ../savedModels/VariationalEncoderModel_2.h5\n",
      "711/711 [==============================] - 3s 4ms/step - loss: 33.6158 - val_loss: 33.5837\n",
      "Epoch 82/500\n",
      "708/711 [============================>.] - ETA: 0s - loss: 33.4914\n",
      "Epoch 00082: val_loss improved from 33.58369 to 33.48034, saving model to ../savedModels/VariationalEncoderModel_2.h5\n",
      "711/711 [==============================] - 3s 4ms/step - loss: 33.4881 - val_loss: 33.4803\n",
      "Epoch 83/500\n",
      "702/711 [============================>.] - ETA: 0s - loss: 33.3615\n",
      "Epoch 00083: val_loss improved from 33.48034 to 33.34992, saving model to ../savedModels/VariationalEncoderModel_2.h5\n",
      "711/711 [==============================] - 3s 4ms/step - loss: 33.3618 - val_loss: 33.3499\n",
      "Epoch 84/500\n",
      "697/711 [============================>.] - ETA: 0s - loss: 33.2691\n",
      "Epoch 00084: val_loss improved from 33.34992 to 33.23682, saving model to ../savedModels/VariationalEncoderModel_2.h5\n",
      "711/711 [==============================] - 3s 4ms/step - loss: 33.2620 - val_loss: 33.2368\n",
      "Epoch 85/500\n",
      "707/711 [============================>.] - ETA: 0s - loss: 33.1779\n",
      "Epoch 00085: val_loss improved from 33.23682 to 33.20098, saving model to ../savedModels/VariationalEncoderModel_2.h5\n",
      "711/711 [==============================] - 3s 4ms/step - loss: 33.1784 - val_loss: 33.2010\n",
      "Epoch 86/500\n",
      "709/711 [============================>.] - ETA: 0s - loss: 33.0568\n",
      "Epoch 00086: val_loss improved from 33.20098 to 33.03996, saving model to ../savedModels/VariationalEncoderModel_2.h5\n",
      "711/711 [==============================] - 3s 4ms/step - loss: 33.0596 - val_loss: 33.0400\n",
      "Epoch 87/500\n",
      "701/711 [============================>.] - ETA: 0s - loss: 32.9375\n",
      "Epoch 00087: val_loss improved from 33.03996 to 32.90534, saving model to ../savedModels/VariationalEncoderModel_2.h5\n",
      "711/711 [==============================] - 3s 4ms/step - loss: 32.9345 - val_loss: 32.9053\n",
      "Epoch 88/500\n",
      "709/711 [============================>.] - ETA: 0s - loss: 32.8171\n",
      "Epoch 00088: val_loss improved from 32.90534 to 32.83862, saving model to ../savedModels/VariationalEncoderModel_2.h5\n",
      "711/711 [==============================] - 3s 4ms/step - loss: 32.8160 - val_loss: 32.8386\n",
      "Epoch 89/500\n",
      "711/711 [==============================] - ETA: 0s - loss: 32.7431\n",
      "Epoch 00089: val_loss improved from 32.83862 to 32.82137, saving model to ../savedModels/VariationalEncoderModel_2.h5\n",
      "711/711 [==============================] - 3s 4ms/step - loss: 32.7431 - val_loss: 32.8214\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 90/500\n",
      "701/711 [============================>.] - ETA: 0s - loss: 32.6797\n",
      "Epoch 00090: val_loss improved from 32.82137 to 32.68605, saving model to ../savedModels/VariationalEncoderModel_2.h5\n",
      "711/711 [==============================] - 3s 4ms/step - loss: 32.6764 - val_loss: 32.6860\n",
      "Epoch 91/500\n",
      "700/711 [============================>.] - ETA: 0s - loss: 32.6184\n",
      "Epoch 00091: val_loss improved from 32.68605 to 32.67630, saving model to ../savedModels/VariationalEncoderModel_2.h5\n",
      "711/711 [==============================] - 3s 4ms/step - loss: 32.6221 - val_loss: 32.6763\n",
      "Epoch 92/500\n",
      "706/711 [============================>.] - ETA: 0s - loss: 32.5922\n",
      "Epoch 00092: val_loss improved from 32.67630 to 32.59383, saving model to ../savedModels/VariationalEncoderModel_2.h5\n",
      "711/711 [==============================] - 3s 4ms/step - loss: 32.5959 - val_loss: 32.5938\n",
      "Epoch 93/500\n",
      "700/711 [============================>.] - ETA: 0s - loss: 32.5542\n",
      "Epoch 00093: val_loss did not improve from 32.59383\n",
      "711/711 [==============================] - 3s 4ms/step - loss: 32.5566 - val_loss: 32.6007\n",
      "Epoch 94/500\n",
      "698/711 [============================>.] - ETA: 0s - loss: 32.5193\n",
      "Epoch 00094: val_loss did not improve from 32.59383\n",
      "711/711 [==============================] - 3s 4ms/step - loss: 32.5218 - val_loss: 32.6425\n",
      "Epoch 95/500\n",
      "711/711 [==============================] - ETA: 0s - loss: 32.4988\n",
      "Epoch 00095: val_loss did not improve from 32.59383\n",
      "711/711 [==============================] - 3s 4ms/step - loss: 32.4988 - val_loss: 32.6175\n",
      "Epoch 96/500\n",
      "708/711 [============================>.] - ETA: 0s - loss: 32.4739\n",
      "Epoch 00096: val_loss improved from 32.59383 to 32.51576, saving model to ../savedModels/VariationalEncoderModel_2.h5\n",
      "711/711 [==============================] - 3s 4ms/step - loss: 32.4708 - val_loss: 32.5158\n",
      "Epoch 97/500\n",
      "709/711 [============================>.] - ETA: 0s - loss: 32.4498\n",
      "Epoch 00097: val_loss did not improve from 32.51576\n",
      "711/711 [==============================] - 3s 4ms/step - loss: 32.4482 - val_loss: 32.5540\n",
      "Epoch 98/500\n",
      "707/711 [============================>.] - ETA: 0s - loss: 32.4180\n",
      "Epoch 00098: val_loss improved from 32.51576 to 32.47913, saving model to ../savedModels/VariationalEncoderModel_2.h5\n",
      "711/711 [==============================] - 3s 4ms/step - loss: 32.4192 - val_loss: 32.4791\n",
      "Epoch 99/500\n",
      "706/711 [============================>.] - ETA: 0s - loss: 32.4111\n",
      "Epoch 00099: val_loss improved from 32.47913 to 32.45826, saving model to ../savedModels/VariationalEncoderModel_2.h5\n",
      "711/711 [==============================] - 3s 4ms/step - loss: 32.4098 - val_loss: 32.4583\n",
      "Epoch 100/500\n",
      "707/711 [============================>.] - ETA: 0s - loss: 32.3791\n",
      "Epoch 00100: val_loss did not improve from 32.45826\n",
      "711/711 [==============================] - 3s 4ms/step - loss: 32.3816 - val_loss: 32.4835\n",
      "Epoch 101/500\n",
      "711/711 [==============================] - ETA: 0s - loss: 32.3601\n",
      "Epoch 00101: val_loss improved from 32.45826 to 32.42566, saving model to ../savedModels/VariationalEncoderModel_2.h5\n",
      "711/711 [==============================] - 3s 4ms/step - loss: 32.3601 - val_loss: 32.4257\n",
      "Epoch 102/500\n",
      "706/711 [============================>.] - ETA: 0s - loss: 32.3372\n",
      "Epoch 00102: val_loss improved from 32.42566 to 32.40015, saving model to ../savedModels/VariationalEncoderModel_2.h5\n",
      "711/711 [==============================] - 3s 4ms/step - loss: 32.3362 - val_loss: 32.4002\n",
      "Epoch 103/500\n",
      "709/711 [============================>.] - ETA: 0s - loss: 32.3220\n",
      "Epoch 00103: val_loss did not improve from 32.40015\n",
      "711/711 [==============================] - 3s 4ms/step - loss: 32.3258 - val_loss: 32.4104\n",
      "Epoch 104/500\n",
      "706/711 [============================>.] - ETA: 0s - loss: 32.2969\n",
      "Epoch 00104: val_loss improved from 32.40015 to 32.35309, saving model to ../savedModels/VariationalEncoderModel_2.h5\n",
      "711/711 [==============================] - 3s 4ms/step - loss: 32.2970 - val_loss: 32.3531\n",
      "Epoch 105/500\n",
      "711/711 [==============================] - ETA: 0s - loss: 32.2961\n",
      "Epoch 00105: val_loss improved from 32.35309 to 32.32149, saving model to ../savedModels/VariationalEncoderModel_2.h5\n",
      "711/711 [==============================] - 3s 4ms/step - loss: 32.2961 - val_loss: 32.3215\n",
      "Epoch 106/500\n",
      "705/711 [============================>.] - ETA: 0s - loss: 32.2600\n",
      "Epoch 00106: val_loss did not improve from 32.32149\n",
      "711/711 [==============================] - 3s 4ms/step - loss: 32.2603 - val_loss: 32.3372\n",
      "Epoch 107/500\n",
      "705/711 [============================>.] - ETA: 0s - loss: 32.2683\n",
      "Epoch 00107: val_loss improved from 32.32149 to 32.31229, saving model to ../savedModels/VariationalEncoderModel_2.h5\n",
      "711/711 [==============================] - 3s 4ms/step - loss: 32.2648 - val_loss: 32.3123\n",
      "Epoch 108/500\n",
      "706/711 [============================>.] - ETA: 0s - loss: 32.2300\n",
      "Epoch 00108: val_loss did not improve from 32.31229\n",
      "711/711 [==============================] - 3s 4ms/step - loss: 32.2265 - val_loss: 32.3354\n",
      "Epoch 109/500\n",
      "699/711 [============================>.] - ETA: 0s - loss: 32.2269\n",
      "Epoch 00109: val_loss improved from 32.31229 to 32.27858, saving model to ../savedModels/VariationalEncoderModel_2.h5\n",
      "711/711 [==============================] - 3s 4ms/step - loss: 32.2295 - val_loss: 32.2786\n",
      "Epoch 110/500\n",
      "703/711 [============================>.] - ETA: 0s - loss: 32.2116\n",
      "Epoch 00110: val_loss improved from 32.27858 to 32.27154, saving model to ../savedModels/VariationalEncoderModel_2.h5\n",
      "711/711 [==============================] - 3s 4ms/step - loss: 32.2052 - val_loss: 32.2715\n",
      "Epoch 111/500\n",
      "706/711 [============================>.] - ETA: 0s - loss: 32.1968\n",
      "Epoch 00111: val_loss improved from 32.27154 to 32.24873, saving model to ../savedModels/VariationalEncoderModel_2.h5\n",
      "711/711 [==============================] - 3s 4ms/step - loss: 32.1972 - val_loss: 32.2487\n",
      "Epoch 112/500\n",
      "707/711 [============================>.] - ETA: 0s - loss: 32.1901\n",
      "Epoch 00112: val_loss did not improve from 32.24873\n",
      "711/711 [==============================] - 3s 4ms/step - loss: 32.1874 - val_loss: 32.3070\n",
      "Epoch 113/500\n",
      "698/711 [============================>.] - ETA: 0s - loss: 32.1891\n",
      "Epoch 00113: val_loss did not improve from 32.24873\n",
      "711/711 [==============================] - 3s 4ms/step - loss: 32.1859 - val_loss: 32.7058\n",
      "Epoch 114/500\n",
      "705/711 [============================>.] - ETA: 0s - loss: 32.1621\n",
      "Epoch 00114: val_loss did not improve from 32.24873\n",
      "711/711 [==============================] - 3s 4ms/step - loss: 32.1685 - val_loss: 32.2707\n",
      "Epoch 115/500\n",
      "704/711 [============================>.] - ETA: 0s - loss: 32.1693\n",
      "Epoch 00115: val_loss did not improve from 32.24873\n",
      "711/711 [==============================] - 3s 4ms/step - loss: 32.1666 - val_loss: 32.2764\n",
      "Epoch 116/500\n",
      "698/711 [============================>.] - ETA: 0s - loss: 32.1380\n",
      "Epoch 00116: val_loss did not improve from 32.24873\n",
      "711/711 [==============================] - 3s 4ms/step - loss: 32.1357 - val_loss: 32.4689\n",
      "Epoch 117/500\n",
      "703/711 [============================>.] - ETA: 0s - loss: 32.1336\n",
      "Epoch 00117: val_loss improved from 32.24873 to 32.20829, saving model to ../savedModels/VariationalEncoderModel_2.h5\n",
      "711/711 [==============================] - 3s 4ms/step - loss: 32.1323 - val_loss: 32.2083\n",
      "Epoch 118/500\n",
      "704/711 [============================>.] - ETA: 0s - loss: 32.1143\n",
      "Epoch 00118: val_loss improved from 32.20829 to 32.19284, saving model to ../savedModels/VariationalEncoderModel_2.h5\n",
      "711/711 [==============================] - 3s 4ms/step - loss: 32.1141 - val_loss: 32.1928\n",
      "Epoch 119/500\n",
      "702/711 [============================>.] - ETA: 0s - loss: 32.1118\n",
      "Epoch 00119: val_loss improved from 32.19284 to 32.15700, saving model to ../savedModels/VariationalEncoderModel_2.h5\n",
      "711/711 [==============================] - 3s 4ms/step - loss: 32.1081 - val_loss: 32.1570\n",
      "Epoch 120/500\n",
      "708/711 [============================>.] - ETA: 0s - loss: 32.1026\n",
      "Epoch 00120: val_loss did not improve from 32.15700\n",
      "711/711 [==============================] - 3s 4ms/step - loss: 32.1049 - val_loss: 32.2456\n",
      "Epoch 121/500\n",
      "703/711 [============================>.] - ETA: 0s - loss: 32.0900\n",
      "Epoch 00121: val_loss did not improve from 32.15700\n",
      "711/711 [==============================] - 3s 4ms/step - loss: 32.0891 - val_loss: 32.1951\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 122/500\n",
      "698/711 [============================>.] - ETA: 0s - loss: 32.0796\n",
      "Epoch 00122: val_loss did not improve from 32.15700\n",
      "711/711 [==============================] - 3s 4ms/step - loss: 32.0831 - val_loss: 32.1969\n",
      "Epoch 123/500\n",
      "700/711 [============================>.] - ETA: 0s - loss: 32.0671\n",
      "Epoch 00123: val_loss did not improve from 32.15700\n",
      "711/711 [==============================] - 3s 4ms/step - loss: 32.0708 - val_loss: 48.3330\n",
      "Epoch 124/500\n",
      "711/711 [==============================] - ETA: 0s - loss: 32.0700\n",
      "Epoch 00124: val_loss improved from 32.15700 to 32.15267, saving model to ../savedModels/VariationalEncoderModel_2.h5\n",
      "711/711 [==============================] - 3s 4ms/step - loss: 32.0700 - val_loss: 32.1527\n",
      "Epoch 125/500\n",
      "704/711 [============================>.] - ETA: 0s - loss: 32.0643\n",
      "Epoch 00125: val_loss did not improve from 32.15267\n",
      "711/711 [==============================] - 3s 4ms/step - loss: 32.0618 - val_loss: 32.5640\n",
      "Epoch 126/500\n",
      "706/711 [============================>.] - ETA: 0s - loss: 32.0529\n",
      "Epoch 00126: val_loss did not improve from 32.15267\n",
      "711/711 [==============================] - 3s 4ms/step - loss: 32.0524 - val_loss: 32.4376\n",
      "Epoch 127/500\n",
      "699/711 [============================>.] - ETA: 0s - loss: 32.0695\n",
      "Epoch 00127: val_loss improved from 32.15267 to 32.11282, saving model to ../savedModels/VariationalEncoderModel_2.h5\n",
      "711/711 [==============================] - 3s 4ms/step - loss: 32.0613 - val_loss: 32.1128\n",
      "Epoch 128/500\n",
      "706/711 [============================>.] - ETA: 0s - loss: 32.0323\n",
      "Epoch 00128: val_loss did not improve from 32.11282\n",
      "711/711 [==============================] - 3s 4ms/step - loss: 32.0291 - val_loss: 32.1687\n",
      "Epoch 129/500\n",
      "706/711 [============================>.] - ETA: 0s - loss: 32.0230\n",
      "Epoch 00129: val_loss improved from 32.11282 to 32.09661, saving model to ../savedModels/VariationalEncoderModel_2.h5\n",
      "711/711 [==============================] - 3s 4ms/step - loss: 32.0225 - val_loss: 32.0966\n",
      "Epoch 130/500\n",
      "700/711 [============================>.] - ETA: 0s - loss: 32.0183\n",
      "Epoch 00130: val_loss did not improve from 32.09661\n",
      "711/711 [==============================] - 3s 4ms/step - loss: 32.0128 - val_loss: 32.2367\n",
      "Epoch 131/500\n",
      "698/711 [============================>.] - ETA: 0s - loss: 31.9999\n",
      "Epoch 00131: val_loss did not improve from 32.09661\n",
      "711/711 [==============================] - 3s 4ms/step - loss: 32.0011 - val_loss: 220.2295\n",
      "Epoch 132/500\n",
      "708/711 [============================>.] - ETA: 0s - loss: 31.9994\n",
      "Epoch 00132: val_loss improved from 32.09661 to 32.04660, saving model to ../savedModels/VariationalEncoderModel_2.h5\n",
      "711/711 [==============================] - 3s 4ms/step - loss: 31.9959 - val_loss: 32.0466\n",
      "Epoch 133/500\n",
      "704/711 [============================>.] - ETA: 0s - loss: 31.9962\n",
      "Epoch 00133: val_loss did not improve from 32.04660\n",
      "711/711 [==============================] - 3s 4ms/step - loss: 31.9927 - val_loss: 32.4350\n",
      "Epoch 134/500\n",
      "708/711 [============================>.] - ETA: 0s - loss: 31.9947\n",
      "Epoch 00134: val_loss did not improve from 32.04660\n",
      "711/711 [==============================] - 3s 4ms/step - loss: 31.9929 - val_loss: 32.1143\n",
      "Epoch 135/500\n",
      "707/711 [============================>.] - ETA: 0s - loss: 31.9804\n",
      "Epoch 00135: val_loss did not improve from 32.04660\n",
      "711/711 [==============================] - 3s 4ms/step - loss: 31.9794 - val_loss: 32.1278\n",
      "Epoch 136/500\n",
      "711/711 [==============================] - ETA: 0s - loss: 31.9567\n",
      "Epoch 00136: val_loss improved from 32.04660 to 32.04379, saving model to ../savedModels/VariationalEncoderModel_2.h5\n",
      "711/711 [==============================] - 3s 4ms/step - loss: 31.9567 - val_loss: 32.0438\n",
      "Epoch 137/500\n",
      "699/711 [============================>.] - ETA: 0s - loss: 31.9671\n",
      "Epoch 00137: val_loss did not improve from 32.04379\n",
      "711/711 [==============================] - 3s 4ms/step - loss: 31.9783 - val_loss: 32.5366\n",
      "Epoch 138/500\n",
      "708/711 [============================>.] - ETA: 0s - loss: 31.9970\n",
      "Epoch 00138: val_loss improved from 32.04379 to 32.02375, saving model to ../savedModels/VariationalEncoderModel_2.h5\n",
      "711/711 [==============================] - 3s 4ms/step - loss: 31.9984 - val_loss: 32.0238\n",
      "Epoch 139/500\n",
      "708/711 [============================>.] - ETA: 0s - loss: 31.9511\n",
      "Epoch 00139: val_loss did not improve from 32.02375\n",
      "711/711 [==============================] - 3s 4ms/step - loss: 31.9521 - val_loss: 32.0374\n",
      "Epoch 140/500\n",
      "703/711 [============================>.] - ETA: 0s - loss: 31.9357\n",
      "Epoch 00140: val_loss did not improve from 32.02375\n",
      "711/711 [==============================] - 3s 4ms/step - loss: 31.9361 - val_loss: 32.0290\n",
      "Epoch 141/500\n",
      "707/711 [============================>.] - ETA: 0s - loss: 31.9342\n",
      "Epoch 00141: val_loss did not improve from 32.02375\n",
      "711/711 [==============================] - 3s 4ms/step - loss: 31.9381 - val_loss: 32.0376\n",
      "Epoch 142/500\n",
      "707/711 [============================>.] - ETA: 0s - loss: 31.9232\n",
      "Epoch 00142: val_loss improved from 32.02375 to 32.02169, saving model to ../savedModels/VariationalEncoderModel_2.h5\n",
      "711/711 [==============================] - 3s 4ms/step - loss: 31.9239 - val_loss: 32.0217\n",
      "Epoch 143/500\n",
      "706/711 [============================>.] - ETA: 0s - loss: 31.9257\n",
      "Epoch 00143: val_loss did not improve from 32.02169\n",
      "711/711 [==============================] - 3s 4ms/step - loss: 31.9276 - val_loss: 32.0494\n",
      "Epoch 144/500\n",
      "697/711 [============================>.] - ETA: 0s - loss: 31.9128\n",
      "Epoch 00144: val_loss improved from 32.02169 to 31.99183, saving model to ../savedModels/VariationalEncoderModel_2.h5\n",
      "711/711 [==============================] - 3s 4ms/step - loss: 31.9205 - val_loss: 31.9918\n",
      "Epoch 145/500\n",
      "708/711 [============================>.] - ETA: 0s - loss: 31.9094\n",
      "Epoch 00145: val_loss did not improve from 31.99183\n",
      "711/711 [==============================] - 3s 4ms/step - loss: 31.9074 - val_loss: 32.3481\n",
      "Epoch 146/500\n",
      "705/711 [============================>.] - ETA: 0s - loss: 31.9045\n",
      "Epoch 00146: val_loss improved from 31.99183 to 31.96935, saving model to ../savedModels/VariationalEncoderModel_2.h5\n",
      "711/711 [==============================] - 3s 4ms/step - loss: 31.9066 - val_loss: 31.9694\n",
      "Epoch 147/500\n",
      "711/711 [==============================] - ETA: 0s - loss: 31.9027\n",
      "Epoch 00147: val_loss improved from 31.96935 to 31.96016, saving model to ../savedModels/VariationalEncoderModel_2.h5\n",
      "711/711 [==============================] - 3s 4ms/step - loss: 31.9027 - val_loss: 31.9602\n",
      "Epoch 148/500\n",
      "707/711 [============================>.] - ETA: 0s - loss: 31.8966\n",
      "Epoch 00148: val_loss did not improve from 31.96016\n",
      "711/711 [==============================] - 3s 4ms/step - loss: 31.8946 - val_loss: 31.9787\n",
      "Epoch 149/500\n",
      "702/711 [============================>.] - ETA: 0s - loss: 31.8862\n",
      "Epoch 00149: val_loss did not improve from 31.96016\n",
      "711/711 [==============================] - 3s 4ms/step - loss: 31.8873 - val_loss: 31.9920\n",
      "Epoch 150/500\n",
      "711/711 [==============================] - ETA: 0s - loss: 31.8726\n",
      "Epoch 00150: val_loss did not improve from 31.96016\n",
      "711/711 [==============================] - 3s 4ms/step - loss: 31.8726 - val_loss: 31.9896\n",
      "Epoch 151/500\n",
      " 16/711 [..............................] - ETA: 2s - loss: 32.0424"
     ]
    }
   ],
   "source": [
    "history = VAE.fit(train,epochs=epochs,shuffle=True,\n",
    "                          verbose=1,validation_data=dev,\n",
    "                          callbacks=[checkpoint,earlystop])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "plot_loss(history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "VAE.load_weights(\"../savedModels/VariationalEncoderModel.h5\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### create monte carlo to generate output prob score for anomaly prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "sampling_size = 100\n",
    "\n",
    "def reconstruction_log_prob(x_input,sampling_size):\n",
    "    Z = encoder(x_input)\n",
    "    encoder_samples = Z.sample(sampling_size)  # generate 30 outputs from encoder per input \n",
    "    return np.mean(decoder(encoder_samples).log_prob(x_input), axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = pd.read_csv(\"../processedData/hold_outset_moreFraud.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_tf_data, label = test.drop(\"Class\",axis=1).values, test[\"Class\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Model was constructed with shape (None, 5) for input Tensor(\"input_2:0\", shape=(None, 5), dtype=float32), but it was called on an input with incompatible shape (100, 57350, 5).\n"
     ]
    }
   ],
   "source": [
    "x_log_prob = reconstruction_log_prob(test_tf_data, sampling_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.hist(-x_log_prob[label==1],label=\"fraud\",color=\"red\",alpha = 0.5, log=True)\n",
    "plt.hist(-x_log_prob[label==0],label=\"normal\",color=\"blue\",alpha=0.5, log=True)\n",
    "plt.title(\"reconstruction log prob\")\n",
    "plt.ylabel(\"frequence log\")\n",
    "plt.xlabel(\"logp(x_input|x_output)\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "fpr, tpr, threshold = roc_curve(label,-x_log_prob)\n",
    "auc = roc_auc_score(label,-x_log_prob)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(fpr,tpr,label=f\"linear in-sample, auc={auc}\")\n",
    "plt.legend(loc=\"best\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Choose a threshold that gives a good overall class1 recall "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = pd.DataFrame({\"label\":label,\"neg_log_prob\":-x_log_prob})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "results[\"pred_class\"]=results.neg_log_prob.apply(lambda x: 1 if x>75.5 else 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[56729,   129],\n",
       "       [  135,   357]])"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "confusion_matrix(results.label,results.pred_class)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00     56858\n",
      "           1       0.73      0.73      0.73       492\n",
      "\n",
      "    accuracy                           1.00     57350\n",
      "   macro avg       0.87      0.86      0.86     57350\n",
      "weighted avg       1.00      1.00      1.00     57350\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(results.label, results.pred_class))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
