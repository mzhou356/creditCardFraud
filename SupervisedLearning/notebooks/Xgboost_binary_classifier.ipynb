{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import xgboost\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.model_selection import GridSearchCV,train_test_split\n",
    "import sys\n",
    "import numpy as np\n",
    "import pandas as pd \n",
    "import matplotlib.pyplot as plt \n",
    "%matplotlib inline\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "plt.style.use('bmh')\n",
    "sys.path.append(\"/home/mindy/Documents/projects/creditCardFraud/SupervisedLearning/scripts/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "from util import *\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load in Data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv(\"../../AnomalyDetection/processedData/TrainingData_normal.csv\")\n",
    "dev = pd.read_csv(\"../../AnomalyDetection/processedData/DevData_normal.csv\")\n",
    "test = pd.read_csv(\"../../AnomalyDetection/processedData/hold_outset_moreFraud.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "training,testing = train_test_dfs(train,dev,test,\"Class\",0.1,2020)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_X, train_y = training.drop(\"Class\", axis=1), training.Class;\n",
    "test_X, test_y = testing.drop(\"Class\",axis=1), testing.Class;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### XGBoost Parameters\n",
    "   * Key tree booster parameters:\n",
    "      * eta (learning rate) \n",
    "      * gamma: min loss reduction required to make a further split \n",
    "      * max depth: high deep the tree will be. Also memory costly.\n",
    "      * min_child_weight: decides on complex the model will be. \n",
    "      * max_delta_step: might help with logistic regression when class is extremely imbalanced.\n",
    "      * subsample: sample only parts of the data to prevent overfitting. \n",
    "      * sampling_method: \n",
    "         * uniform: subsample >= 0.5 is great. most tree methods only support this. \n",
    "         * gradient_based: subsample can be set to 0.1 and be okay. tree_method is = gpu_hist;\n",
    "      * colsample_bytree, colsample_bylevel, colsample_bynode: subsmapling of feature columns. \n",
    "      * lambda: l1 regularization. \n",
    "      * alpha: l1. \n",
    "      * tree method: auto,exact,approx,hist,gpu_hist (approx,hist,gpu_hist for distributed training) \n",
    "      * scale_pos_weight: control balance of positive and negative weights, start (sum(negative)/sum(positive))\n",
    "      * updater: define the sequence of tree updaters to run. \n",
    "      * refresh_leaf: when refresh in updater is 1, the tree leafs and nodes stats are updated if 0 only node stats are updated.\n",
    "      * process_type: a type of boosting process to run\n",
    "         * default: creates new trees \n",
    "         * update: only updates trees. \n",
    "      * num_parallel_tree: default is 1, num of parallel trees constructed during each iteration. It allows boosted random forest. \n",
    "      * "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### run a model with default parameter first"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "default_mdl = XGBClassifier().fit(train_X, train_y, eval_metric=\"aucpr\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_score_default = default_mdl.predict_proba(test_X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[28436     5]\n",
      " [   10    30]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00     28441\n",
      "           1       0.86      0.75      0.80        40\n",
      "\n",
      "    accuracy                           1.00     28481\n",
      "   macro avg       0.93      0.87      0.90     28481\n",
      "weighted avg       1.00      1.00      1.00     28481\n",
      "\n"
     ]
    }
   ],
   "source": [
    "output = model_results(test_y,pred_score_default[:,1],0.5, ifprint=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Really good initial results and let's see if we can improve this"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define Custom Metrics and run gridsearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "XG_model = XGBClassifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "custom_metrics = make_custom_score()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "parameters = {\n",
    "    \"eta\":[0.05,0.1,0.5],\n",
    "    \"max_depth\":[3,5,7],\n",
    "    \"n_estimators\":[20,50,100]\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "searchCV = GridSearchCV(XG_model,\n",
    "                        parameters,\n",
    "                        verbose=1,\n",
    "                        scoring=custom_metrics,\n",
    "                        refit=False,\n",
    "                        cv=5,\n",
    "                        n_jobs=20)                   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 27 candidates, totalling 135 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=20)]: Using backend LokyBackend with 20 concurrent workers.\n",
      "[Parallel(n_jobs=20)]: Done  10 tasks      | elapsed:   15.6s\n",
      "[Parallel(n_jobs=20)]: Done 135 out of 135 | elapsed:  3.9min finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5,\n",
       "             estimator=XGBClassifier(base_score=None, booster=None,\n",
       "                                     colsample_bylevel=None,\n",
       "                                     colsample_bynode=None,\n",
       "                                     colsample_bytree=None, gamma=None,\n",
       "                                     gpu_id=None, importance_type='gain',\n",
       "                                     interaction_constraints=None,\n",
       "                                     learning_rate=None, max_delta_step=None,\n",
       "                                     max_depth=None, min_child_weight=None,\n",
       "                                     missing=nan, monotone_constraints=None,\n",
       "                                     n_estimators=100, n_jobs...\n",
       "                                     scale_pos_weight=None, subsample=None,\n",
       "                                     tree_method=None, validate_parameters=None,\n",
       "                                     verbosity=None),\n",
       "             n_jobs=20,\n",
       "             param_grid={'eta': [0.05, 0.1, 0.5], 'max_depth': [3, 5, 7],\n",
       "                         'n_estimators': [20, 50, 100]},\n",
       "             refit=False,\n",
       "             scoring={'f1_f': make_scorer(f1_f), 'fn': make_scorer(fn),\n",
       "                      'fp': make_scorer(fp), 'prec_f': make_scorer(prec_f),\n",
       "                      'recall_f': make_scorer(recall_f),\n",
       "                      'tp': make_scorer(tp)},\n",
       "             verbose=1)"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "searchCV.fit(train_X, train_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>eta</th>\n",
       "      <th>max_depth</th>\n",
       "      <th>n_estimators</th>\n",
       "      <th>tp</th>\n",
       "      <th>fp</th>\n",
       "      <th>fn</th>\n",
       "      <th>f1_f</th>\n",
       "      <th>prec_f</th>\n",
       "      <th>recall_f</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>0.50</td>\n",
       "      <td>7</td>\n",
       "      <td>50</td>\n",
       "      <td>72.4</td>\n",
       "      <td>3.6</td>\n",
       "      <td>18.0</td>\n",
       "      <td>0.869525</td>\n",
       "      <td>0.953249</td>\n",
       "      <td>0.800952</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0.10</td>\n",
       "      <td>5</td>\n",
       "      <td>100</td>\n",
       "      <td>72.4</td>\n",
       "      <td>4.6</td>\n",
       "      <td>18.0</td>\n",
       "      <td>0.864754</td>\n",
       "      <td>0.940519</td>\n",
       "      <td>0.801001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0.10</td>\n",
       "      <td>5</td>\n",
       "      <td>50</td>\n",
       "      <td>72.2</td>\n",
       "      <td>4.2</td>\n",
       "      <td>18.2</td>\n",
       "      <td>0.865494</td>\n",
       "      <td>0.945333</td>\n",
       "      <td>0.798779</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0.10</td>\n",
       "      <td>5</td>\n",
       "      <td>20</td>\n",
       "      <td>72.0</td>\n",
       "      <td>5.4</td>\n",
       "      <td>18.4</td>\n",
       "      <td>0.858053</td>\n",
       "      <td>0.930717</td>\n",
       "      <td>0.796532</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.05</td>\n",
       "      <td>5</td>\n",
       "      <td>50</td>\n",
       "      <td>72.0</td>\n",
       "      <td>5.4</td>\n",
       "      <td>18.4</td>\n",
       "      <td>0.858053</td>\n",
       "      <td>0.930717</td>\n",
       "      <td>0.796532</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.05</td>\n",
       "      <td>5</td>\n",
       "      <td>100</td>\n",
       "      <td>72.0</td>\n",
       "      <td>4.2</td>\n",
       "      <td>18.4</td>\n",
       "      <td>0.864187</td>\n",
       "      <td>0.945179</td>\n",
       "      <td>0.796557</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>0.50</td>\n",
       "      <td>3</td>\n",
       "      <td>20</td>\n",
       "      <td>72.0</td>\n",
       "      <td>6.2</td>\n",
       "      <td>18.4</td>\n",
       "      <td>0.853731</td>\n",
       "      <td>0.921084</td>\n",
       "      <td>0.796532</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.05</td>\n",
       "      <td>7</td>\n",
       "      <td>50</td>\n",
       "      <td>72.0</td>\n",
       "      <td>4.8</td>\n",
       "      <td>18.4</td>\n",
       "      <td>0.861042</td>\n",
       "      <td>0.938583</td>\n",
       "      <td>0.796532</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>0.50</td>\n",
       "      <td>7</td>\n",
       "      <td>20</td>\n",
       "      <td>71.8</td>\n",
       "      <td>4.4</td>\n",
       "      <td>18.6</td>\n",
       "      <td>0.861435</td>\n",
       "      <td>0.943087</td>\n",
       "      <td>0.794310</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>0.10</td>\n",
       "      <td>7</td>\n",
       "      <td>100</td>\n",
       "      <td>71.8</td>\n",
       "      <td>4.0</td>\n",
       "      <td>18.6</td>\n",
       "      <td>0.863775</td>\n",
       "      <td>0.947637</td>\n",
       "      <td>0.794335</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>0.10</td>\n",
       "      <td>7</td>\n",
       "      <td>20</td>\n",
       "      <td>71.8</td>\n",
       "      <td>5.6</td>\n",
       "      <td>18.6</td>\n",
       "      <td>0.855664</td>\n",
       "      <td>0.928379</td>\n",
       "      <td>0.794310</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>0.50</td>\n",
       "      <td>7</td>\n",
       "      <td>100</td>\n",
       "      <td>71.8</td>\n",
       "      <td>3.4</td>\n",
       "      <td>18.6</td>\n",
       "      <td>0.866506</td>\n",
       "      <td>0.955649</td>\n",
       "      <td>0.794310</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.05</td>\n",
       "      <td>7</td>\n",
       "      <td>100</td>\n",
       "      <td>71.8</td>\n",
       "      <td>4.4</td>\n",
       "      <td>18.6</td>\n",
       "      <td>0.861778</td>\n",
       "      <td>0.943336</td>\n",
       "      <td>0.794335</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>0.10</td>\n",
       "      <td>7</td>\n",
       "      <td>50</td>\n",
       "      <td>71.6</td>\n",
       "      <td>4.4</td>\n",
       "      <td>18.8</td>\n",
       "      <td>0.860369</td>\n",
       "      <td>0.943222</td>\n",
       "      <td>0.792112</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.05</td>\n",
       "      <td>7</td>\n",
       "      <td>20</td>\n",
       "      <td>71.6</td>\n",
       "      <td>6.0</td>\n",
       "      <td>18.8</td>\n",
       "      <td>0.852241</td>\n",
       "      <td>0.923783</td>\n",
       "      <td>0.792088</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>0.50</td>\n",
       "      <td>3</td>\n",
       "      <td>50</td>\n",
       "      <td>71.4</td>\n",
       "      <td>3.4</td>\n",
       "      <td>19.0</td>\n",
       "      <td>0.863958</td>\n",
       "      <td>0.954863</td>\n",
       "      <td>0.789890</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>0.50</td>\n",
       "      <td>3</td>\n",
       "      <td>100</td>\n",
       "      <td>71.4</td>\n",
       "      <td>4.4</td>\n",
       "      <td>19.0</td>\n",
       "      <td>0.858846</td>\n",
       "      <td>0.941997</td>\n",
       "      <td>0.789841</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>0.50</td>\n",
       "      <td>5</td>\n",
       "      <td>100</td>\n",
       "      <td>71.4</td>\n",
       "      <td>3.6</td>\n",
       "      <td>19.0</td>\n",
       "      <td>0.863046</td>\n",
       "      <td>0.952941</td>\n",
       "      <td>0.789890</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.05</td>\n",
       "      <td>5</td>\n",
       "      <td>20</td>\n",
       "      <td>71.2</td>\n",
       "      <td>6.4</td>\n",
       "      <td>19.2</td>\n",
       "      <td>0.847422</td>\n",
       "      <td>0.918465</td>\n",
       "      <td>0.787643</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0.10</td>\n",
       "      <td>3</td>\n",
       "      <td>100</td>\n",
       "      <td>71.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>19.4</td>\n",
       "      <td>0.848158</td>\n",
       "      <td>0.923095</td>\n",
       "      <td>0.785470</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>0.50</td>\n",
       "      <td>5</td>\n",
       "      <td>50</td>\n",
       "      <td>70.8</td>\n",
       "      <td>3.6</td>\n",
       "      <td>19.6</td>\n",
       "      <td>0.858913</td>\n",
       "      <td>0.952119</td>\n",
       "      <td>0.783272</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>0.50</td>\n",
       "      <td>5</td>\n",
       "      <td>20</td>\n",
       "      <td>70.6</td>\n",
       "      <td>5.8</td>\n",
       "      <td>19.8</td>\n",
       "      <td>0.846207</td>\n",
       "      <td>0.924507</td>\n",
       "      <td>0.781074</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.05</td>\n",
       "      <td>3</td>\n",
       "      <td>50</td>\n",
       "      <td>70.4</td>\n",
       "      <td>10.8</td>\n",
       "      <td>20.0</td>\n",
       "      <td>0.820538</td>\n",
       "      <td>0.869849</td>\n",
       "      <td>0.778755</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.05</td>\n",
       "      <td>3</td>\n",
       "      <td>100</td>\n",
       "      <td>70.4</td>\n",
       "      <td>7.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>0.839024</td>\n",
       "      <td>0.911442</td>\n",
       "      <td>0.778779</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.10</td>\n",
       "      <td>3</td>\n",
       "      <td>20</td>\n",
       "      <td>70.2</td>\n",
       "      <td>12.0</td>\n",
       "      <td>20.2</td>\n",
       "      <td>0.813646</td>\n",
       "      <td>0.857251</td>\n",
       "      <td>0.776557</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.10</td>\n",
       "      <td>3</td>\n",
       "      <td>50</td>\n",
       "      <td>70.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>20.4</td>\n",
       "      <td>0.836380</td>\n",
       "      <td>0.911268</td>\n",
       "      <td>0.774383</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.05</td>\n",
       "      <td>3</td>\n",
       "      <td>20</td>\n",
       "      <td>67.8</td>\n",
       "      <td>14.2</td>\n",
       "      <td>22.6</td>\n",
       "      <td>0.786662</td>\n",
       "      <td>0.827596</td>\n",
       "      <td>0.750037</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     eta  max_depth  n_estimators    tp    fp    fn      f1_f    prec_f  \\\n",
       "25  0.50          7            50  72.4   3.6  18.0  0.869525  0.953249   \n",
       "14  0.10          5           100  72.4   4.6  18.0  0.864754  0.940519   \n",
       "13  0.10          5            50  72.2   4.2  18.2  0.865494  0.945333   \n",
       "12  0.10          5            20  72.0   5.4  18.4  0.858053  0.930717   \n",
       "4   0.05          5            50  72.0   5.4  18.4  0.858053  0.930717   \n",
       "5   0.05          5           100  72.0   4.2  18.4  0.864187  0.945179   \n",
       "18  0.50          3            20  72.0   6.2  18.4  0.853731  0.921084   \n",
       "7   0.05          7            50  72.0   4.8  18.4  0.861042  0.938583   \n",
       "24  0.50          7            20  71.8   4.4  18.6  0.861435  0.943087   \n",
       "17  0.10          7           100  71.8   4.0  18.6  0.863775  0.947637   \n",
       "15  0.10          7            20  71.8   5.6  18.6  0.855664  0.928379   \n",
       "26  0.50          7           100  71.8   3.4  18.6  0.866506  0.955649   \n",
       "8   0.05          7           100  71.8   4.4  18.6  0.861778  0.943336   \n",
       "16  0.10          7            50  71.6   4.4  18.8  0.860369  0.943222   \n",
       "6   0.05          7            20  71.6   6.0  18.8  0.852241  0.923783   \n",
       "19  0.50          3            50  71.4   3.4  19.0  0.863958  0.954863   \n",
       "20  0.50          3           100  71.4   4.4  19.0  0.858846  0.941997   \n",
       "23  0.50          5           100  71.4   3.6  19.0  0.863046  0.952941   \n",
       "3   0.05          5            20  71.2   6.4  19.2  0.847422  0.918465   \n",
       "11  0.10          3           100  71.0   6.0  19.4  0.848158  0.923095   \n",
       "22  0.50          5            50  70.8   3.6  19.6  0.858913  0.952119   \n",
       "21  0.50          5            20  70.6   5.8  19.8  0.846207  0.924507   \n",
       "1   0.05          3            50  70.4  10.8  20.0  0.820538  0.869849   \n",
       "2   0.05          3           100  70.4   7.0  20.0  0.839024  0.911442   \n",
       "9   0.10          3            20  70.2  12.0  20.2  0.813646  0.857251   \n",
       "10  0.10          3            50  70.0   7.0  20.4  0.836380  0.911268   \n",
       "0   0.05          3            20  67.8  14.2  22.6  0.786662  0.827596   \n",
       "\n",
       "    recall_f  \n",
       "25  0.800952  \n",
       "14  0.801001  \n",
       "13  0.798779  \n",
       "12  0.796532  \n",
       "4   0.796532  \n",
       "5   0.796557  \n",
       "18  0.796532  \n",
       "7   0.796532  \n",
       "24  0.794310  \n",
       "17  0.794335  \n",
       "15  0.794310  \n",
       "26  0.794310  \n",
       "8   0.794335  \n",
       "16  0.792112  \n",
       "6   0.792088  \n",
       "19  0.789890  \n",
       "20  0.789841  \n",
       "23  0.789890  \n",
       "3   0.787643  \n",
       "11  0.785470  \n",
       "22  0.783272  \n",
       "21  0.781074  \n",
       "1   0.778755  \n",
       "2   0.778779  \n",
       "9   0.776557  \n",
       "10  0.774383  \n",
       "0   0.750037  "
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "CVResultsOutput(searchCV.cv_results_,custom_metrics.keys()).sort_values(\"tp\",ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### the following parameter seems to provide the best metrics:\n",
    "  * eta: 0.5\n",
    "  * maxdepth:7\n",
    "  * n_estimators: 50\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_model = XGBClassifier(n_estimators=50, eta = 0.5, max_depth=7).fit(train_X,train_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_pred_score = best_model.predict_proba(test_X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[28438     3]\n",
      " [   10    30]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00     28441\n",
      "           1       0.91      0.75      0.82        40\n",
      "\n",
      "    accuracy                           1.00     28481\n",
      "   macro avg       0.95      0.87      0.91     28481\n",
      "weighted avg       1.00      1.00      1.00     28481\n",
      "\n"
     ]
    }
   ],
   "source": [
    "final_output = model_results(test_y,best_pred_score[:,1],0.5,True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Precision has been improved after rough gridsearchCV"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
